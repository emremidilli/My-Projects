# VARIATIONAL ENCODER
* https://atcold.github.io/pytorch-Deep-Learning/en/week11/11-3/

# LSTM
* https://towardsdatascience.com/lstm-networks-a-detailed-explanation-8fae6aefc7f9#:~:text=LSTMs%20use%20a%20series%20of,each%20their%20own%20neural%20network.

# REGULARIZATION
* https://stats.stackexchange.com/questions/365778/what-should-i-do-when-my-neural-network-doesnt-generalize-well
* https://lilianweng.github.io/posts/2019-03-14-overfit/    (very important)

# GENERATIVE ADVERSARIAL NETWORK
* https://www.youtube.com/watch?v=ROLugVqjf00

# LOSS FUNCTIONS
* https://towardsdatascience.com/choosing-and-customizing-loss-functions-for-image-processing-a0e4bf665b0a

# LEARNING TO RANK
* https://towardsdatascience.com/learning-to-rank-a-complete-guide-to-ranking-using-machine-learning-4c9688d370d4
* https://embracingtherandom.com/machine-learning/tensorflow/ranking/deep-learning/learning-to-rank-part-2/#where-do-probabilities-fit-into-listnet

# SUPPORT & RESISTENCE LEVELS
* https://medium.com/@judopro/using-machine-learning-to-programmatically-determine-stock-support-and-resistance-levels-9bb70777cf8e  K-Means Algorithm used to identify the support and resistence levels.

# BAGGING
* https://towardsdatascience.com/time-series-bootstrap-in-the-age-of-deep-learning-b98aa2aa32c4

# EDA
* https://www.kaggle.com/code/vishank123/eda-on-m5-data-and-forecast-using-various-models

# BERT
* https://github.com/google-research/bert
* http://jalammar.github.io/illustrated-bert/
* https://www.youtube.com/watch?v=EOmd5sUUA_A&list=PLgtf4d9zHHO8p_zDKstvqvtkv80jhHxoE&index=6


# TRANSFORMER
* https://jalammar.github.io/illustrated-transformer/
* https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/
* https://towardsdatascience.com/attention-for-time-series-classification-and-forecasting-261723e0006d
* https://www.topbots.com/attention-for-time-series-forecasting-and-classification/
* https://towardsdatascience.com/transformers-141e32e69591
* https://towardsdatascience.com/stock-predictions-with-state-of-the-art-transformer-and-time-embeddings-3a4485237de6
* https://www.youtube.com/watch?v=FC8PziPmxnQ
* https://www.youtube.com/watch?v=J4H6A4-dvhE
* https://www.youtube.com/watch?v=48gBPL7aHJY
* https://www.youtube.com/watch?v=dichIcUZfOw&t=0s
* https://www.youtube.com/watch?v=mMa2PmYJlCo&t=14s
* https://www.youtube.com/watch?v=gJ9kaJsE78k&t=172s


# N-BEATS
* https://www.kaggle.com/code/gatandubuc/forecast-with-n-beats-interpretable-model

# N-HITS
* https://towardsdatascience.com/all-about-n-hits-the-latest-breakthrough-in-time-series-forecasting-a8ddcb27b0d5#:~:text=N%2DHiTS%20stands%20for%20Neural,time%20series%20at%20different%20rates.

# TEMPORAL CONVOLUTIONAL NEURAL NETWORKS
* https://towardsdatascience.com/temporal-convolutional-networks-the-next-revolution-for-time-series-8990af826567


# TEMPORAL FUSION TRANSFORMER
* https://towardsdatascience.com/temporal-fusion-transformer-googles-model-for-interpretable-time-series-forecasting-5aa17beb621