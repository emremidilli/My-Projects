{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0611acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import MetaTrader5 as mt5\n",
    "import pytz\n",
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, max_error, median_absolute_error, r2_score, explained_variance_score\n",
    "from Optimize_Portfolio import PortfolioManagement\n",
    "from Long_Short_Term_Memory import Long_Short_Term_Memory\n",
    "from Neural_Attention_Mechanism import Neural_Attention_Mechanism\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import ta\n",
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c6fc32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_o_TIME_ZONE = pytz.timezone(\"Etc/UTC\")\n",
    "gc_dt_FROM = datetime(2021, 1, 1, tzinfo=gc_o_TIME_ZONE)\n",
    "gc_dt_TO = datetime(2021, 9, 22, tzinfo=gc_o_TIME_ZONE)\n",
    "gc_dt_SIMULATION_MODEL_FROM = \"2021-09-01 00:00:00\"\n",
    "\n",
    "\n",
    "gc_a_SYMBOLS = []\n",
    "\n",
    "\n",
    "gc_i_BACKWARD_TIME_WINDOW = -1\n",
    "gc_i_FORWARD_TIME_WINDOW = 5\n",
    "\n",
    "\n",
    "gc_dec_TRAINING_RATIO = 0.6\n",
    "gc_dec_VALIDATION_RATIO = 0.2\n",
    "gc_dec_TEST_RATIO = 0.2\n",
    "\n",
    "\n",
    "gc_dec_MAX_RISK_RMSE = 0.10\n",
    "gc_dec_INITIAL_BALANCE = 1000\n",
    "\n",
    "\n",
    "g_aBackwardTimeSteps = range(gc_i_BACKWARD_TIME_WINDOW, 0)\n",
    "g_aForwardTimeSteps = range(0, gc_i_FORWARD_TIME_WINDOW)\n",
    "\n",
    "gc_i_PERIODS_OF_CLASSES = 5\n",
    "\n",
    "g_aInputFeatures = set(['open', 'high', 'low', 'close', 'spread' ,'tick_volume'])\n",
    "g_aOutputFeatures = pd.IntervalIndex.from_breaks(st.norm.ppf(np.linspace(0, 1, gc_i_PERIODS_OF_CLASSES+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4727b224",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def ConvertSpreadValues(dfRates, aSymbolInfo):\n",
    "    iDigits = aSymbolInfo.digits\n",
    "    dfRates['spread'] = dfRates['spread'] * pow(10, -iDigits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "041e482c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def dfShiftTimeSteps(dfRates, aTimeSteps):\n",
    "    \n",
    "    lstColumnNames = list([])\n",
    "    for iTimeStep in aTimeSteps:\n",
    "        for tplCol in dfRates.columns:\n",
    "            lstColumnNames.append((iTimeStep, ) + tplCol)\n",
    "    \n",
    "    \n",
    "    lstIndexNames = (\"Time Step\",) +  tuple(dfRates.columns.names)\n",
    "    \n",
    "    dicColumnIndices = pd.MultiIndex.from_tuples(\n",
    "        lstColumnNames,\n",
    "        names = lstIndexNames\n",
    "        )\n",
    "\n",
    "\n",
    "    dfShiftedRates = pd.DataFrame(\n",
    "        columns=dicColumnIndices, \n",
    "        index=dfRates.index)\n",
    "    \n",
    "    \n",
    "\n",
    "    for i in aTimeSteps:\n",
    "        dfShiftedRates[i] = dfRates.shift(-i)\n",
    "\n",
    "    dfShiftedRates.dropna(inplace=True)\n",
    "\n",
    "    return dfShiftedRates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bad524f3",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def dfGetMarketData(sSymbol):\n",
    "\n",
    "    if not mt5.initialize():\n",
    "        print(\"initialize() failed, error code =\", mt5.last_error())\n",
    "        sys.exit()\n",
    "\n",
    "    aSymbolInfo = mt5.symbol_info(sSymbol)\n",
    "    if not aSymbolInfo:\n",
    "        print(\"symbol_info() failed, error code =\", mt5.last_error())\n",
    "        sys.exit()\n",
    "\n",
    "    aRates = mt5.copy_rates_range(\n",
    "        sSymbol, mt5.TIMEFRAME_M30, gc_dt_FROM, gc_dt_TO)\n",
    "    if len(aRates) == 0:\n",
    "        print(\"copy_rates_range() failed, error code =\", mt5.last_error())\n",
    "        sys.exit()\n",
    "\n",
    "    mt5.shutdown()\n",
    "\n",
    "    dfRates = pd.DataFrame(aRates)\n",
    "\n",
    "    dfRates['time'] = pd.to_datetime(dfRates['time'], unit='s')\n",
    "    dfRates.set_index('time', inplace=True)\n",
    "    dfRates.drop('real_volume', axis=1, inplace=True)\n",
    "\n",
    "    ConvertSpreadValues(dfRates, aSymbolInfo)\n",
    "    AddSeasonalFeatures(dfRates)\n",
    "    AddReturns(dfRates)\n",
    "    dfRates = dfAddTechnicalIndicators(dfRates)\n",
    "\n",
    "    dfRates.columns  = pd.MultiIndex.from_product(\n",
    "        [[sSymbol], dfRates.columns], \n",
    "        names=[\"Time Series\", \"Feature\"])\n",
    "    \n",
    "    \n",
    "    return dfRates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d9f70b2",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def dfAddTechnicalIndicators(dfRates):\n",
    "    global g_aInputFeatures \n",
    "    \n",
    "    \n",
    "    iTimeWindow = 24\n",
    "    \n",
    "    dfHigh = dfRates[\"high\"]\n",
    "    dfLow = dfRates[\"low\"]\n",
    "    dfClose = dfRates[\"close\"]\n",
    "    \n",
    "    # Average Dricetional Movement Index\n",
    "    oAdx = ta.trend.ADXIndicator(dfHigh, dfLow, dfClose, iTimeWindow, False)\n",
    "    \n",
    "    dfAdx = oAdx.adx()\n",
    "    dfAdx.drop(dfAdx[dfAdx == 0].index, inplace = True)\n",
    "    g_aInputFeatures.add(dfAdx.name)\n",
    "    \n",
    "    dfAdxNeg = oAdx.adx_neg()\n",
    "    dfAdxNeg.drop(dfAdxNeg[dfAdxNeg == 0].index, inplace = True)\n",
    "    g_aInputFeatures.add(dfAdxNeg.name)\n",
    "    \n",
    "    \n",
    "    dfAdxPos = oAdx.adx_pos()\n",
    "    dfAdxPos.drop(dfAdxPos[dfAdxPos == 0].index, inplace = True)\n",
    "    g_aInputFeatures.add(dfAdxPos.name)\n",
    "    \n",
    "    \n",
    "    dfRates = dfRates.join(dfAdx, how = \"inner\")\n",
    "    dfRates = dfRates.join(dfAdxNeg, how = \"inner\")\n",
    "    dfRates = dfRates.join(dfAdxPos, how = \"inner\")\n",
    "\n",
    "    \n",
    "    # Aroon Indicator\n",
    "    oAroon = ta.trend.AroonIndicator(dfClose, iTimeWindow, False)\n",
    "    dfAroonDown = oAroon.aroon_down()\n",
    "    dfAroonDown.dropna(inplace = True)\n",
    "    g_aInputFeatures.add(dfAroonDown.name)\n",
    "    \n",
    "    dfAroonIndicator = oAroon.aroon_indicator() \n",
    "    dfAroonIndicator.dropna(inplace = True)\n",
    "    g_aInputFeatures.add(dfAroonIndicator.name)\n",
    "\n",
    "    \n",
    "    dfAroonUp = oAroon.aroon_up()\n",
    "    dfAroonUp.dropna(inplace = True)\n",
    "    g_aInputFeatures.add(dfAroonUp.name)\n",
    "    \n",
    "    dfRates = dfRates.join(dfAroonDown, how = \"inner\")\n",
    "    dfRates = dfRates.join(dfAroonIndicator, how = \"inner\")\n",
    "    dfRates = dfRates.join(dfAroonUp, how = \"inner\")\n",
    "    \n",
    "    \n",
    "    # Commodity Channel Index\n",
    "    oCci = ta.trend.CCIIndicator(dfHigh, dfLow,dfClose, iTimeWindow)\n",
    "    dfCci = oCci.cci()\n",
    "    dfCci.dropna(inplace = True)\n",
    "    g_aInputFeatures.add(dfCci.name)\n",
    "    \n",
    "    dfRates = dfRates.join(dfCci, how = \"inner\")\n",
    "    \n",
    "    \n",
    "    # Detrended Price Oscillator (DPO)\n",
    "    oDpo = ta.trend.DPOIndicator(dfClose, iTimeWindow)\n",
    "    dfDpo = oDpo.dpo()\n",
    "    dfDpo.dropna(inplace = True)\n",
    "    g_aInputFeatures.add(dfDpo.name)    \n",
    "    \n",
    "    dfRates = dfRates.join(dfDpo, how = \"inner\")\n",
    "    \n",
    "    \n",
    "    # EMA - Exponential Moving Average\n",
    "    oEma = ta.trend.EMAIndicator(dfClose, iTimeWindow)\n",
    "    dfEma = oEma.ema_indicator()\n",
    "    dfEma.dropna(inplace = True)\n",
    "    g_aInputFeatures.add(dfEma.name)\n",
    "    \n",
    "    dfRates = dfRates.join(dfEma, how = \"inner\")\n",
    "    \n",
    "    \n",
    "    return dfRates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f89a65d2",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def AddSeasonalFeatures(dfRates):\n",
    "    global g_aInputFeatures \n",
    "    \n",
    "    c_a_SEASONAL_FEATURES = [\"year\", \"month\", \"day\", \"dayofweek\", \"hour\"]\n",
    "    for sSeasonalFeature in c_a_SEASONAL_FEATURES:\n",
    "        exec(\"dfRates[sSeasonalFeature] = dfRates.index.\" + sSeasonalFeature)\n",
    "        g_aInputFeatures.add(sSeasonalFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17475e81",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def AddReturns(dfRates):\n",
    "    dfRates[\"return\"] = (dfRates[\"open\"] - dfRates[\"close\"])/dfRates[\"open\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e680ce9d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def dfOversampleImbalancedData(dfX, dfY):\n",
    "    \n",
    "#     oOversample = SMOTE()\n",
    "#     aX, aY = oOversample.fit_resample(dfX.values, dfY.values)\n",
    "    \n",
    "#     dfX = pd.DataFrame(data = aX, columns = dfX.columns)\n",
    "#     dfY = pd.DataFrame(data = aY, columns = dfY.columns)\n",
    "    \n",
    "    dfXCopy = dfX.copy()\n",
    "    dfYCopy = dfY.copy()\n",
    "        \n",
    "    dfCombinations = dfYCopy.astype(str).agg('-'.join, axis=1)\n",
    "    dfCombinationsStats = dfCombinations.value_counts()\n",
    "    dfCombinationsStats = pd.DataFrame(dfCombinationsStats).reset_index()\n",
    "    \n",
    "    \n",
    "    iMaxAmount = dfCombinationsStats.iloc[0,1]\n",
    "    for i in range(1, len(dfCombinationsStats) ):\n",
    "        \n",
    "        sCombination = dfCombinationsStats.iloc[i, 0]\n",
    "        iSamplesNeeded = iMaxAmount - dfCombinationsStats.iloc[i, 1]\n",
    "        \n",
    "        dfSampledIndex =  dfCombinations[dfCombinations == sCombination].sample(iSamplesNeeded, replace = True).index\n",
    "        \n",
    "        dfSampledX = dfXCopy.loc[dfSampledIndex]\n",
    "        dfSampledY = dfYCopy.loc[dfSampledIndex]\n",
    "        \n",
    "    \n",
    "        dfX = dfX.append(dfSampledX , ignore_index= True)\n",
    "        dfY = dfY.append(dfSampledY , ignore_index= True)\n",
    "        \n",
    "    \n",
    "    dfX,dfY = shuffle(dfX,dfY )\n",
    "    \n",
    "\n",
    "    return dfX, dfY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "682253c6",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def dfSplitData(dfInput, dfOutput):\n",
    "    dfInputTrainValidation, dfInputTest, dfOutputTrainValidation, dfOutputTest = train_test_split(\n",
    "        dfInput,\n",
    "        dfOutput,\n",
    "        test_size=gc_dec_TEST_RATIO,\n",
    "        shuffle=False)\n",
    "\n",
    "    dfInputTrain, dfInputValidation, dfOutputTrain, dfOutputValidation = train_test_split(\n",
    "        dfInputTrainValidation,\n",
    "        dfOutputTrainValidation,\n",
    "        test_size=(1/(1 -gc_dec_TEST_RATIO))-1,\n",
    "        shuffle=False)\n",
    "    \n",
    "    \n",
    "    dfInputTrain = dfInputTrain.astype(float)\n",
    "    dfInputValidation = dfInputValidation.astype(float)\n",
    "    dfInputTest = dfInputTest.astype(float)\n",
    "    dfOutputTrain = dfOutputTrain.astype(float)\n",
    "    dfOutputValidation = dfOutputValidation.astype(float)\n",
    "    dfOutputTest = dfOutputTest.astype(float)\n",
    "    \n",
    "    return dfInputTrain, dfInputValidation, dfInputTest, dfOutputTrain, dfOutputValidation, dfOutputTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca3eba12",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def dfScaleData(sScalerName,dfTrain,dfValidation, dfTest):\n",
    "    sScalersDirectory = os.path.join(sSubModelName , \"__scalers__\")\n",
    "\n",
    "    oScaler = StandardScaler()\n",
    "\n",
    "    oScaler.fit(dfTrain)\n",
    "\n",
    "    aScaledTrain = oScaler.transform(dfTrain)\n",
    "    aScaledValidation = oScaler.transform(dfValidation)\n",
    "    aScaledTest = oScaler.transform(dfTest)\n",
    "\n",
    "    dfScaledTrain = pd.DataFrame(aScaledTrain, columns = dfTrain.columns, index = dfTrain.index)\n",
    "    dfScaledValidation = pd.DataFrame(aScaledValidation, columns = dfValidation.columns, index = dfValidation.index)\n",
    "    dfScaledTest = pd.DataFrame(aScaledTest, columns = dfTest.columns, index = dfTest.index)\n",
    "\n",
    "    sScalerFilePath =os.path.join(sScalersDirectory, sScalerName + \".sav\")\n",
    "    os.makedirs(os.path.dirname(sScalerFilePath), exist_ok=True)\n",
    "    pickle.dump(oScaler, open(sScalerFilePath, 'wb'))\n",
    "    \n",
    "    \n",
    "    return dfScaledTrain, dfScaledValidation, dfScaledTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a44508f4",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "sSymbol = \"NAT.GAS\"\n",
    "aRelevantSymbols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad7ce049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yunus\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ta\\trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[i] = 100 * (self._dip[i] / self._trs[i])\n",
      "C:\\Users\\yunus\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ta\\trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[i] = 100 * (self._din[i] / self._trs[i])\n"
     ]
    }
   ],
   "source": [
    "dfRates = dfGetMarketData(sSymbol)\n",
    "\n",
    "for sRelevantSymbol in aRelevantSymbols:\n",
    "    dfRelevantRates = dfGetMarketData(sRelevantSymbol)\n",
    "    dfRates = dfRates.join(dfRelevantRates, how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fa7f436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Time Series</th>\n",
       "      <th colspan=\"21\" halign=\"left\">NAT.GAS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>tick_volume</th>\n",
       "      <th>spread</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>...</th>\n",
       "      <th>return</th>\n",
       "      <th>adx</th>\n",
       "      <th>adx_neg</th>\n",
       "      <th>adx_pos</th>\n",
       "      <th>aroon_down_24</th>\n",
       "      <th>aroon_ind_24</th>\n",
       "      <th>aroon_up_24</th>\n",
       "      <th>cci</th>\n",
       "      <th>dpo_24</th>\n",
       "      <th>ema_24</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-05 01:30:00</th>\n",
       "      <td>2.582</td>\n",
       "      <td>2.589</td>\n",
       "      <td>2.582</td>\n",
       "      <td>2.588</td>\n",
       "      <td>148</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002324</td>\n",
       "      <td>18.732942</td>\n",
       "      <td>22.124691</td>\n",
       "      <td>16.667519</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>-41.666667</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>-27.331487</td>\n",
       "      <td>-0.006958</td>\n",
       "      <td>2.590461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05 02:00:00</th>\n",
       "      <td>2.588</td>\n",
       "      <td>2.589</td>\n",
       "      <td>2.583</td>\n",
       "      <td>2.587</td>\n",
       "      <td>153</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>18.538557</td>\n",
       "      <td>21.748555</td>\n",
       "      <td>16.384159</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>-41.666667</td>\n",
       "      <td>20.833333</td>\n",
       "      <td>-24.385511</td>\n",
       "      <td>-0.013083</td>\n",
       "      <td>2.590184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05 02:30:00</th>\n",
       "      <td>2.586</td>\n",
       "      <td>2.592</td>\n",
       "      <td>2.585</td>\n",
       "      <td>2.588</td>\n",
       "      <td>129</td>\n",
       "      <td>0.011</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000773</td>\n",
       "      <td>18.244230</td>\n",
       "      <td>21.307561</td>\n",
       "      <td>16.920949</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>-41.666667</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>-12.569691</td>\n",
       "      <td>-0.011458</td>\n",
       "      <td>2.590010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05 03:00:00</th>\n",
       "      <td>2.589</td>\n",
       "      <td>2.602</td>\n",
       "      <td>2.588</td>\n",
       "      <td>2.602</td>\n",
       "      <td>270</td>\n",
       "      <td>0.011</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005021</td>\n",
       "      <td>17.621825</td>\n",
       "      <td>20.442495</td>\n",
       "      <td>19.133904</td>\n",
       "      <td>54.166667</td>\n",
       "      <td>-41.666667</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>29.306931</td>\n",
       "      <td>-0.013125</td>\n",
       "      <td>2.590969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05 03:30:00</th>\n",
       "      <td>2.601</td>\n",
       "      <td>2.601</td>\n",
       "      <td>2.595</td>\n",
       "      <td>2.599</td>\n",
       "      <td>136</td>\n",
       "      <td>0.011</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>17.025352</td>\n",
       "      <td>20.018462</td>\n",
       "      <td>18.737015</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>-41.666667</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>31.773597</td>\n",
       "      <td>-0.006375</td>\n",
       "      <td>2.591611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21 21:30:00</th>\n",
       "      <td>4.843</td>\n",
       "      <td>4.864</td>\n",
       "      <td>4.840</td>\n",
       "      <td>4.849</td>\n",
       "      <td>799</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001239</td>\n",
       "      <td>21.460824</td>\n",
       "      <td>27.739579</td>\n",
       "      <td>16.741784</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>-45.833333</td>\n",
       "      <td>29.166667</td>\n",
       "      <td>-50.402653</td>\n",
       "      <td>-0.000917</td>\n",
       "      <td>4.889529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21 22:00:00</th>\n",
       "      <td>4.849</td>\n",
       "      <td>4.885</td>\n",
       "      <td>4.848</td>\n",
       "      <td>4.879</td>\n",
       "      <td>671</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006187</td>\n",
       "      <td>21.341199</td>\n",
       "      <td>26.658781</td>\n",
       "      <td>18.300860</td>\n",
       "      <td>70.833333</td>\n",
       "      <td>-45.833333</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>-31.879393</td>\n",
       "      <td>0.043042</td>\n",
       "      <td>4.888687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21 22:30:00</th>\n",
       "      <td>4.879</td>\n",
       "      <td>4.888</td>\n",
       "      <td>4.862</td>\n",
       "      <td>4.872</td>\n",
       "      <td>679</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>21.190593</td>\n",
       "      <td>25.918313</td>\n",
       "      <td>18.113029</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>-45.833333</td>\n",
       "      <td>20.833333</td>\n",
       "      <td>-26.149548</td>\n",
       "      <td>-0.006917</td>\n",
       "      <td>4.887352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21 23:00:00</th>\n",
       "      <td>4.872</td>\n",
       "      <td>4.873</td>\n",
       "      <td>4.849</td>\n",
       "      <td>4.855</td>\n",
       "      <td>409</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003489</td>\n",
       "      <td>21.155493</td>\n",
       "      <td>26.654375</td>\n",
       "      <td>17.641062</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>-45.833333</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>-34.438907</td>\n",
       "      <td>-0.007458</td>\n",
       "      <td>4.884764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21 23:30:00</th>\n",
       "      <td>4.855</td>\n",
       "      <td>4.857</td>\n",
       "      <td>4.828</td>\n",
       "      <td>4.832</td>\n",
       "      <td>230</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004737</td>\n",
       "      <td>21.291022</td>\n",
       "      <td>28.109943</td>\n",
       "      <td>17.079914</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>-45.833333</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>-47.183227</td>\n",
       "      <td>-0.086042</td>\n",
       "      <td>4.880543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8464 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Time Series         NAT.GAS                                                \\\n",
       "Feature                open   high    low  close tick_volume spread  year   \n",
       "time                                                                        \n",
       "2021-01-05 01:30:00   2.582  2.589  2.582  2.588         148  0.010  2021   \n",
       "2021-01-05 02:00:00   2.588  2.589  2.583  2.587         153  0.010  2021   \n",
       "2021-01-05 02:30:00   2.586  2.592  2.585  2.588         129  0.011  2021   \n",
       "2021-01-05 03:00:00   2.589  2.602  2.588  2.602         270  0.011  2021   \n",
       "2021-01-05 03:30:00   2.601  2.601  2.595  2.599         136  0.011  2021   \n",
       "...                     ...    ...    ...    ...         ...    ...   ...   \n",
       "2021-09-21 21:30:00   4.843  4.864  4.840  4.849         799  0.005  2021   \n",
       "2021-09-21 22:00:00   4.849  4.885  4.848  4.879         671  0.005  2021   \n",
       "2021-09-21 22:30:00   4.879  4.888  4.862  4.872         679  0.005  2021   \n",
       "2021-09-21 23:00:00   4.872  4.873  4.849  4.855         409  0.010  2021   \n",
       "2021-09-21 23:30:00   4.855  4.857  4.828  4.832         230  0.010  2021   \n",
       "\n",
       "Time Series                              ...                                  \\\n",
       "Feature             month day dayofweek  ...    return        adx    adx_neg   \n",
       "time                                     ...                                   \n",
       "2021-01-05 01:30:00     1   5         1  ... -0.002324  18.732942  22.124691   \n",
       "2021-01-05 02:00:00     1   5         1  ...  0.000386  18.538557  21.748555   \n",
       "2021-01-05 02:30:00     1   5         1  ... -0.000773  18.244230  21.307561   \n",
       "2021-01-05 03:00:00     1   5         1  ... -0.005021  17.621825  20.442495   \n",
       "2021-01-05 03:30:00     1   5         1  ...  0.000769  17.025352  20.018462   \n",
       "...                   ...  ..       ...  ...       ...        ...        ...   \n",
       "2021-09-21 21:30:00     9  21         1  ... -0.001239  21.460824  27.739579   \n",
       "2021-09-21 22:00:00     9  21         1  ... -0.006187  21.341199  26.658781   \n",
       "2021-09-21 22:30:00     9  21         1  ...  0.001435  21.190593  25.918313   \n",
       "2021-09-21 23:00:00     9  21         1  ...  0.003489  21.155493  26.654375   \n",
       "2021-09-21 23:30:00     9  21         1  ...  0.004737  21.291022  28.109943   \n",
       "\n",
       "Time Series                                                            \\\n",
       "Feature                adx_pos aroon_down_24 aroon_ind_24 aroon_up_24   \n",
       "time                                                                    \n",
       "2021-01-05 01:30:00  16.667519     66.666667   -41.666667   25.000000   \n",
       "2021-01-05 02:00:00  16.384159     62.500000   -41.666667   20.833333   \n",
       "2021-01-05 02:30:00  16.920949     58.333333   -41.666667   16.666667   \n",
       "2021-01-05 03:00:00  19.133904     54.166667   -41.666667   12.500000   \n",
       "2021-01-05 03:30:00  18.737015     50.000000   -41.666667    8.333333   \n",
       "...                        ...           ...          ...         ...   \n",
       "2021-09-21 21:30:00  16.741784     75.000000   -45.833333   29.166667   \n",
       "2021-09-21 22:00:00  18.300860     70.833333   -45.833333   25.000000   \n",
       "2021-09-21 22:30:00  18.113029     66.666667   -45.833333   20.833333   \n",
       "2021-09-21 23:00:00  17.641062     62.500000   -45.833333   16.666667   \n",
       "2021-09-21 23:30:00  17.079914     58.333333   -45.833333   12.500000   \n",
       "\n",
       "Time Series                                         \n",
       "Feature                    cci    dpo_24    ema_24  \n",
       "time                                                \n",
       "2021-01-05 01:30:00 -27.331487 -0.006958  2.590461  \n",
       "2021-01-05 02:00:00 -24.385511 -0.013083  2.590184  \n",
       "2021-01-05 02:30:00 -12.569691 -0.011458  2.590010  \n",
       "2021-01-05 03:00:00  29.306931 -0.013125  2.590969  \n",
       "2021-01-05 03:30:00  31.773597 -0.006375  2.591611  \n",
       "...                        ...       ...       ...  \n",
       "2021-09-21 21:30:00 -50.402653 -0.000917  4.889529  \n",
       "2021-09-21 22:00:00 -31.879393  0.043042  4.888687  \n",
       "2021-09-21 22:30:00 -26.149548 -0.006917  4.887352  \n",
       "2021-09-21 23:00:00 -34.438907 -0.007458  4.884764  \n",
       "2021-09-21 23:30:00 -47.183227 -0.086042  4.880543  \n",
       "\n",
       "[8464 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfRates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d458f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInput  = dfRates.loc[:, dfRates.columns.get_level_values(1).isin(g_aInputFeatures)]\n",
    "dfInput = dfShiftTimeSteps(dfInput, g_aBackwardTimeSteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07c7b3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Time Step</th>\n",
       "      <th colspan=\"20\" halign=\"left\">-1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time Series</th>\n",
       "      <th colspan=\"20\" halign=\"left\">NAT.GAS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>tick_volume</th>\n",
       "      <th>spread</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour</th>\n",
       "      <th>adx</th>\n",
       "      <th>adx_neg</th>\n",
       "      <th>adx_pos</th>\n",
       "      <th>aroon_down_24</th>\n",
       "      <th>aroon_ind_24</th>\n",
       "      <th>aroon_up_24</th>\n",
       "      <th>cci</th>\n",
       "      <th>dpo_24</th>\n",
       "      <th>ema_24</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-05 02:00:00</th>\n",
       "      <td>2.582</td>\n",
       "      <td>2.589</td>\n",
       "      <td>2.582</td>\n",
       "      <td>2.588</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.732942</td>\n",
       "      <td>22.124691</td>\n",
       "      <td>16.667519</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>-41.666667</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>-27.331487</td>\n",
       "      <td>-0.006958</td>\n",
       "      <td>2.590461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05 02:30:00</th>\n",
       "      <td>2.588</td>\n",
       "      <td>2.589</td>\n",
       "      <td>2.583</td>\n",
       "      <td>2.587</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.538557</td>\n",
       "      <td>21.748555</td>\n",
       "      <td>16.384159</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>-41.666667</td>\n",
       "      <td>20.833333</td>\n",
       "      <td>-24.385511</td>\n",
       "      <td>-0.013083</td>\n",
       "      <td>2.590184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05 03:00:00</th>\n",
       "      <td>2.586</td>\n",
       "      <td>2.592</td>\n",
       "      <td>2.585</td>\n",
       "      <td>2.588</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.244230</td>\n",
       "      <td>21.307561</td>\n",
       "      <td>16.920949</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>-41.666667</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>-12.569691</td>\n",
       "      <td>-0.011458</td>\n",
       "      <td>2.590010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05 03:30:00</th>\n",
       "      <td>2.589</td>\n",
       "      <td>2.602</td>\n",
       "      <td>2.588</td>\n",
       "      <td>2.602</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.621825</td>\n",
       "      <td>20.442495</td>\n",
       "      <td>19.133904</td>\n",
       "      <td>54.166667</td>\n",
       "      <td>-41.666667</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>29.306931</td>\n",
       "      <td>-0.013125</td>\n",
       "      <td>2.590969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05 04:00:00</th>\n",
       "      <td>2.601</td>\n",
       "      <td>2.601</td>\n",
       "      <td>2.595</td>\n",
       "      <td>2.599</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.025352</td>\n",
       "      <td>20.018462</td>\n",
       "      <td>18.737015</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>-41.666667</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>31.773597</td>\n",
       "      <td>-0.006375</td>\n",
       "      <td>2.591611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21 21:30:00</th>\n",
       "      <td>4.824</td>\n",
       "      <td>4.844</td>\n",
       "      <td>4.810</td>\n",
       "      <td>4.843</td>\n",
       "      <td>1570.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.318925</td>\n",
       "      <td>28.456738</td>\n",
       "      <td>15.020175</td>\n",
       "      <td>79.166667</td>\n",
       "      <td>-45.833333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>-69.497198</td>\n",
       "      <td>0.053083</td>\n",
       "      <td>4.893054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21 22:00:00</th>\n",
       "      <td>4.843</td>\n",
       "      <td>4.864</td>\n",
       "      <td>4.840</td>\n",
       "      <td>4.849</td>\n",
       "      <td>799.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.460824</td>\n",
       "      <td>27.739579</td>\n",
       "      <td>16.741784</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>-45.833333</td>\n",
       "      <td>29.166667</td>\n",
       "      <td>-50.402653</td>\n",
       "      <td>-0.000917</td>\n",
       "      <td>4.889529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21 22:30:00</th>\n",
       "      <td>4.849</td>\n",
       "      <td>4.885</td>\n",
       "      <td>4.848</td>\n",
       "      <td>4.879</td>\n",
       "      <td>671.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.341199</td>\n",
       "      <td>26.658781</td>\n",
       "      <td>18.300860</td>\n",
       "      <td>70.833333</td>\n",
       "      <td>-45.833333</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>-31.879393</td>\n",
       "      <td>0.043042</td>\n",
       "      <td>4.888687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21 23:00:00</th>\n",
       "      <td>4.879</td>\n",
       "      <td>4.888</td>\n",
       "      <td>4.862</td>\n",
       "      <td>4.872</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.190593</td>\n",
       "      <td>25.918313</td>\n",
       "      <td>18.113029</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>-45.833333</td>\n",
       "      <td>20.833333</td>\n",
       "      <td>-26.149548</td>\n",
       "      <td>-0.006917</td>\n",
       "      <td>4.887352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21 23:30:00</th>\n",
       "      <td>4.872</td>\n",
       "      <td>4.873</td>\n",
       "      <td>4.849</td>\n",
       "      <td>4.855</td>\n",
       "      <td>409.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>21.155493</td>\n",
       "      <td>26.654375</td>\n",
       "      <td>17.641062</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>-45.833333</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>-34.438907</td>\n",
       "      <td>-0.007458</td>\n",
       "      <td>4.884764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8463 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Time Step                -1                                                  \\\n",
       "Time Series         NAT.GAS                                                   \n",
       "Feature                open   high    low  close tick_volume spread    year   \n",
       "time                                                                          \n",
       "2021-01-05 02:00:00   2.582  2.589  2.582  2.588       148.0  0.010  2021.0   \n",
       "2021-01-05 02:30:00   2.588  2.589  2.583  2.587       153.0  0.010  2021.0   \n",
       "2021-01-05 03:00:00   2.586  2.592  2.585  2.588       129.0  0.011  2021.0   \n",
       "2021-01-05 03:30:00   2.589  2.602  2.588  2.602       270.0  0.011  2021.0   \n",
       "2021-01-05 04:00:00   2.601  2.601  2.595  2.599       136.0  0.011  2021.0   \n",
       "...                     ...    ...    ...    ...         ...    ...     ...   \n",
       "2021-09-21 21:30:00   4.824  4.844  4.810  4.843      1570.0  0.008  2021.0   \n",
       "2021-09-21 22:00:00   4.843  4.864  4.840  4.849       799.0  0.005  2021.0   \n",
       "2021-09-21 22:30:00   4.849  4.885  4.848  4.879       671.0  0.005  2021.0   \n",
       "2021-09-21 23:00:00   4.879  4.888  4.862  4.872       679.0  0.005  2021.0   \n",
       "2021-09-21 23:30:00   4.872  4.873  4.849  4.855       409.0  0.010  2021.0   \n",
       "\n",
       "Time Step                                                              \\\n",
       "Time Series                                                             \n",
       "Feature             month   day dayofweek  hour        adx    adx_neg   \n",
       "time                                                                    \n",
       "2021-01-05 02:00:00   1.0   5.0       1.0   1.0  18.732942  22.124691   \n",
       "2021-01-05 02:30:00   1.0   5.0       1.0   2.0  18.538557  21.748555   \n",
       "2021-01-05 03:00:00   1.0   5.0       1.0   2.0  18.244230  21.307561   \n",
       "2021-01-05 03:30:00   1.0   5.0       1.0   3.0  17.621825  20.442495   \n",
       "2021-01-05 04:00:00   1.0   5.0       1.0   3.0  17.025352  20.018462   \n",
       "...                   ...   ...       ...   ...        ...        ...   \n",
       "2021-09-21 21:30:00   9.0  21.0       1.0  21.0  21.318925  28.456738   \n",
       "2021-09-21 22:00:00   9.0  21.0       1.0  21.0  21.460824  27.739579   \n",
       "2021-09-21 22:30:00   9.0  21.0       1.0  22.0  21.341199  26.658781   \n",
       "2021-09-21 23:00:00   9.0  21.0       1.0  22.0  21.190593  25.918313   \n",
       "2021-09-21 23:30:00   9.0  21.0       1.0  23.0  21.155493  26.654375   \n",
       "\n",
       "Time Step                                                              \\\n",
       "Time Series                                                             \n",
       "Feature                adx_pos aroon_down_24 aroon_ind_24 aroon_up_24   \n",
       "time                                                                    \n",
       "2021-01-05 02:00:00  16.667519     66.666667   -41.666667   25.000000   \n",
       "2021-01-05 02:30:00  16.384159     62.500000   -41.666667   20.833333   \n",
       "2021-01-05 03:00:00  16.920949     58.333333   -41.666667   16.666667   \n",
       "2021-01-05 03:30:00  19.133904     54.166667   -41.666667   12.500000   \n",
       "2021-01-05 04:00:00  18.737015     50.000000   -41.666667    8.333333   \n",
       "...                        ...           ...          ...         ...   \n",
       "2021-09-21 21:30:00  15.020175     79.166667   -45.833333   33.333333   \n",
       "2021-09-21 22:00:00  16.741784     75.000000   -45.833333   29.166667   \n",
       "2021-09-21 22:30:00  18.300860     70.833333   -45.833333   25.000000   \n",
       "2021-09-21 23:00:00  18.113029     66.666667   -45.833333   20.833333   \n",
       "2021-09-21 23:30:00  17.641062     62.500000   -45.833333   16.666667   \n",
       "\n",
       "Time Step                                           \n",
       "Time Series                                         \n",
       "Feature                    cci    dpo_24    ema_24  \n",
       "time                                                \n",
       "2021-01-05 02:00:00 -27.331487 -0.006958  2.590461  \n",
       "2021-01-05 02:30:00 -24.385511 -0.013083  2.590184  \n",
       "2021-01-05 03:00:00 -12.569691 -0.011458  2.590010  \n",
       "2021-01-05 03:30:00  29.306931 -0.013125  2.590969  \n",
       "2021-01-05 04:00:00  31.773597 -0.006375  2.591611  \n",
       "...                        ...       ...       ...  \n",
       "2021-09-21 21:30:00 -69.497198  0.053083  4.893054  \n",
       "2021-09-21 22:00:00 -50.402653 -0.000917  4.889529  \n",
       "2021-09-21 22:30:00 -31.879393  0.043042  4.888687  \n",
       "2021-09-21 23:00:00 -26.149548 -0.006917  4.887352  \n",
       "2021-09-21 23:30:00 -34.438907 -0.007458  4.884764  \n",
       "\n",
       "[8463 rows x 20 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dabba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "j = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c4e0cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "aColumns = pd.MultiIndex.from_tuples(\n",
    "    [(i,j)],\n",
    "    names = [\"From\",\"To\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bdfa0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOutput = pd.DataFrame(index = dfInput.index, \n",
    "                        columns = aColumns)\n",
    "\n",
    "    \n",
    "dfSpread = dfRates[sSymbol][\"spread\"]\n",
    "dfOpen = dfRates[sSymbol][\"open\"].shift(-i)\n",
    "dfClose = dfRates[sSymbol][\"close\"].shift(-j)\n",
    "\n",
    "dfNetReturn = (abs(dfClose - dfOpen) - dfSpread)\n",
    "dfReturn = (dfClose - dfOpen)/dfOpen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b58f09",
   "metadata": {},
   "source": [
    "# INVESTABILITY MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3db7ddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sModelName = os.path.join(sSymbol , \"__investability model__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "449e35ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sSubModelName = os.path.join(sModelName , \"__\"+ str(i) +\"  \" + str(j) + \"__\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575fa9d7",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c9f820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInputInvestability = dfInput.copy()\n",
    "dfOutputInvestability = dfOutput.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87e7d7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMaskNonInvestable = dfNetReturn<=0\n",
    "dfMaskInvestable = dfNetReturn>0\n",
    "\n",
    "dfOutputInvestability.loc[dfMaskNonInvestable] = 0\n",
    "dfOutputInvestability.loc[dfMaskInvestable] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "646509c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>From</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>To</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-05 02:00:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05 02:30:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05 03:00:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05 03:30:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05 04:00:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21 21:30:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21 22:00:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21 22:30:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21 23:00:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21 23:30:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8463 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "From                   1\n",
       "To                     3\n",
       "time                    \n",
       "2021-01-05 02:00:00    1\n",
       "2021-01-05 02:30:00    1\n",
       "2021-01-05 03:00:00    0\n",
       "2021-01-05 03:30:00    0\n",
       "2021-01-05 04:00:00    0\n",
       "...                  ...\n",
       "2021-09-21 21:30:00    1\n",
       "2021-09-21 22:00:00    1\n",
       "2021-09-21 22:30:00  NaN\n",
       "2021-09-21 23:00:00  NaN\n",
       "2021-09-21 23:30:00  NaN\n",
       "\n",
       "[8463 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfOutputInvestability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16787112",
   "metadata": {},
   "source": [
    "### Remove Empty Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e03e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aMissingOutputs = dfOutputInvestability[dfOutputInvestability.isna().any(axis=1)].index\n",
    "dfInputInvestability.drop(aMissingOutputs, inplace = True)\n",
    "dfOutputInvestability.drop(aMissingOutputs, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c2102f",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6154ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInputTrain, dfInputValidation, dfInputTest, dfOutputTrain, dfOutputValidation, dfOutputTest = dfSplitData(dfInputInvestability, \n",
    "                                                                                                            dfOutputInvestability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0d669c",
   "metadata": {},
   "source": [
    "### Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d506f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfScaledInputTrain, dfScaledInputValidation, dfScaledInputTest = dfScaleData(\"input\", dfInputTrain,dfInputValidation, dfInputTest )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6b9931",
   "metadata": {},
   "source": [
    "### Balance Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89f6c7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)\n",
       "0.0       3171\n",
       "1.0       1905\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfOutputTrain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53a4994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBalancedInputTrain , dfBalancedOutputTrain = dfOversampleImbalancedData(\n",
    "    dfScaledInputTrain,\n",
    "    dfOutputTrain)\n",
    "dfBalancedOutputTrain.columns = aColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9bfa3eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)\n",
       "0.0       3171\n",
       "1.0       3171\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBalancedOutputTrain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71839c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)\n",
       "0.0       1008\n",
       "1.0        684\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfOutputValidation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88179483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)\n",
       "1.0       871\n",
       "0.0       821\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfOutputTest.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d1128f",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ff3f1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "100/100 [==============================] - 4s 12ms/step - loss: 0.7857 - val_loss: 0.7964\n",
      "Epoch 2/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.7807 - val_loss: 0.7888\n",
      "Epoch 3/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.7761 - val_loss: 0.7816\n",
      "Epoch 4/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.7715 - val_loss: 0.7746\n",
      "Epoch 5/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.7668 - val_loss: 0.7683\n",
      "Epoch 6/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.7622 - val_loss: 0.7625\n",
      "Epoch 7/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.7575 - val_loss: 0.7572\n",
      "Epoch 8/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.7528 - val_loss: 0.7517\n",
      "Epoch 9/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.7480 - val_loss: 0.7466\n",
      "Epoch 10/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.7430 - val_loss: 0.7419\n",
      "Epoch 11/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.7379 - val_loss: 0.7371\n",
      "Epoch 12/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.7329 - val_loss: 0.7327\n",
      "Epoch 13/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.7277 - val_loss: 0.7285\n",
      "Epoch 14/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.7225 - val_loss: 0.7247\n",
      "Epoch 15/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.7173 - val_loss: 0.7212\n",
      "Epoch 16/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.7121 - val_loss: 0.7181\n",
      "Epoch 17/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.7071 - val_loss: 0.7154\n",
      "Epoch 18/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.7021 - val_loss: 0.7129\n",
      "Epoch 19/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6971 - val_loss: 0.7108\n",
      "Epoch 20/10000\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.6922 - val_loss: 0.7085\n",
      "Epoch 21/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6877 - val_loss: 0.7067\n",
      "Epoch 22/10000\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.6832 - val_loss: 0.7050\n",
      "Epoch 23/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6789 - val_loss: 0.7036\n",
      "Epoch 24/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6747 - val_loss: 0.7024\n",
      "Epoch 25/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6708 - val_loss: 0.7018\n",
      "Epoch 26/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6672 - val_loss: 0.7009\n",
      "Epoch 27/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6638 - val_loss: 0.7004\n",
      "Epoch 28/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6607 - val_loss: 0.6998\n",
      "Epoch 29/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6578 - val_loss: 0.6989\n",
      "Epoch 30/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6551 - val_loss: 0.6980\n",
      "Epoch 31/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6527 - val_loss: 0.6965\n",
      "Epoch 32/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6504 - val_loss: 0.6955\n",
      "Epoch 33/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6484 - val_loss: 0.6952\n",
      "Epoch 34/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6467 - val_loss: 0.6944\n",
      "Epoch 35/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6451 - val_loss: 0.6927\n",
      "Epoch 36/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6435 - val_loss: 0.6931\n",
      "Epoch 37/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6421 - val_loss: 0.6926\n",
      "Epoch 38/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6407 - val_loss: 0.6921\n",
      "Epoch 39/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6395 - val_loss: 0.6910\n",
      "Epoch 40/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6384 - val_loss: 0.6902\n",
      "Epoch 41/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6373 - val_loss: 0.6900\n",
      "Epoch 42/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6363 - val_loss: 0.6888\n",
      "Epoch 43/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6354 - val_loss: 0.6877\n",
      "Epoch 44/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6345 - val_loss: 0.6874\n",
      "Epoch 45/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6337 - val_loss: 0.6868\n",
      "Epoch 46/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6329 - val_loss: 0.6855\n",
      "Epoch 47/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6322 - val_loss: 0.6846\n",
      "Epoch 48/10000\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.6315 - val_loss: 0.6831\n",
      "Epoch 49/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6309 - val_loss: 0.6817\n",
      "Epoch 50/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6302 - val_loss: 0.6806\n",
      "Epoch 51/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6296 - val_loss: 0.6791\n",
      "Epoch 52/10000\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.6290 - val_loss: 0.6783\n",
      "Epoch 53/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6284 - val_loss: 0.6773\n",
      "Epoch 54/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6278 - val_loss: 0.6767\n",
      "Epoch 55/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6273 - val_loss: 0.6738\n",
      "Epoch 56/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6267 - val_loss: 0.6727\n",
      "Epoch 57/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6261 - val_loss: 0.6724\n",
      "Epoch 58/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6256 - val_loss: 0.6718\n",
      "Epoch 59/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6251 - val_loss: 0.6707\n",
      "Epoch 60/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6246 - val_loss: 0.6700\n",
      "Epoch 61/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6241 - val_loss: 0.6686\n",
      "Epoch 62/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6236 - val_loss: 0.6670\n",
      "Epoch 63/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6231 - val_loss: 0.6666\n",
      "Epoch 64/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6226 - val_loss: 0.6655\n",
      "Epoch 65/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6222 - val_loss: 0.6642\n",
      "Epoch 66/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6217 - val_loss: 0.6634\n",
      "Epoch 67/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6212 - val_loss: 0.6621\n",
      "Epoch 68/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6208 - val_loss: 0.6613\n",
      "Epoch 69/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6203 - val_loss: 0.6604\n",
      "Epoch 70/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6199 - val_loss: 0.6592\n",
      "Epoch 71/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6194 - val_loss: 0.6586\n",
      "Epoch 72/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6189 - val_loss: 0.6583\n",
      "Epoch 73/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6185 - val_loss: 0.6578\n",
      "Epoch 74/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6181 - val_loss: 0.6570\n",
      "Epoch 75/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6176 - val_loss: 0.6561\n",
      "Epoch 76/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6172 - val_loss: 0.6554\n",
      "Epoch 77/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6167 - val_loss: 0.6544\n",
      "Epoch 78/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6163 - val_loss: 0.6537\n",
      "Epoch 79/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6159 - val_loss: 0.6529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6155 - val_loss: 0.6523\n",
      "Epoch 81/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6150 - val_loss: 0.6514\n",
      "Epoch 82/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6146 - val_loss: 0.6509\n",
      "Epoch 83/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6142 - val_loss: 0.6505\n",
      "Epoch 84/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6138 - val_loss: 0.6500\n",
      "Epoch 85/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6134 - val_loss: 0.6498\n",
      "Epoch 86/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6130 - val_loss: 0.6493\n",
      "Epoch 87/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6126 - val_loss: 0.6485\n",
      "Epoch 88/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6122 - val_loss: 0.6479\n",
      "Epoch 89/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6118 - val_loss: 0.6474\n",
      "Epoch 90/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6114 - val_loss: 0.6470\n",
      "Epoch 91/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6110 - val_loss: 0.6467\n",
      "Epoch 92/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6106 - val_loss: 0.6463\n",
      "Epoch 93/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6102 - val_loss: 0.6460\n",
      "Epoch 94/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6098 - val_loss: 0.6457\n",
      "Epoch 95/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6094 - val_loss: 0.6455\n",
      "Epoch 96/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6090 - val_loss: 0.6452\n",
      "Epoch 97/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6086 - val_loss: 0.6450\n",
      "Epoch 98/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6083 - val_loss: 0.6447\n",
      "Epoch 99/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6079 - val_loss: 0.6444\n",
      "Epoch 100/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6075 - val_loss: 0.6442\n",
      "Epoch 101/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6071 - val_loss: 0.6441\n",
      "Epoch 102/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6067 - val_loss: 0.6438\n",
      "Epoch 103/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6063 - val_loss: 0.6436\n",
      "Epoch 104/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6060 - val_loss: 0.6436\n",
      "Epoch 105/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6056 - val_loss: 0.6433\n",
      "Epoch 106/10000\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.6052 - val_loss: 0.6432\n",
      "Epoch 107/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6048 - val_loss: 0.6431\n",
      "Epoch 108/10000\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.6045 - val_loss: 0.6431\n",
      "Epoch 109/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6041 - val_loss: 0.6430\n",
      "Epoch 110/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6038 - val_loss: 0.6428\n",
      "Epoch 111/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6034 - val_loss: 0.6430\n",
      "Epoch 112/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6030 - val_loss: 0.6431\n",
      "Epoch 113/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6027 - val_loss: 0.6432\n",
      "Epoch 114/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6023 - val_loss: 0.6435\n",
      "Epoch 115/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6020 - val_loss: 0.6440\n",
      "Epoch 116/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6016 - val_loss: 0.6436\n",
      "Epoch 117/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6012 - val_loss: 0.6436\n",
      "Epoch 118/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6009 - val_loss: 0.6438\n",
      "Epoch 119/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6005 - val_loss: 0.6439\n",
      "Epoch 120/10000\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6002 - val_loss: 0.6441\n",
      "Epoch 121/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.5998 - val_loss: 0.6445\n",
      "Epoch 122/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.5995 - val_loss: 0.6443\n",
      "Epoch 123/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.5991 - val_loss: 0.6444\n",
      "Epoch 124/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.5988 - val_loss: 0.6444\n",
      "Epoch 125/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.5984 - val_loss: 0.6451\n",
      "Epoch 126/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.5981 - val_loss: 0.6451\n",
      "Epoch 127/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.5978 - val_loss: 0.6450\n",
      "Epoch 128/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.5974 - val_loss: 0.6455\n",
      "Epoch 129/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.5971 - val_loss: 0.6455\n",
      "Epoch 130/10000\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.5967 - val_loss: 0.6452\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "oPredictiveModel = Long_Short_Term_Memory(\n",
    "    sSubModelName, \n",
    "    dfScaledInputTrain.shape[1], \n",
    "    1,\n",
    "    len(g_aBackwardTimeSteps), \n",
    "    1\n",
    "    )\n",
    "\n",
    "oPredictiveModel.Train(dfBalancedInputTrain, \n",
    "                       dfBalancedOutputTrain,\n",
    "                       dfScaledInputValidation,\n",
    "                       dfOutputValidation\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3389a00a",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1105a7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "aPredictionProb, _ = oPredictiveModel.aPredict(dfScaledInputTest)\n",
    "\n",
    "aPrediction = aPredictionProb.round()\n",
    "\n",
    "dfPrediction = pd.DataFrame(aPrediction, index = dfInputTest.index)\n",
    "dfPrediction.columns = aColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d895dc3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)\n",
       "1.0       1240\n",
       "0.0        452\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPrediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09d189d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.42      0.54       821\n",
      "         1.0       0.61      0.87      0.72       871\n",
      "\n",
      "    accuracy                           0.65      1692\n",
      "   macro avg       0.68      0.64      0.63      1692\n",
      "weighted avg       0.68      0.65      0.63      1692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(dfOutputTest, dfPrediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1edcb31",
   "metadata": {},
   "source": [
    "# DIRECTIONAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6fabc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sModelName = os.path.join(sSymbol , \"__directional model__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "294a054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sSubModelName = os.path.join(sModelName , \"__\"+ str(i) +\"  \" + str(j) + \"__\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2850b94",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38436612",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInputDirectional = dfInput.copy()\n",
    "dfOutputDirectional = dfOutput.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f4d1205",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMaskUpward = dfClose>dfOpen\n",
    "dfMaskDownward = dfClose<dfOpen \n",
    "\n",
    "dfOutputDirectional.loc[(dfMaskInvestable) & (dfMaskDownward)] = 0\n",
    "dfOutputDirectional.loc[(dfMaskInvestable) & (dfMaskUpward)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7446b2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>From</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>To</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-05 02:00:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05 02:30:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05 03:00:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05 03:30:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05 04:00:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21 21:30:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21 22:00:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21 22:30:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21 23:00:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21 23:30:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8463 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "From                   1\n",
       "To                     3\n",
       "time                    \n",
       "2021-01-05 02:00:00    1\n",
       "2021-01-05 02:30:00    1\n",
       "2021-01-05 03:00:00  NaN\n",
       "2021-01-05 03:30:00  NaN\n",
       "2021-01-05 04:00:00  NaN\n",
       "...                  ...\n",
       "2021-09-21 21:30:00    1\n",
       "2021-09-21 22:00:00    0\n",
       "2021-09-21 22:30:00  NaN\n",
       "2021-09-21 23:00:00  NaN\n",
       "2021-09-21 23:30:00  NaN\n",
       "\n",
       "[8463 rows x 1 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfOutputDirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e02677",
   "metadata": {},
   "source": [
    "### Remove Empty Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "016840c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aMissingOutputs = dfOutputDirectional[dfOutputDirectional.isna().any(axis=1)].index\n",
    "dfInputDirectional.drop(aMissingOutputs, inplace = True)\n",
    "dfOutputDirectional.drop(aMissingOutputs, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9cd8c1",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e7857648",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInputTrain, dfInputValidation, dfInputTest, dfOutputTrain, dfOutputValidation, dfOutputTest = dfSplitData(dfInputDirectional, \n",
    "                                                                                                            dfOutputDirectional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d867c265",
   "metadata": {},
   "source": [
    "### Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "38a247ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfScaledInputTrain, dfScaledInputValidation, dfScaledInputTest = dfScaleData(\"input\", dfInputTrain,dfInputValidation, dfInputTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d9f864",
   "metadata": {},
   "source": [
    "### Balance Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f0a0894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)\n",
       "1.0       1073\n",
       "0.0       1003\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfOutputTrain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "54d54711",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBalancedInputTrain , dfBalancedOutputTrain = dfOversampleImbalancedData(\n",
    "    dfScaledInputTrain,\n",
    "    dfOutputTrain)\n",
    "dfBalancedOutputTrain.columns = aColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1d7d92a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)\n",
       "0.0       1073\n",
       "1.0       1073\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBalancedOutputTrain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7cb2e5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)\n",
       "1.0       371\n",
       "0.0       321\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfOutputValidation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f6e7f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)\n",
       "1.0       382\n",
       "0.0       310\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfOutputTest.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd272c43",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aadc49b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "34/34 [==============================] - 3s 21ms/step - loss: 0.7844 - val_loss: 0.8100\n",
      "Epoch 2/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7841 - val_loss: 0.8101\n",
      "Epoch 3/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7838 - val_loss: 0.8100\n",
      "Epoch 4/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7835 - val_loss: 0.8098\n",
      "Epoch 5/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7832 - val_loss: 0.8098\n",
      "Epoch 6/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7829 - val_loss: 0.8096\n",
      "Epoch 7/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7826 - val_loss: 0.8096\n",
      "Epoch 8/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7823 - val_loss: 0.8095\n",
      "Epoch 9/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7820 - val_loss: 0.8095\n",
      "Epoch 10/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7817 - val_loss: 0.8094\n",
      "Epoch 11/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7815 - val_loss: 0.8092\n",
      "Epoch 12/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7812 - val_loss: 0.8092\n",
      "Epoch 13/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7809 - val_loss: 0.8091\n",
      "Epoch 14/10000\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.7807 - val_loss: 0.8091\n",
      "Epoch 15/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7804 - val_loss: 0.8089\n",
      "Epoch 16/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7801 - val_loss: 0.8089\n",
      "Epoch 17/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7799 - val_loss: 0.8089\n",
      "Epoch 18/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7796 - val_loss: 0.8089\n",
      "Epoch 19/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7794 - val_loss: 0.8088\n",
      "Epoch 20/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7791 - val_loss: 0.8085\n",
      "Epoch 21/10000\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.7789 - val_loss: 0.8085\n",
      "Epoch 22/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7786 - val_loss: 0.8085\n",
      "Epoch 23/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7784 - val_loss: 0.8083\n",
      "Epoch 24/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7781 - val_loss: 0.8081\n",
      "Epoch 25/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7779 - val_loss: 0.8079\n",
      "Epoch 26/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7777 - val_loss: 0.8076\n",
      "Epoch 27/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7774 - val_loss: 0.8076\n",
      "Epoch 28/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7772 - val_loss: 0.8075\n",
      "Epoch 29/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7770 - val_loss: 0.8074\n",
      "Epoch 30/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7767 - val_loss: 0.8072\n",
      "Epoch 31/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7765 - val_loss: 0.8071\n",
      "Epoch 32/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7763 - val_loss: 0.8070\n",
      "Epoch 33/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7760 - val_loss: 0.8070\n",
      "Epoch 34/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7758 - val_loss: 0.8068\n",
      "Epoch 35/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7756 - val_loss: 0.8067\n",
      "Epoch 36/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7754 - val_loss: 0.8066\n",
      "Epoch 37/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7751 - val_loss: 0.8065\n",
      "Epoch 38/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7749 - val_loss: 0.8064\n",
      "Epoch 39/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7747 - val_loss: 0.8063\n",
      "Epoch 40/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7745 - val_loss: 0.8060\n",
      "Epoch 41/10000\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.7743 - val_loss: 0.8059\n",
      "Epoch 42/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7741 - val_loss: 0.8057\n",
      "Epoch 43/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7738 - val_loss: 0.8056\n",
      "Epoch 44/10000\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.7736 - val_loss: 0.8056\n",
      "Epoch 45/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7734 - val_loss: 0.8054\n",
      "Epoch 46/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7732 - val_loss: 0.8053\n",
      "Epoch 47/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7730 - val_loss: 0.8052\n",
      "Epoch 48/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7728 - val_loss: 0.8051\n",
      "Epoch 49/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7726 - val_loss: 0.8051\n",
      "Epoch 50/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7724 - val_loss: 0.8051\n",
      "Epoch 51/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7722 - val_loss: 0.8050\n",
      "Epoch 52/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7720 - val_loss: 0.8048\n",
      "Epoch 53/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7718 - val_loss: 0.8048\n",
      "Epoch 54/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7715 - val_loss: 0.8048\n",
      "Epoch 55/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7713 - val_loss: 0.8047\n",
      "Epoch 56/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7711 - val_loss: 0.8047\n",
      "Epoch 57/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7709 - val_loss: 0.8046\n",
      "Epoch 58/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7707 - val_loss: 0.8045\n",
      "Epoch 59/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7705 - val_loss: 0.8045\n",
      "Epoch 60/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7703 - val_loss: 0.8044\n",
      "Epoch 61/10000\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.7702 - val_loss: 0.8042\n",
      "Epoch 62/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7700 - val_loss: 0.8041\n",
      "Epoch 63/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7698 - val_loss: 0.8040\n",
      "Epoch 64/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7696 - val_loss: 0.8039\n",
      "Epoch 65/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7694 - val_loss: 0.8038\n",
      "Epoch 66/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7692 - val_loss: 0.8037\n",
      "Epoch 67/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7690 - val_loss: 0.8036\n",
      "Epoch 68/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7688 - val_loss: 0.8033\n",
      "Epoch 69/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7686 - val_loss: 0.8033\n",
      "Epoch 70/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7684 - val_loss: 0.8031\n",
      "Epoch 71/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7682 - val_loss: 0.8029\n",
      "Epoch 72/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7680 - val_loss: 0.8028\n",
      "Epoch 73/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7678 - val_loss: 0.8028\n",
      "Epoch 74/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7676 - val_loss: 0.8027\n",
      "Epoch 75/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7674 - val_loss: 0.8026\n",
      "Epoch 76/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7672 - val_loss: 0.8025\n",
      "Epoch 77/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7670 - val_loss: 0.8024\n",
      "Epoch 78/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7669 - val_loss: 0.8024\n",
      "Epoch 79/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7667 - val_loss: 0.8024\n",
      "Epoch 80/10000\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.7665 - val_loss: 0.8024\n",
      "Epoch 81/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 10ms/step - loss: 0.7663 - val_loss: 0.8024\n",
      "Epoch 82/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7661 - val_loss: 0.8022\n",
      "Epoch 83/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7659 - val_loss: 0.8022\n",
      "Epoch 84/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7658 - val_loss: 0.8021\n",
      "Epoch 85/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7656 - val_loss: 0.8020\n",
      "Epoch 86/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7654 - val_loss: 0.8018\n",
      "Epoch 87/10000\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.7652 - val_loss: 0.8017\n",
      "Epoch 88/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7650 - val_loss: 0.8017\n",
      "Epoch 89/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7648 - val_loss: 0.8016\n",
      "Epoch 90/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7646 - val_loss: 0.8015\n",
      "Epoch 91/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7645 - val_loss: 0.8013\n",
      "Epoch 92/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7643 - val_loss: 0.8013\n",
      "Epoch 93/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7641 - val_loss: 0.8012\n",
      "Epoch 94/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7639 - val_loss: 0.8011\n",
      "Epoch 95/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7638 - val_loss: 0.8010\n",
      "Epoch 96/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7636 - val_loss: 0.8009\n",
      "Epoch 97/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7634 - val_loss: 0.8008\n",
      "Epoch 98/10000\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.7632 - val_loss: 0.8007\n",
      "Epoch 99/10000\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.7630 - val_loss: 0.8005\n",
      "Epoch 100/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7629 - val_loss: 0.8004\n",
      "Epoch 101/10000\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.7627 - val_loss: 0.8003\n",
      "Epoch 102/10000\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.7625 - val_loss: 0.8003\n",
      "Epoch 103/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7623 - val_loss: 0.8001\n",
      "Epoch 104/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7622 - val_loss: 0.8000\n",
      "Epoch 105/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7620 - val_loss: 0.8000\n",
      "Epoch 106/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7618 - val_loss: 0.7999\n",
      "Epoch 107/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7616 - val_loss: 0.7998\n",
      "Epoch 108/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7615 - val_loss: 0.7997\n",
      "Epoch 109/10000\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.7613 - val_loss: 0.7996\n",
      "Epoch 110/10000\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.7611 - val_loss: 0.7995\n",
      "Epoch 111/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7609 - val_loss: 0.7995\n",
      "Epoch 112/10000\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.7608 - val_loss: 0.7993\n",
      "Epoch 113/10000\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.7606 - val_loss: 0.7993\n",
      "Epoch 114/10000\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.7604 - val_loss: 0.7992\n",
      "Epoch 115/10000\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.7602 - val_loss: 0.7991\n",
      "Epoch 116/10000\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.7601 - val_loss: 0.7991\n",
      "Epoch 117/10000\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.7599 - val_loss: 0.7992\n",
      "Epoch 118/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7597 - val_loss: 0.7991\n",
      "Epoch 119/10000\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.7596 - val_loss: 0.7989\n",
      "Epoch 120/10000\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.7594 - val_loss: 0.7990\n",
      "Epoch 121/10000\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.7592 - val_loss: 0.7989\n",
      "Epoch 122/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7591 - val_loss: 0.7989\n",
      "Epoch 123/10000\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.7589 - val_loss: 0.7988\n",
      "Epoch 124/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7587 - val_loss: 0.7987\n",
      "Epoch 125/10000\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.7586 - val_loss: 0.7987\n",
      "Epoch 126/10000\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.7584 - val_loss: 0.7986\n",
      "Epoch 127/10000\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.7582 - val_loss: 0.7986\n",
      "Epoch 128/10000\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.7581 - val_loss: 0.7986\n",
      "Epoch 129/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7579 - val_loss: 0.7985\n",
      "Epoch 130/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7577 - val_loss: 0.7985\n",
      "Epoch 131/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7576 - val_loss: 0.7984\n",
      "Epoch 132/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7574 - val_loss: 0.7984\n",
      "Epoch 133/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7572 - val_loss: 0.7983\n",
      "Epoch 134/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7571 - val_loss: 0.7983\n",
      "Epoch 135/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7569 - val_loss: 0.7983\n",
      "Epoch 136/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7568 - val_loss: 0.7982\n",
      "Epoch 137/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7566 - val_loss: 0.7982\n",
      "Epoch 138/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7564 - val_loss: 0.7981\n",
      "Epoch 139/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7563 - val_loss: 0.7980\n",
      "Epoch 140/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7561 - val_loss: 0.7980\n",
      "Epoch 141/10000\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.7559 - val_loss: 0.7979\n",
      "Epoch 142/10000\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.7558 - val_loss: 0.7980\n",
      "Epoch 143/10000\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.7556 - val_loss: 0.7979\n",
      "Epoch 144/10000\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.7555 - val_loss: 0.7978\n",
      "Epoch 145/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7553 - val_loss: 0.7978\n",
      "Epoch 146/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7551 - val_loss: 0.7980\n",
      "Epoch 147/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7550 - val_loss: 0.7980\n",
      "Epoch 148/10000\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.7548 - val_loss: 0.7979\n",
      "Epoch 149/10000\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.7547 - val_loss: 0.7978\n",
      "Epoch 150/10000\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.7545 - val_loss: 0.7976\n",
      "Epoch 151/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7543 - val_loss: 0.7975\n",
      "Epoch 152/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7542 - val_loss: 0.7975\n",
      "Epoch 153/10000\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.7540 - val_loss: 0.7974\n",
      "Epoch 154/10000\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.7539 - val_loss: 0.7974\n",
      "Epoch 155/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7537 - val_loss: 0.7974\n",
      "Epoch 156/10000\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.7536 - val_loss: 0.7975\n",
      "Epoch 157/10000\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.7534 - val_loss: 0.7976\n",
      "Epoch 158/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7532 - val_loss: 0.7976\n",
      "Epoch 159/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7531 - val_loss: 0.7978\n",
      "Epoch 160/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7529 - val_loss: 0.7978\n",
      "Epoch 161/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7528 - val_loss: 0.7978\n",
      "Epoch 162/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7526 - val_loss: 0.7977\n",
      "Epoch 163/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7525 - val_loss: 0.7977\n",
      "Epoch 164/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7523 - val_loss: 0.7976\n",
      "Epoch 165/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7522 - val_loss: 0.7976\n",
      "Epoch 166/10000\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.7520 - val_loss: 0.7975\n",
      "Epoch 167/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7519 - val_loss: 0.7974\n",
      "Epoch 168/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7517 - val_loss: 0.7973\n",
      "Epoch 169/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7516 - val_loss: 0.7972\n",
      "Epoch 170/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7514 - val_loss: 0.7973\n",
      "Epoch 171/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7513 - val_loss: 0.7973\n",
      "Epoch 172/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7511 - val_loss: 0.7972\n",
      "Epoch 173/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7510 - val_loss: 0.7971\n",
      "Epoch 174/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7508 - val_loss: 0.7973\n",
      "Epoch 175/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7507 - val_loss: 0.7974\n",
      "Epoch 176/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7505 - val_loss: 0.7975\n",
      "Epoch 177/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7504 - val_loss: 0.7976\n",
      "Epoch 178/10000\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.7502 - val_loss: 0.7976\n",
      "Epoch 179/10000\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.7501 - val_loss: 0.7977\n",
      "Epoch 180/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7499 - val_loss: 0.7976\n",
      "Epoch 181/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7498 - val_loss: 0.7975\n",
      "Epoch 182/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7496 - val_loss: 0.7976\n",
      "Epoch 183/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7495 - val_loss: 0.7976\n",
      "Epoch 184/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7493 - val_loss: 0.7975\n",
      "Epoch 185/10000\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.7492 - val_loss: 0.7973\n",
      "Epoch 186/10000\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.7490 - val_loss: 0.7972\n",
      "Epoch 187/10000\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.7489 - val_loss: 0.7971\n",
      "Epoch 188/10000\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.7487 - val_loss: 0.7970\n",
      "Epoch 189/10000\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.7486 - val_loss: 0.7969\n",
      "Epoch 190/10000\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.7484 - val_loss: 0.7969\n",
      "Epoch 191/10000\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.7483 - val_loss: 0.7969\n",
      "Epoch 192/10000\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.7481 - val_loss: 0.7968\n",
      "Epoch 193/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7480 - val_loss: 0.7967\n",
      "Epoch 194/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7478 - val_loss: 0.7966\n",
      "Epoch 195/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7477 - val_loss: 0.7965\n",
      "Epoch 196/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7476 - val_loss: 0.7964\n",
      "Epoch 197/10000\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.7474 - val_loss: 0.7962\n",
      "Epoch 198/10000\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.7473 - val_loss: 0.7961\n",
      "Epoch 199/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7471 - val_loss: 0.7961\n",
      "Epoch 200/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7470 - val_loss: 0.7961\n",
      "Epoch 201/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7468 - val_loss: 0.7962\n",
      "Epoch 202/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7467 - val_loss: 0.7963\n",
      "Epoch 203/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7465 - val_loss: 0.7966\n",
      "Epoch 204/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7464 - val_loss: 0.7966\n",
      "Epoch 205/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7463 - val_loss: 0.7967\n",
      "Epoch 206/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7461 - val_loss: 0.7967\n",
      "Epoch 207/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7460 - val_loss: 0.7967\n",
      "Epoch 208/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7458 - val_loss: 0.7966\n",
      "Epoch 209/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7457 - val_loss: 0.7966\n",
      "Epoch 210/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7456 - val_loss: 0.7967\n",
      "Epoch 211/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7454 - val_loss: 0.7967\n",
      "Epoch 212/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7453 - val_loss: 0.7968\n",
      "Epoch 213/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7451 - val_loss: 0.7968\n",
      "Epoch 214/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7450 - val_loss: 0.7968\n",
      "Epoch 215/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7449 - val_loss: 0.7968\n",
      "Epoch 216/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7447 - val_loss: 0.7968\n",
      "Epoch 217/10000\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.7446 - val_loss: 0.7968\n",
      "Epoch 218/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7444 - val_loss: 0.7969\n",
      "Epoch 219/10000\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.7443 - val_loss: 0.7970\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "oPredictiveModel = Long_Short_Term_Memory(\n",
    "    sSubModelName, \n",
    "    dfScaledInputTrain.shape[1], \n",
    "    1,\n",
    "    len(g_aBackwardTimeSteps), \n",
    "    1\n",
    "    )\n",
    "\n",
    "oPredictiveModel.Train(dfBalancedInputTrain, \n",
    "                       dfBalancedOutputTrain,\n",
    "                       dfScaledInputValidation,\n",
    "                       dfOutputValidation\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988c117a",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "862e6cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aPredictionProb, _ = oPredictiveModel.aPredict(dfScaledInputTest)\n",
    "\n",
    "aPrediction = aPredictionProb.round()\n",
    "\n",
    "dfPrediction = pd.DataFrame(aPrediction, index = dfInputTest.index)\n",
    "dfPrediction.columns = aColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "26914599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)\n",
       "0.0       692\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPrediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7936f2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      1.00      0.62       310\n",
      "         1.0       0.00      0.00      0.00       382\n",
      "\n",
      "    accuracy                           0.45       692\n",
      "   macro avg       0.22      0.50      0.31       692\n",
      "weighted avg       0.20      0.45      0.28       692\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yunus\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yunus\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yunus\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(dfOutputTest, dfPrediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc84d4e1",
   "metadata": {},
   "source": [
    "# UPWARD REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "404f4f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sModelName = os.path.join(sSymbol , \"__upward regression model__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ae829f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "sSubModelName = os.path.join(sModelName , \"__\"+ str(i) +\"  \" + str(j) + \"__\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6be5a7",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fee2856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInputUpward = dfInput.copy()\n",
    "dfOutputUpward = dfOutput.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "20724947",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfOutputUpward.loc[dfMaskInvestable & dfMaskUpward, i] = dfReturn.loc[dfOutputUpward.index].loc[dfMaskInvestable & dfMaskUpward].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0912ca0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>From</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>To</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-05 02:00:00</th>\n",
       "      <td>0.005027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05 02:30:00</th>\n",
       "      <td>0.004635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05 03:00:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05 03:30:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05 04:00:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21 21:30:00</th>\n",
       "      <td>0.001237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21 22:00:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21 22:30:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21 23:00:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21 23:30:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8463 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "From                        1\n",
       "To                          3\n",
       "time                         \n",
       "2021-01-05 02:00:00  0.005027\n",
       "2021-01-05 02:30:00  0.004635\n",
       "2021-01-05 03:00:00       NaN\n",
       "2021-01-05 03:30:00       NaN\n",
       "2021-01-05 04:00:00       NaN\n",
       "...                       ...\n",
       "2021-09-21 21:30:00  0.001237\n",
       "2021-09-21 22:00:00       NaN\n",
       "2021-09-21 22:30:00       NaN\n",
       "2021-09-21 23:00:00       NaN\n",
       "2021-09-21 23:30:00       NaN\n",
       "\n",
       "[8463 rows x 1 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfOutputUpward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e910b5a",
   "metadata": {},
   "source": [
    "### Remove Empty Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "33b3bea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "aMissingOutputs = dfOutputUpward[dfOutputUpward.isna().any(axis=1)].index\n",
    "dfInputUpward.drop(aMissingOutputs, inplace = True)\n",
    "dfOutputUpward.drop(aMissingOutputs, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dd4001",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "39c8ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInputTrain, dfInputValidation, dfInputTest, dfOutputTrain, dfOutputValidation, dfOutputTest = dfSplitData(dfInputUpward, \n",
    "                                                                                                            dfOutputUpward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de994de3",
   "metadata": {},
   "source": [
    "### Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "132ea6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfScaledInputTrain, dfScaledInputValidation, dfScaledInputTest = dfScaleData(\"input\", dfInputTrain,dfInputValidation, dfInputTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a81094d",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eb7719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "18/18 [==============================] - 3s 41ms/step - loss: 0.1270 - val_loss: 0.7213\n",
      "Epoch 2/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1241 - val_loss: 0.6776\n",
      "Epoch 3/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1215 - val_loss: 0.6379\n",
      "Epoch 4/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1190 - val_loss: 0.5968\n",
      "Epoch 5/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1166 - val_loss: 0.5613\n",
      "Epoch 6/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1145 - val_loss: 0.5296\n",
      "Epoch 7/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1125 - val_loss: 0.4992\n",
      "Epoch 8/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1107 - val_loss: 0.4710\n",
      "Epoch 9/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1089 - val_loss: 0.4450\n",
      "Epoch 10/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1073 - val_loss: 0.4205\n",
      "Epoch 11/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1059 - val_loss: 0.3959\n",
      "Epoch 12/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1044 - val_loss: 0.3737\n",
      "Epoch 13/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1031 - val_loss: 0.3526\n",
      "Epoch 14/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1019 - val_loss: 0.3343\n",
      "Epoch 15/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1008 - val_loss: 0.3163\n",
      "Epoch 16/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0997 - val_loss: 0.3002\n",
      "Epoch 17/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0988 - val_loss: 0.2848\n",
      "Epoch 18/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0979 - val_loss: 0.2705\n",
      "Epoch 19/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0971 - val_loss: 0.2573\n",
      "Epoch 20/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0963 - val_loss: 0.2452\n",
      "Epoch 21/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0956 - val_loss: 0.2331\n",
      "Epoch 22/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0949 - val_loss: 0.2213\n",
      "Epoch 23/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0943 - val_loss: 0.2105\n",
      "Epoch 24/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0937 - val_loss: 0.2020\n",
      "Epoch 25/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0932 - val_loss: 0.1940\n",
      "Epoch 26/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0927 - val_loss: 0.1867\n",
      "Epoch 27/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0923 - val_loss: 0.1797\n",
      "Epoch 28/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0918 - val_loss: 0.1728\n",
      "Epoch 29/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0915 - val_loss: 0.1669\n",
      "Epoch 30/10000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0911 - val_loss: 0.1616\n",
      "Epoch 31/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0908 - val_loss: 0.1564\n",
      "Epoch 32/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0905 - val_loss: 0.1519\n",
      "Epoch 33/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0902 - val_loss: 0.1478\n",
      "Epoch 34/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0899 - val_loss: 0.1439\n",
      "Epoch 35/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0896 - val_loss: 0.1400\n",
      "Epoch 36/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0894 - val_loss: 0.1365\n",
      "Epoch 37/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0891 - val_loss: 0.1333\n",
      "Epoch 38/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0889 - val_loss: 0.1303\n",
      "Epoch 39/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0887 - val_loss: 0.1276\n",
      "Epoch 40/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0885 - val_loss: 0.1253\n",
      "Epoch 41/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0883 - val_loss: 0.1231\n",
      "Epoch 42/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0881 - val_loss: 0.1210\n",
      "Epoch 43/10000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0879 - val_loss: 0.1191\n",
      "Epoch 44/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0878 - val_loss: 0.1173\n",
      "Epoch 45/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0876 - val_loss: 0.1156\n",
      "Epoch 46/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0874 - val_loss: 0.1142\n",
      "Epoch 47/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0873 - val_loss: 0.1128\n",
      "Epoch 48/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0871 - val_loss: 0.1116\n",
      "Epoch 49/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0870 - val_loss: 0.1103\n",
      "Epoch 50/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0868 - val_loss: 0.1089\n",
      "Epoch 51/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0867 - val_loss: 0.1077\n",
      "Epoch 52/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0865 - val_loss: 0.1068\n",
      "Epoch 53/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0864 - val_loss: 0.1059\n",
      "Epoch 54/10000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0863 - val_loss: 0.1050\n",
      "Epoch 55/10000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0861 - val_loss: 0.1041\n",
      "Epoch 56/10000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0860 - val_loss: 0.1034\n",
      "Epoch 57/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0859 - val_loss: 0.1027\n",
      "Epoch 58/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0857 - val_loss: 0.1018\n",
      "Epoch 59/10000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0856 - val_loss: 0.1012\n",
      "Epoch 60/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0855 - val_loss: 0.1005\n",
      "Epoch 61/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0853 - val_loss: 0.1000\n",
      "Epoch 62/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0852 - val_loss: 0.0994\n",
      "Epoch 63/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0851 - val_loss: 0.0989\n",
      "Epoch 64/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0849 - val_loss: 0.0984\n",
      "Epoch 65/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0848 - val_loss: 0.0980\n",
      "Epoch 66/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0847 - val_loss: 0.0975\n",
      "Epoch 67/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0846 - val_loss: 0.0971\n",
      "Epoch 68/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0844 - val_loss: 0.0967\n",
      "Epoch 69/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0843 - val_loss: 0.0963\n",
      "Epoch 70/10000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0842 - val_loss: 0.0957\n",
      "Epoch 71/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0841 - val_loss: 0.0954\n",
      "Epoch 72/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0839 - val_loss: 0.0952\n",
      "Epoch 73/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0838 - val_loss: 0.0948\n",
      "Epoch 74/10000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0837 - val_loss: 0.0944\n",
      "Epoch 75/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0836 - val_loss: 0.0942\n",
      "Epoch 76/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0835 - val_loss: 0.0940\n",
      "Epoch 77/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0833 - val_loss: 0.0937\n",
      "Epoch 78/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0832 - val_loss: 0.0933\n",
      "Epoch 79/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0831 - val_loss: 0.0929\n",
      "Epoch 80/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0830 - val_loss: 0.0927\n",
      "Epoch 81/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0829 - val_loss: 0.0924\n",
      "Epoch 82/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0827 - val_loss: 0.0920\n",
      "Epoch 83/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0826 - val_loss: 0.0917\n",
      "Epoch 84/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0825 - val_loss: 0.0915\n",
      "Epoch 85/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0824 - val_loss: 0.0912\n",
      "Epoch 86/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0823 - val_loss: 0.0909\n",
      "Epoch 87/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0821 - val_loss: 0.0906\n",
      "Epoch 88/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0820 - val_loss: 0.0904\n",
      "Epoch 89/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0819 - val_loss: 0.0902\n",
      "Epoch 90/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0818 - val_loss: 0.0900\n",
      "Epoch 91/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0817 - val_loss: 0.0897\n",
      "Epoch 92/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0816 - val_loss: 0.0895\n",
      "Epoch 93/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0814 - val_loss: 0.0893\n",
      "Epoch 94/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0813 - val_loss: 0.0890\n",
      "Epoch 95/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0812 - val_loss: 0.0888\n",
      "Epoch 96/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0811 - val_loss: 0.0886\n",
      "Epoch 97/10000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0810 - val_loss: 0.0883\n",
      "Epoch 98/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0808 - val_loss: 0.0881\n",
      "Epoch 99/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0807 - val_loss: 0.0879\n",
      "Epoch 100/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0806 - val_loss: 0.0877\n",
      "Epoch 101/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0805 - val_loss: 0.0875\n",
      "Epoch 102/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0804 - val_loss: 0.0873\n",
      "Epoch 103/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0803 - val_loss: 0.0871\n",
      "Epoch 104/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0801 - val_loss: 0.0869\n",
      "Epoch 105/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0800 - val_loss: 0.0867\n",
      "Epoch 106/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0799 - val_loss: 0.0865\n",
      "Epoch 107/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0798 - val_loss: 0.0863\n",
      "Epoch 108/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0797 - val_loss: 0.0861\n",
      "Epoch 109/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0795 - val_loss: 0.0858\n",
      "Epoch 110/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0794 - val_loss: 0.0856\n",
      "Epoch 111/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0793 - val_loss: 0.0854\n",
      "Epoch 112/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0792 - val_loss: 0.0853\n",
      "Epoch 113/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0791 - val_loss: 0.0850\n",
      "Epoch 114/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0789 - val_loss: 0.0848\n",
      "Epoch 115/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0788 - val_loss: 0.0846\n",
      "Epoch 116/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0787 - val_loss: 0.0844\n",
      "Epoch 117/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0786 - val_loss: 0.0842\n",
      "Epoch 118/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0785 - val_loss: 0.0840\n",
      "Epoch 119/10000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0784 - val_loss: 0.0839\n",
      "Epoch 120/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0782 - val_loss: 0.0837\n",
      "Epoch 121/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0781 - val_loss: 0.0835\n",
      "Epoch 122/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0780 - val_loss: 0.0832\n",
      "Epoch 123/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0779 - val_loss: 0.0830\n",
      "Epoch 124/10000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0778 - val_loss: 0.0829\n",
      "Epoch 125/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0776 - val_loss: 0.0828\n",
      "Epoch 126/10000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0775 - val_loss: 0.0826\n",
      "Epoch 127/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0774 - val_loss: 0.0824\n",
      "Epoch 128/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0773 - val_loss: 0.0822\n",
      "Epoch 129/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0772 - val_loss: 0.0821\n",
      "Epoch 130/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0770 - val_loss: 0.0819\n",
      "Epoch 131/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0769 - val_loss: 0.0818\n",
      "Epoch 132/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0768 - val_loss: 0.0817\n",
      "Epoch 133/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0767 - val_loss: 0.0815\n",
      "Epoch 134/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0766 - val_loss: 0.0813\n",
      "Epoch 135/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0764 - val_loss: 0.0811\n",
      "Epoch 136/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0763 - val_loss: 0.0809\n",
      "Epoch 137/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0762 - val_loss: 0.0808\n",
      "Epoch 138/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0761 - val_loss: 0.0806\n",
      "Epoch 139/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0760 - val_loss: 0.0804\n",
      "Epoch 140/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0758 - val_loss: 0.0802\n",
      "Epoch 141/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0757 - val_loss: 0.0800\n",
      "Epoch 142/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0756 - val_loss: 0.0799\n",
      "Epoch 143/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0755 - val_loss: 0.0797\n",
      "Epoch 144/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0754 - val_loss: 0.0794\n",
      "Epoch 145/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0752 - val_loss: 0.0793\n",
      "Epoch 146/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0751 - val_loss: 0.0790\n",
      "Epoch 147/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0750 - val_loss: 0.0789\n",
      "Epoch 148/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0749 - val_loss: 0.0787\n",
      "Epoch 149/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0748 - val_loss: 0.0786\n",
      "Epoch 150/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0746 - val_loss: 0.0785\n",
      "Epoch 151/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0745 - val_loss: 0.0783\n",
      "Epoch 152/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0744 - val_loss: 0.0781\n",
      "Epoch 153/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0743 - val_loss: 0.0780\n",
      "Epoch 154/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0741 - val_loss: 0.0778\n",
      "Epoch 155/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0740 - val_loss: 0.0777\n",
      "Epoch 156/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0739 - val_loss: 0.0776\n",
      "Epoch 157/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0738 - val_loss: 0.0774\n",
      "Epoch 158/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0737 - val_loss: 0.0771\n",
      "Epoch 159/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0735 - val_loss: 0.0770\n",
      "Epoch 160/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0734 - val_loss: 0.0769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0733 - val_loss: 0.0767\n",
      "Epoch 162/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0732 - val_loss: 0.0766\n",
      "Epoch 163/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0731 - val_loss: 0.0764\n",
      "Epoch 164/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0729 - val_loss: 0.0763\n",
      "Epoch 165/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0728 - val_loss: 0.0761\n",
      "Epoch 166/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0727 - val_loss: 0.0759\n",
      "Epoch 167/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0726 - val_loss: 0.0758\n",
      "Epoch 168/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0724 - val_loss: 0.0756\n",
      "Epoch 169/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0723 - val_loss: 0.0755\n",
      "Epoch 170/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0722 - val_loss: 0.0753\n",
      "Epoch 171/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0721 - val_loss: 0.0751\n",
      "Epoch 172/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0719 - val_loss: 0.0750\n",
      "Epoch 173/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0718 - val_loss: 0.0748\n",
      "Epoch 174/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0717 - val_loss: 0.0746\n",
      "Epoch 175/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0716 - val_loss: 0.0745\n",
      "Epoch 176/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0715 - val_loss: 0.0743\n",
      "Epoch 177/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0713 - val_loss: 0.0742\n",
      "Epoch 178/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0712 - val_loss: 0.0741\n",
      "Epoch 179/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0711 - val_loss: 0.0739\n",
      "Epoch 180/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0710 - val_loss: 0.0737\n",
      "Epoch 181/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0708 - val_loss: 0.0736\n",
      "Epoch 182/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0707 - val_loss: 0.0735\n",
      "Epoch 183/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0706 - val_loss: 0.0733\n",
      "Epoch 184/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0705 - val_loss: 0.0732\n",
      "Epoch 185/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0703 - val_loss: 0.0730\n",
      "Epoch 186/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0702 - val_loss: 0.0729\n",
      "Epoch 187/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0701 - val_loss: 0.0727\n",
      "Epoch 188/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0700 - val_loss: 0.0726\n",
      "Epoch 189/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0698 - val_loss: 0.0724\n",
      "Epoch 190/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0697 - val_loss: 0.0723\n",
      "Epoch 191/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0696 - val_loss: 0.0721\n",
      "Epoch 192/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0695 - val_loss: 0.0719\n",
      "Epoch 193/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0693 - val_loss: 0.0718\n",
      "Epoch 194/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0692 - val_loss: 0.0716\n",
      "Epoch 195/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0691 - val_loss: 0.0715\n",
      "Epoch 196/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0690 - val_loss: 0.0714\n",
      "Epoch 197/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0689 - val_loss: 0.0712\n",
      "Epoch 198/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0687 - val_loss: 0.0710\n",
      "Epoch 199/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0686 - val_loss: 0.0709\n",
      "Epoch 200/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0685 - val_loss: 0.0707\n",
      "Epoch 201/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0684 - val_loss: 0.0706\n",
      "Epoch 202/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0682 - val_loss: 0.0704\n",
      "Epoch 203/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0681 - val_loss: 0.0703\n",
      "Epoch 204/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0680 - val_loss: 0.0702\n",
      "Epoch 205/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0679 - val_loss: 0.0700\n",
      "Epoch 206/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0677 - val_loss: 0.0699\n",
      "Epoch 207/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0676 - val_loss: 0.0697\n",
      "Epoch 208/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0675 - val_loss: 0.0696\n",
      "Epoch 209/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0674 - val_loss: 0.0694\n",
      "Epoch 210/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0672 - val_loss: 0.0693\n",
      "Epoch 211/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0671 - val_loss: 0.0691\n",
      "Epoch 212/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0670 - val_loss: 0.0690\n",
      "Epoch 213/10000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0669 - val_loss: 0.0689\n",
      "Epoch 214/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0667 - val_loss: 0.0687\n",
      "Epoch 215/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0666 - val_loss: 0.0686\n",
      "Epoch 216/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0665 - val_loss: 0.0684\n",
      "Epoch 217/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0664 - val_loss: 0.0682\n",
      "Epoch 218/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0662 - val_loss: 0.0681\n",
      "Epoch 219/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0661 - val_loss: 0.0680\n",
      "Epoch 220/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0660 - val_loss: 0.0678\n",
      "Epoch 221/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0659 - val_loss: 0.0677\n",
      "Epoch 222/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0657 - val_loss: 0.0676\n",
      "Epoch 223/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0656 - val_loss: 0.0674\n",
      "Epoch 224/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0655 - val_loss: 0.0673\n",
      "Epoch 225/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0654 - val_loss: 0.0671\n",
      "Epoch 226/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0652 - val_loss: 0.0670\n",
      "Epoch 227/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0651 - val_loss: 0.0669\n",
      "Epoch 228/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0650 - val_loss: 0.0667\n",
      "Epoch 229/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0649 - val_loss: 0.0666\n",
      "Epoch 230/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0647 - val_loss: 0.0664\n",
      "Epoch 231/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0646 - val_loss: 0.0663\n",
      "Epoch 232/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0645 - val_loss: 0.0661\n",
      "Epoch 233/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0644 - val_loss: 0.0660\n",
      "Epoch 234/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0642 - val_loss: 0.0659\n",
      "Epoch 235/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0641 - val_loss: 0.0657\n",
      "Epoch 236/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0640 - val_loss: 0.0656\n",
      "Epoch 237/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0639 - val_loss: 0.0654\n",
      "Epoch 238/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0637 - val_loss: 0.0653\n",
      "Epoch 239/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0636 - val_loss: 0.0652\n",
      "Epoch 240/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0635 - val_loss: 0.0651\n",
      "Epoch 241/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0634 - val_loss: 0.0649\n",
      "Epoch 242/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0632 - val_loss: 0.0648\n",
      "Epoch 243/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0631 - val_loss: 0.0647\n",
      "Epoch 244/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0630 - val_loss: 0.0645\n",
      "Epoch 245/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0629 - val_loss: 0.0644\n",
      "Epoch 246/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0627 - val_loss: 0.0642\n",
      "Epoch 247/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0626 - val_loss: 0.0641\n",
      "Epoch 248/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0625 - val_loss: 0.0639\n",
      "Epoch 249/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0624 - val_loss: 0.0638\n",
      "Epoch 250/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0622 - val_loss: 0.0636\n",
      "Epoch 251/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0621 - val_loss: 0.0635\n",
      "Epoch 252/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0620 - val_loss: 0.0633\n",
      "Epoch 253/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0619 - val_loss: 0.0632\n",
      "Epoch 254/10000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0617 - val_loss: 0.0631\n",
      "Epoch 255/10000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0616 - val_loss: 0.0630\n",
      "Epoch 256/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0615 - val_loss: 0.0628\n",
      "Epoch 257/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0614 - val_loss: 0.0627\n",
      "Epoch 258/10000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0612 - val_loss: 0.0626\n",
      "Epoch 259/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0611 - val_loss: 0.0624\n",
      "Epoch 260/10000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0610 - val_loss: 0.0623\n",
      "Epoch 261/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0609 - val_loss: 0.0621\n",
      "Epoch 262/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0607 - val_loss: 0.0620\n",
      "Epoch 263/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0606 - val_loss: 0.0619\n",
      "Epoch 264/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0605 - val_loss: 0.0618\n",
      "Epoch 265/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0604 - val_loss: 0.0616\n",
      "Epoch 266/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0602 - val_loss: 0.0615\n",
      "Epoch 267/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0601 - val_loss: 0.0614\n",
      "Epoch 268/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0600 - val_loss: 0.0612\n",
      "Epoch 269/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0599 - val_loss: 0.0611\n",
      "Epoch 270/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0597 - val_loss: 0.0610\n",
      "Epoch 271/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0596 - val_loss: 0.0608\n",
      "Epoch 272/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0595 - val_loss: 0.0607\n",
      "Epoch 273/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0594 - val_loss: 0.0605\n",
      "Epoch 274/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0592 - val_loss: 0.0605\n",
      "Epoch 275/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0591 - val_loss: 0.0603\n",
      "Epoch 276/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0590 - val_loss: 0.0601\n",
      "Epoch 277/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0589 - val_loss: 0.0600\n",
      "Epoch 278/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0587 - val_loss: 0.0599\n",
      "Epoch 279/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0586 - val_loss: 0.0597\n",
      "Epoch 280/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0585 - val_loss: 0.0596\n",
      "Epoch 281/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0584 - val_loss: 0.0595\n",
      "Epoch 282/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0583 - val_loss: 0.0594\n",
      "Epoch 283/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0581 - val_loss: 0.0593\n",
      "Epoch 284/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0580 - val_loss: 0.0591\n",
      "Epoch 285/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0579 - val_loss: 0.0590\n",
      "Epoch 286/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0578 - val_loss: 0.0588\n",
      "Epoch 287/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0576 - val_loss: 0.0587\n",
      "Epoch 288/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0575 - val_loss: 0.0586\n",
      "Epoch 289/10000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0574 - val_loss: 0.0584\n",
      "Epoch 290/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0573 - val_loss: 0.0583\n",
      "Epoch 291/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0571 - val_loss: 0.0582\n",
      "Epoch 292/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0570 - val_loss: 0.0581\n",
      "Epoch 293/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0569 - val_loss: 0.0579\n",
      "Epoch 294/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0568 - val_loss: 0.0578\n",
      "Epoch 295/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0567 - val_loss: 0.0576\n",
      "Epoch 296/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0565 - val_loss: 0.0575\n",
      "Epoch 297/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0564 - val_loss: 0.0574\n",
      "Epoch 298/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0563 - val_loss: 0.0573\n",
      "Epoch 299/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0562 - val_loss: 0.0571\n",
      "Epoch 300/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0560 - val_loss: 0.0570\n",
      "Epoch 301/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0559 - val_loss: 0.0569\n",
      "Epoch 302/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0558 - val_loss: 0.0568\n",
      "Epoch 303/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0557 - val_loss: 0.0566\n",
      "Epoch 304/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0556 - val_loss: 0.0565\n",
      "Epoch 305/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0554 - val_loss: 0.0564\n",
      "Epoch 306/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0553 - val_loss: 0.0562\n",
      "Epoch 307/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0552 - val_loss: 0.0561\n",
      "Epoch 308/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0551 - val_loss: 0.0560\n",
      "Epoch 309/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0550 - val_loss: 0.0558\n",
      "Epoch 310/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0548 - val_loss: 0.0557\n",
      "Epoch 311/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0547 - val_loss: 0.0556\n",
      "Epoch 312/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0546 - val_loss: 0.0554\n",
      "Epoch 313/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0545 - val_loss: 0.0553\n",
      "Epoch 314/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0543 - val_loss: 0.0552\n",
      "Epoch 315/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0542 - val_loss: 0.0551\n",
      "Epoch 316/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0541 - val_loss: 0.0550\n",
      "Epoch 317/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0540 - val_loss: 0.0548\n",
      "Epoch 318/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0539 - val_loss: 0.0547\n",
      "Epoch 319/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0537 - val_loss: 0.0546\n",
      "Epoch 320/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0536 - val_loss: 0.0545\n",
      "Epoch 321/10000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0535 - val_loss: 0.0543\n",
      "Epoch 322/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0534 - val_loss: 0.0542\n",
      "Epoch 323/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0533 - val_loss: 0.0541\n",
      "Epoch 324/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0531 - val_loss: 0.0540\n",
      "Epoch 325/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0530 - val_loss: 0.0538\n",
      "Epoch 326/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0529 - val_loss: 0.0537\n",
      "Epoch 327/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0528 - val_loss: 0.0536\n",
      "Epoch 328/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0527 - val_loss: 0.0534\n",
      "Epoch 329/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0526 - val_loss: 0.0533\n",
      "Epoch 330/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0524 - val_loss: 0.0532\n",
      "Epoch 331/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0523 - val_loss: 0.0531\n",
      "Epoch 332/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0522 - val_loss: 0.0529\n",
      "Epoch 333/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0521 - val_loss: 0.0528\n",
      "Epoch 334/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0520 - val_loss: 0.0527\n",
      "Epoch 335/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0518 - val_loss: 0.0526\n",
      "Epoch 336/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0517 - val_loss: 0.0525\n",
      "Epoch 337/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0516 - val_loss: 0.0523\n",
      "Epoch 338/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0515 - val_loss: 0.0522\n",
      "Epoch 339/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0514 - val_loss: 0.0521\n",
      "Epoch 340/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0512 - val_loss: 0.0520\n",
      "Epoch 341/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0511 - val_loss: 0.0518\n",
      "Epoch 342/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0510 - val_loss: 0.0517\n",
      "Epoch 343/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0509 - val_loss: 0.0516\n",
      "Epoch 344/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0508 - val_loss: 0.0515\n",
      "Epoch 345/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0507 - val_loss: 0.0513\n",
      "Epoch 346/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0505 - val_loss: 0.0512\n",
      "Epoch 347/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0504 - val_loss: 0.0511\n",
      "Epoch 348/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0503 - val_loss: 0.0510\n",
      "Epoch 349/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0502 - val_loss: 0.0509\n",
      "Epoch 350/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0501 - val_loss: 0.0507\n",
      "Epoch 351/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0500 - val_loss: 0.0506\n",
      "Epoch 352/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0498 - val_loss: 0.0505\n",
      "Epoch 353/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0497 - val_loss: 0.0504\n",
      "Epoch 354/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0496 - val_loss: 0.0503\n",
      "Epoch 355/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0495 - val_loss: 0.0501\n",
      "Epoch 356/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0494 - val_loss: 0.0500\n",
      "Epoch 357/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0493 - val_loss: 0.0499\n",
      "Epoch 358/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0491 - val_loss: 0.0498\n",
      "Epoch 359/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0490 - val_loss: 0.0496\n",
      "Epoch 360/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0489 - val_loss: 0.0495\n",
      "Epoch 361/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0488 - val_loss: 0.0494\n",
      "Epoch 362/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0487 - val_loss: 0.0493\n",
      "Epoch 363/10000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0486 - val_loss: 0.0492\n",
      "Epoch 364/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0485 - val_loss: 0.0490\n",
      "Epoch 365/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0483 - val_loss: 0.0489\n",
      "Epoch 366/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0482 - val_loss: 0.0488\n",
      "Epoch 367/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0481 - val_loss: 0.0487\n",
      "Epoch 368/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0480 - val_loss: 0.0486\n",
      "Epoch 369/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0479 - val_loss: 0.0484\n",
      "Epoch 370/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0478 - val_loss: 0.0483\n",
      "Epoch 371/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0477 - val_loss: 0.0482\n",
      "Epoch 372/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0475 - val_loss: 0.0481\n",
      "Epoch 373/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0474 - val_loss: 0.0480\n",
      "Epoch 374/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0473 - val_loss: 0.0479\n",
      "Epoch 375/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0472 - val_loss: 0.0477\n",
      "Epoch 376/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0471 - val_loss: 0.0476\n",
      "Epoch 377/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0470 - val_loss: 0.0475\n",
      "Epoch 378/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0469 - val_loss: 0.0474\n",
      "Epoch 379/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0467 - val_loss: 0.0473\n",
      "Epoch 380/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0466 - val_loss: 0.0472\n",
      "Epoch 381/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0465 - val_loss: 0.0470\n",
      "Epoch 382/10000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0464 - val_loss: 0.0469\n",
      "Epoch 383/10000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0463 - val_loss: 0.0468\n",
      "Epoch 384/10000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0462 - val_loss: 0.0467\n",
      "Epoch 385/10000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0461 - val_loss: 0.0466\n",
      "Epoch 386/10000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0460 - val_loss: 0.0465\n",
      "Epoch 387/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0459 - val_loss: 0.0464\n",
      "Epoch 388/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0457 - val_loss: 0.0462\n",
      "Epoch 389/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0456 - val_loss: 0.0461\n",
      "Epoch 390/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0455 - val_loss: 0.0460\n",
      "Epoch 391/10000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0454 - val_loss: 0.0459\n",
      "Epoch 392/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0453 - val_loss: 0.0458\n",
      "Epoch 393/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0452 - val_loss: 0.0457\n",
      "Epoch 394/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0451 - val_loss: 0.0455\n",
      "Epoch 395/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0450 - val_loss: 0.0454\n",
      "Epoch 396/10000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0449 - val_loss: 0.0453\n",
      "Epoch 397/10000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0447 - val_loss: 0.0452\n",
      "Epoch 398/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0446 - val_loss: 0.0451\n",
      "Epoch 399/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0445 - val_loss: 0.0450\n",
      "Epoch 400/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0444 - val_loss: 0.0449\n",
      "Epoch 401/10000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0443 - val_loss: 0.0448\n",
      "Epoch 402/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0442 - val_loss: 0.0446\n",
      "Epoch 403/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0441 - val_loss: 0.0445\n",
      "Epoch 404/10000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0440 - val_loss: 0.0444\n",
      "Epoch 405/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0439 - val_loss: 0.0443\n",
      "Epoch 406/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0438 - val_loss: 0.0442\n",
      "Epoch 407/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0436 - val_loss: 0.0441\n",
      "Epoch 408/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0435 - val_loss: 0.0440\n",
      "Epoch 409/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0434 - val_loss: 0.0439\n",
      "Epoch 410/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0433 - val_loss: 0.0438\n",
      "Epoch 411/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0432 - val_loss: 0.0436\n",
      "Epoch 412/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0431 - val_loss: 0.0435\n",
      "Epoch 413/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0430 - val_loss: 0.0434\n",
      "Epoch 414/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0429 - val_loss: 0.0433\n",
      "Epoch 415/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0428 - val_loss: 0.0432\n",
      "Epoch 416/10000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0427 - val_loss: 0.0431\n",
      "Epoch 417/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0426 - val_loss: 0.0430\n",
      "Epoch 418/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0425 - val_loss: 0.0429\n",
      "Epoch 419/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0424 - val_loss: 0.0428\n",
      "Epoch 420/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0422 - val_loss: 0.0426\n",
      "Epoch 421/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0421 - val_loss: 0.0425\n",
      "Epoch 422/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0420 - val_loss: 0.0424\n",
      "Epoch 423/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0419 - val_loss: 0.0423\n",
      "Epoch 424/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0418 - val_loss: 0.0422\n",
      "Epoch 425/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0417 - val_loss: 0.0421\n",
      "Epoch 426/10000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0416 - val_loss: 0.0420\n",
      "Epoch 427/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0415 - val_loss: 0.0419\n",
      "Epoch 428/10000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0414 - val_loss: 0.0418\n",
      "Epoch 429/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0413 - val_loss: 0.0417\n",
      "Epoch 430/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0412 - val_loss: 0.0416\n",
      "Epoch 431/10000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0411 - val_loss: 0.0415\n",
      "Epoch 432/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0410 - val_loss: 0.0413\n",
      "Epoch 433/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0409 - val_loss: 0.0412\n",
      "Epoch 434/10000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0408 - val_loss: 0.0411\n",
      "Epoch 435/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0407 - val_loss: 0.0410\n",
      "Epoch 436/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0406 - val_loss: 0.0409\n",
      "Epoch 437/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0405 - val_loss: 0.0408\n",
      "Epoch 438/10000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0404 - val_loss: 0.0407\n",
      "Epoch 439/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0403 - val_loss: 0.0406\n",
      "Epoch 440/10000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0401 - val_loss: 0.0405\n",
      "Epoch 441/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0400 - val_loss: 0.0404\n",
      "Epoch 442/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0399 - val_loss: 0.0403\n",
      "Epoch 443/10000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0402\n",
      "Epoch 444/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0397 - val_loss: 0.0401\n",
      "Epoch 445/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0396 - val_loss: 0.0400\n",
      "Epoch 446/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0395 - val_loss: 0.0399\n",
      "Epoch 447/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0394 - val_loss: 0.0398\n",
      "Epoch 448/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0393 - val_loss: 0.0397\n",
      "Epoch 449/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0392 - val_loss: 0.0396\n",
      "Epoch 450/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0391 - val_loss: 0.0394\n",
      "Epoch 451/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0390 - val_loss: 0.0393\n",
      "Epoch 452/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0389 - val_loss: 0.0392\n",
      "Epoch 453/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0388 - val_loss: 0.0391\n",
      "Epoch 454/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0387 - val_loss: 0.0390\n",
      "Epoch 455/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0386 - val_loss: 0.0389\n",
      "Epoch 456/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0385 - val_loss: 0.0388\n",
      "Epoch 457/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0384 - val_loss: 0.0387\n",
      "Epoch 458/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0383 - val_loss: 0.0386\n",
      "Epoch 459/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0382 - val_loss: 0.0385\n",
      "Epoch 460/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0381 - val_loss: 0.0384\n",
      "Epoch 461/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0380 - val_loss: 0.0383\n",
      "Epoch 462/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0379 - val_loss: 0.0382\n",
      "Epoch 463/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0378 - val_loss: 0.0381\n",
      "Epoch 464/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0377 - val_loss: 0.0380\n",
      "Epoch 465/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0376 - val_loss: 0.0379\n",
      "Epoch 466/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0375 - val_loss: 0.0378\n",
      "Epoch 467/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0374 - val_loss: 0.0377\n",
      "Epoch 468/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0373 - val_loss: 0.0376\n",
      "Epoch 469/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0372 - val_loss: 0.0375\n",
      "Epoch 470/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0371 - val_loss: 0.0374\n",
      "Epoch 471/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0370 - val_loss: 0.0373\n",
      "Epoch 472/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0369 - val_loss: 0.0372\n",
      "Epoch 473/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0368 - val_loss: 0.0371\n",
      "Epoch 474/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0367 - val_loss: 0.0370\n",
      "Epoch 475/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0366 - val_loss: 0.0369\n",
      "Epoch 476/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0365 - val_loss: 0.0368\n",
      "Epoch 477/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0364 - val_loss: 0.0367\n",
      "Epoch 478/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0363 - val_loss: 0.0366\n",
      "Epoch 479/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0362 - val_loss: 0.0365\n",
      "Epoch 480/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0361 - val_loss: 0.0364\n",
      "Epoch 481/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0360 - val_loss: 0.0363\n",
      "Epoch 482/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0360 - val_loss: 0.0362\n",
      "Epoch 483/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0359 - val_loss: 0.0361\n",
      "Epoch 484/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0358 - val_loss: 0.0360\n",
      "Epoch 485/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0357 - val_loss: 0.0359\n",
      "Epoch 486/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0356 - val_loss: 0.0358\n",
      "Epoch 487/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0355 - val_loss: 0.0357\n",
      "Epoch 488/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0354 - val_loss: 0.0356\n",
      "Epoch 489/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0353 - val_loss: 0.0355\n",
      "Epoch 490/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0352 - val_loss: 0.0354\n",
      "Epoch 491/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0351 - val_loss: 0.0353\n",
      "Epoch 492/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0350 - val_loss: 0.0352\n",
      "Epoch 493/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0349 - val_loss: 0.0351\n",
      "Epoch 494/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0348 - val_loss: 0.0350\n",
      "Epoch 495/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0347 - val_loss: 0.0349\n",
      "Epoch 496/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0346 - val_loss: 0.0348\n",
      "Epoch 497/10000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0345 - val_loss: 0.0348\n",
      "Epoch 498/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0344 - val_loss: 0.0347\n",
      "Epoch 499/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0343 - val_loss: 0.0346\n",
      "Epoch 500/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0342 - val_loss: 0.0345\n",
      "Epoch 501/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0341 - val_loss: 0.0344\n",
      "Epoch 502/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0341 - val_loss: 0.0343\n",
      "Epoch 503/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0340 - val_loss: 0.0342\n",
      "Epoch 504/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0339 - val_loss: 0.0341\n",
      "Epoch 505/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0338 - val_loss: 0.0340\n",
      "Epoch 506/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0337 - val_loss: 0.0339\n",
      "Epoch 507/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0336 - val_loss: 0.0338\n",
      "Epoch 508/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0335 - val_loss: 0.0337\n",
      "Epoch 509/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0334 - val_loss: 0.0336\n",
      "Epoch 510/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0333 - val_loss: 0.0335\n",
      "Epoch 511/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0332 - val_loss: 0.0334\n",
      "Epoch 512/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0331 - val_loss: 0.0333\n",
      "Epoch 513/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0330 - val_loss: 0.0332\n",
      "Epoch 514/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0330 - val_loss: 0.0332\n",
      "Epoch 515/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0329 - val_loss: 0.0331\n",
      "Epoch 516/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0328 - val_loss: 0.0330\n",
      "Epoch 517/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0327 - val_loss: 0.0329\n",
      "Epoch 518/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0326 - val_loss: 0.0328\n",
      "Epoch 519/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0325 - val_loss: 0.0327\n",
      "Epoch 520/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0324 - val_loss: 0.0326\n",
      "Epoch 521/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0323 - val_loss: 0.0325\n",
      "Epoch 522/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0322 - val_loss: 0.0324\n",
      "Epoch 523/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0321 - val_loss: 0.0323\n",
      "Epoch 524/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0320 - val_loss: 0.0322\n",
      "Epoch 525/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0320 - val_loss: 0.0321\n",
      "Epoch 526/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0319 - val_loss: 0.0321\n",
      "Epoch 527/10000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0318 - val_loss: 0.0320\n",
      "Epoch 528/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0317 - val_loss: 0.0319\n",
      "Epoch 529/10000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0316 - val_loss: 0.0318\n",
      "Epoch 530/10000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.0315"
     ]
    }
   ],
   "source": [
    "oPredictiveModel = Long_Short_Term_Memory(\n",
    "    sSubModelName, \n",
    "    dfScaledInputTrain.shape[1], \n",
    "    1,\n",
    "    len(g_aBackwardTimeSteps), \n",
    "    1,\n",
    "    False\n",
    "    )\n",
    "\n",
    "oPredictiveModel.Train(dfScaledInputTrain, \n",
    "                       dfOutputTrain,\n",
    "                       dfScaledInputValidation,\n",
    "                       dfOutputValidation\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f9461e",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6638440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aPrediction = oPredictiveModel.aPredict(dfScaledInputTest)\n",
    "dfPrediction = pd.DataFrame(aPrediction, index = dfScaledInputTest.index)\n",
    "dfPrediction.columns = aColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "92cde6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for regression:\n",
      "      mean absolute error:                0.842\n",
      "    median absolute error:                0.636\n",
      "       mean squared error:                1.726\n",
      "                max error:                9.312\n",
      "                 r2 score:               -0.009\n",
      " explained variance score:                0.004\n"
     ]
    }
   ],
   "source": [
    "error = dfOutputTest - dfPrediction\n",
    "\n",
    "aMetrics = [\n",
    "        ('mean absolute error', mean_absolute_error(dfOutputTest, dfPrediction)),\n",
    "        ('median absolute error', median_absolute_error(dfOutputTest, dfPrediction)),\n",
    "        ('mean squared error', mean_squared_error(dfOutputTest, dfPrediction)),\n",
    "        ('max error', max_error(dfOutputTest, dfPrediction)),\n",
    "        ('r2 score', r2_score(dfOutputTest, dfPrediction)),\n",
    "        ('explained variance score', explained_variance_score(dfOutputTest, dfPrediction))\n",
    "    ]\n",
    "\n",
    "print('Metrics for regression:')\n",
    "for metric_name, metric_value in aMetrics:\n",
    "    print(f'{metric_name:>25s}: {metric_value: >20.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183a22a2",
   "metadata": {},
   "source": [
    "# DOWNWARD REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93407e81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
