{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d78e1f-e08c-4ea4-9448-81f915546cd2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0611acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import time\n",
    "\n",
    "import pytz\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, max_error, r2_score\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import MetaTrader5 as mt5\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d915683",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa23be1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Cryptocurrency List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac336b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCrpytocurrencies = pd.read_excel('Static Data\\crpytocurrencies.xlsx')\n",
    "dfCrpytocurrencies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369ae0af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MetaTrader 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44508f4",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "gc_o_TIME_ZONE = pytz.timezone(\"Etc/UTC\")\n",
    "gc_dt_FROM = datetime(2021, 9, 1, tzinfo=gc_o_TIME_ZONE)\n",
    "gc_dt_TO = datetime(2022, 3, 10, tzinfo=gc_o_TIME_ZONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66086c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aFetchFromMT5(sSymbol,dtFrom, dtTo, oFreq):\n",
    "    if not mt5.initialize():\n",
    "        print(\"initialize() failed, error code =\", mt5.last_error())\n",
    "        sys.exit()\n",
    "\n",
    "    aSymbolInfo = mt5.symbol_info(sSymbol)\n",
    "    if not aSymbolInfo:\n",
    "        print(\"symbol_info() failed, error code =\", mt5.last_error())\n",
    "        sys.exit()\n",
    "\n",
    "    aOhlcSample = mt5.copy_rates_range(\n",
    "        sSymbol,\n",
    "        oFreq,\n",
    "        dtFrom, \n",
    "        dtTo\n",
    "    )\n",
    "\n",
    "    if len(aOhlcSample) == 0:\n",
    "        print(\"copy_rates_range() failed, error code =\", mt5.last_error())\n",
    "        sys.exit()\n",
    "\n",
    "    mt5.shutdown()\n",
    "    return aOhlcSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2b43fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sOutputSymbol = \"BTCUSD\"\n",
    "aInputSymbols = dfCrpytocurrencies['Symbol'].values\n",
    "\n",
    "aSymbolsToFetch = np.append(aInputSymbols, sOutputSymbol)\n",
    "aSymbolsToFetch = np.unique(aSymbolsToFetch)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be8d476c-c6f8-420e-a51d-6b6caa5a052a",
   "metadata": {},
   "source": [
    "aDatesToFetch = list(pd.date_range(start=gc_dt_FROM, end=gc_dt_TO)) #created since MT5 library fails due to time out.\n",
    "aDatesSampled = aDatesToFetch[::50]\n",
    "aDatesSampled.append(aDatesToFetch[-1])\n",
    "aDatesSampled = list(set(aDatesSampled))\n",
    "aDatesSampled.sort()\n",
    "\n",
    "dfOhlcSource = pd.DataFrame()\n",
    "for sSymbol in aSymbolsToFetch:\n",
    "    for i in range(0, len(aDatesSampled) - 1):\n",
    "        dtFrom = aDatesSampled[i]\n",
    "        dtTo = aDatesSampled[i+1]\n",
    "\n",
    "        aOhlcSample = aFetchFromMT5(sSymbol,dtFrom, dtTo, oFreq = mt5.TIMEFRAME_M30)\n",
    "\n",
    "        dfOhlcSample = pd.DataFrame(aOhlcSample)\n",
    "        dfOhlcSample['symbol'] = sSymbol\n",
    "\n",
    "        dfOhlcSample['timestamp'] = pd.to_datetime(dfOhlcSample['time'], unit= \"s\")\n",
    "        dfOhlcSample.set_index('timestamp', inplace=True)\n",
    "        dfOhlcSample.drop([\"time\"], axis = 1 , inplace = True)\n",
    "\n",
    "        dfOhlcSource = dfOhlcSource.append(dfOhlcSample)\n",
    "\n",
    "dfOhlcSource.drop_duplicates()\n",
    "dfOhlcSource.to_csv('dfOhlcSource.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889e4365",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOhlcSource = pd.read_csv('dfOhlcSource.csv')\n",
    "dfOhlcSource['timestamp'] = pd.DatetimeIndex(dfOhlcSource['timestamp'])\n",
    "dfOhlcSource.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34801cd6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137167f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sModelName = os.path.join(sOutputSymbol , \"__deep learning model__\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e524e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Add Seasonal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66398f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOhlcSource[\"weekday\"] = dfOhlcSource.index.weekday\n",
    "dfOhlcSource[\"hour\"] = dfOhlcSource.index.hour\n",
    "dfOhlcSource[\"minute\"] = dfOhlcSource.index.minute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d543dade",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Add Return Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a036c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOhlcSource[\"return\"] = (dfOhlcSource[\"close\"] - dfOhlcSource[\"open\"])/dfOhlcSource[\"open\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1011e6d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Add Candle Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ffe4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOhlcSource[\"upper_shadow\"] =( dfOhlcSource[\"high\"] - dfOhlcSource[['close', 'open']].max(axis=1))/ dfOhlcSource[['close', 'open']].max(axis=1)\n",
    "dfOhlcSource[\"lower_shadow\"] = (dfOhlcSource[['close', 'open']].min(axis=1) - dfOhlcSource[\"low\"])/dfOhlcSource[\"low\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c165310b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Transform Symbols to Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cd9d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOhlc = pd.DataFrame()\n",
    "\n",
    "i = 1\n",
    "for sSymbol in aSymbolsToFetch:\n",
    "    dfSymbolValues = dfOhlcSource[dfOhlcSource['symbol'] == sSymbol]\n",
    "\n",
    "    if i == 1:\n",
    "        sHow = \"right\"\n",
    "    else:\n",
    "        sHow = \"inner\"\n",
    "    \n",
    "    dfSymbolValues = dfSymbolValues.drop('symbol', axis = 1)\n",
    "    \n",
    "    dfOhlc = dfOhlc.join(dfSymbolValues,how = sHow, rsuffix=sSymbol)\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "aColumnsOhlc = list()\n",
    "for sSymbol in aSymbolsToFetch:\n",
    "    for sColumn in dfOhlcSource.columns:\n",
    "        if sColumn != 'symbol':\n",
    "            sNewColumn = sSymbol + \";\" + sColumn\n",
    "            aColumnsOhlc.append(sNewColumn)\n",
    "    \n",
    "dfOhlc.columns = aColumnsOhlc\n",
    "\n",
    "dfOhlc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa542c9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70088c21",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "fTrainingRatio = 0.7\n",
    "fValidationRatio = 0.15\n",
    "fTestRatio = 0.15\n",
    "\n",
    "ixTrain, ixTest = train_test_split(\n",
    "    dfOhlc.index,\n",
    "    test_size=1-fTrainingRatio,\n",
    "    shuffle=False)\n",
    "\n",
    "ixValidation, ixTest = train_test_split(\n",
    "    ixTest,\n",
    "    test_size=fTestRatio/(fTestRatio + fValidationRatio),\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1a589a-1503-4c27-9df6-60ac3fd0ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lineplot(data = dfScaledOhlc.loc[ixTrain, sOutputSymbol + ';return'], color = 'green', legend = True)\n",
    "# sns.lineplot(data = dfScaledOhlc.loc[ixValidation,sOutputSymbol + ';return'], color = 'yellow', legend = True)\n",
    "# sns.lineplot(data = dfScaledOhlc.loc[ixTest, sOutputSymbol + ';return'], color = 'red', legend = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0205629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(data = dfScaledOhlc.loc[ixTrain,sOutputSymbol + ';return'], color = 'green', legend = True)\n",
    "# sns.histplot(data = dfScaledOhlc.loc[ixValidation, sOutputSymbol + ';return'], color = 'yellow', legend = True)\n",
    "# sns.histplot(data = dfScaledOhlc.loc[ixTest,sOutputSymbol + ';return'], color = 'red', legend = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ba49b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af403bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oLocalOutlierFactor =  LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "# sFeatureToDetectAnomaly = 'BRENT;spread'\n",
    "# dfAnomalyDetection =  dfOhlc.loc[:, [sFeatureToDetectAnomaly]]\n",
    "# dfAnomalyDetection.loc[:, 'anomaly'] = oLocalOutlierFactor.fit_predict(dfAnomalyDetection) \n",
    "\n",
    "# # visualization\n",
    "# fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "# dfAnomaly = dfAnomalyDetection.loc[dfAnomalyDetection['anomaly'] == -1]\n",
    "\n",
    "# ax.plot(dfAnomalyDetection.index, dfAnomalyDetection[sFeatureToDetectAnomaly], color='blue', label = 'Normal')\n",
    "# ax.scatter(dfAnomaly.index,dfAnomaly[sFeatureToDetectAnomaly], color='red', label = 'Anomaly')\n",
    "# plt.legend()\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7610e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aFeaturesToDetectAnomaly = ['upper_shadow', 'lower_shadow','body' ,'return']\n",
    "# aFeaturesToDetectAnomaly = list(map(\";\".join, itertools.product(aInputSymbols, aFeaturesToDetectAnomaly)))\n",
    "\n",
    "# dfAnomalies = pd.DataFrame(index = dfOhlc.index, columns = aFeaturesToDetectAnomaly)\n",
    "# for sCol in dfOhlc.columns:\n",
    "#     oIsolationForest =  IsolationForest(contamination=0.05, random_state=0)\n",
    "#     dfAnomalies.loc[:, sCol] = oIsolationForest.fit_predict(dfOhlc.loc[:, [sCol]].values) \n",
    "    \n",
    "    \n",
    "\n",
    "# # visualization\n",
    "# # fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "# # dfAnomaly = dfAnomalyDetection.loc[dfAnomalyDetection['anomaly'] == -1]\n",
    "\n",
    "# # ax.plot(dfAnomalyDetection.index, dfAnomalyDetection[sFeatureToDetectAnomaly], color='blue', label = 'Normal')\n",
    "# # ax.scatter(dfAnomaly.index,dfAnomaly[sFeatureToDetectAnomaly], color='red', label = 'Anomaly')\n",
    "# # plt.legend()\n",
    "# # plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa92bb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dfNonOutlier = dfOhlc.loc[\n",
    "# #     ixTrain.append(ixValidation).drop(\n",
    "# #         dfAnomalyDetection[dfAnomalyDetection['anomaly'] == -1].index\n",
    "# # ), sFeatureToDetectAnomaly].to_frame()\n",
    "\n",
    "# # sns.lineplot(data = dfNonOutlier)\n",
    "\n",
    "# ixToDrop = dfAnomalyDetection[dfAnomalyDetection['anomaly'] == -1].index\n",
    "# ixTrain = ixTrain.drop(ixToDrop, errors='ignore' )\n",
    "# ixValidation = ixValidation.drop(ixToDrop, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ea59de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplots(figsize=(10,6))\n",
    "# sns.lineplot(data = dfAnomalyDetection.loc[ixTrain.append(ixValidation), sFeatureToDetectAnomaly])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e73e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c7b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfScaledOhlc = pd.DataFrame(index = dfOhlc.index, columns  = dfOhlc.columns)\n",
    "\n",
    "for sColumn in dfOhlc.columns:\n",
    "    oScaler = StandardScaler()\n",
    "    \n",
    "    dfTrain = pd.DataFrame(dfOhlc.loc[ixTrain, sColumn])\n",
    "    dfValidation = pd.DataFrame(dfOhlc.loc[ixValidation, sColumn])\n",
    "    dfTest = pd.DataFrame(dfOhlc.loc[ixTest, sColumn])\n",
    "    \n",
    "    oScaler.fit(dfTrain.append(dfValidation))\n",
    "    \n",
    "    dfScaledOhlc.loc[ixTrain, sColumn] = np.reshape(oScaler.transform(dfTrain), (-1))\n",
    "    dfScaledOhlc.loc[ixValidation, sColumn] = np.reshape(oScaler.transform(dfValidation), (-1))\n",
    "    dfScaledOhlc.loc[ixTest, sColumn] = np.reshape(oScaler.transform(dfTest), (-1))\n",
    "\n",
    "    sScalerFilePath = os.path.join(sModelName , \"__scalers__\")\n",
    "    sScalerFilePath = os.path.join(sScalerFilePath , sColumn + \".sav\")\n",
    "    os.makedirs(os.path.dirname(sScalerFilePath), exist_ok=True)\n",
    "    pickle.dump(oScaler, open(sScalerFilePath, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec96ca9f-f07a-4e1b-bc3c-aa34164c1d24",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Input Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1449fbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aInputFeatures = ['upper_shadow', 'lower_shadow' ,'return']\n",
    "aInputFeatures = list(map(\";\".join, itertools.product(aInputSymbols, aInputFeatures)))\n",
    "\n",
    "iNrInputFeatures = len(aInputFeatures)\n",
    "\n",
    "iBackwardTimeWindow = 8\n",
    "aBackwardTimeSteps = range(-iBackwardTimeWindow, 0)\n",
    "\n",
    "aTplInputColumns = list(itertools.product(aBackwardTimeSteps, aInputFeatures))\n",
    "aIxInputColumns = pd.MultiIndex.from_tuples(aTplInputColumns, names= ['time_step', 'feature'])\n",
    "\n",
    "dfInput = pd.DataFrame(columns = aIxInputColumns)\n",
    "\n",
    "for tplColumn in list(dfInput.columns):\n",
    "    dfInput.loc[:, tplColumn] = dfScaledOhlc[(tplColumn[1])].shift(-tplColumn[0])\n",
    "\n",
    "    \n",
    "ixNas = dfInput[dfInput.isna().any(axis=1)].index\n",
    "dfInput.drop(ixNas, inplace = True, errors = 'ignore') \n",
    "ixTrain= ixTrain.drop(ixNas, errors = 'ignore') \n",
    "ixValidation= ixValidation.drop(ixNas,   errors = 'ignore') \n",
    "ixTest = ixTest.drop(ixNas,   errors = 'ignore') \n",
    "\n",
    "dfInput.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8128dd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Seasonal Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a68dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# oResultSeasonalDecompose = seasonal_decompose(x = dfOhlc['MRO.N;close'], model='additive', period = 40)\n",
    "# plt.figure(figsize=(10,8))\n",
    "# oResultSeasonalDecompose.plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6317c38a",
   "metadata": {},
   "source": [
    "## Independent Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e714a62b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a44547",
   "metadata": {},
   "source": [
    "* PCA is effected by scale so you need to scale the features in your data before applying PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6b028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# iNrOfComponents = 3\n",
    "# aPCAColumnNames = ['PCA1', 'PCA2', 'PCA3']\n",
    "# oPca = PCA(n_components=iNrOfComponents)\n",
    "# aPca = oPca.fit_transform(dfInput)\n",
    "# dfPca = pd.DataFrame(data = aPca, columns = aPCAColumnNames, index = dfInput.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f521f90",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cluster Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc4ffb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Elbow Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eec11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "# aClusterCandidates = list(range(2, 20))\n",
    "# aInertias = []\n",
    "# for k in aClusterCandidates:\n",
    "#     oKMeans = KMeans(n_clusters=k, random_state=0)\n",
    "#     oKMeans.fit(dfPca)\n",
    "#     aInertias.append(oKMeans.inertia_)\n",
    "\n",
    "# plt.figure(figsize=(10,8))\n",
    "# sns.lineplot(y = aInertias, x = aClusterCandidates,  marker = '^')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0820ee0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Optimum Number of Clusters = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa0082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iNrOfClusters = 3\n",
    "# oKMeans = KMeans(n_clusters=iNrOfClusters, random_state=0)\n",
    "# oKMeans.fit(dfPca.loc[ixTrain.append(ixValidation)])\n",
    "# aClusters = oKMeans.predict(dfPca)\n",
    "# dfPca['Cluster'] = aClusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e2ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "# sns.set(style = \"darkgrid\")\n",
    "\n",
    "# fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "# ax = fig.add_subplot(111, projection = '3d')\n",
    "\n",
    "# for i in range(0,iNrOfClusters):\n",
    "#     ixCluster = dfPca[dfPca['Cluster'] == i].index\n",
    "#     ax.scatter(dfPca.loc[ixCluster, 'PCA1'], dfPca.loc[ixCluster, 'PCA2'], dfPca.loc[ixCluster, 'PCA3'])\n",
    "\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a0118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfInput = dfInput.loc[dfPca[dfPca['Cluster']==1].index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8011a0",
   "metadata": {},
   "source": [
    "## Output Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce152a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "aOutputFeatures = ['return']\n",
    "aOutputFeatures = list(map(\";\".join, itertools.product([sOutputSymbol], aOutputFeatures)))\n",
    "iNrOutputFeatures = len(aOutputFeatures)\n",
    "\n",
    "iForwardTimeWindow = 4\n",
    "aForwardTimeSteps = range(0, iForwardTimeWindow)\n",
    "\n",
    "\n",
    "aTplOutputColumns = list(itertools.product(aForwardTimeSteps, aOutputFeatures))\n",
    "aIxOutputColumns = pd.MultiIndex.from_tuples(aTplOutputColumns, names= ['time_step', 'feature'])\n",
    "\n",
    "dfOutput = pd.DataFrame(columns = aIxOutputColumns)\n",
    "\n",
    "for tplColumn in list(dfOutput.columns):\n",
    "    dfOutput.loc[:, tplColumn] = dfOhlc[(tplColumn[1])].shift(-tplColumn[0])\n",
    "\n",
    "ixNas = dfOutput[dfOutput.isna().any(axis=1)].index\n",
    "dfOutput.drop(ixNas, inplace = True, errors = 'ignore') \n",
    "ixTrain= ixTrain.drop(ixNas, errors = 'ignore') \n",
    "ixValidation= ixValidation.drop(ixNas,   errors = 'ignore') \n",
    "ixTest = ixTest.drop(ixNas,   errors = 'ignore') \n",
    "dfOutput.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296eec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "axMerged = dfInput.index.join(dfOutput.index, how = 'inner')\n",
    "\n",
    "dfInput = dfInput.loc[axMerged]\n",
    "dfOutput = dfOutput.loc[axMerged]\n",
    "\n",
    "ixTrain = ixTrain.join(axMerged, how = \"inner\")\n",
    "ixValidation = ixValidation.join(axMerged, how = \"inner\")\n",
    "ixTest = ixTest.join(axMerged, how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e399d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInputTrain = dfInput.loc[ixTrain]\n",
    "aInputTrain = np.reshape(dfInputTrain.values, (dfInputTrain.shape[0], iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "dfInputValidation = dfInput.loc[ixValidation]\n",
    "aInputValidation = np.reshape(dfInputValidation.values, (dfInputValidation.shape[0], iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "dfInputTest = dfInput.loc[ixTest]\n",
    "aInputTest = np.reshape(dfInputTest.values, (dfInputTest.shape[0], iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "dfOutputTrain = dfOutput.loc[ixTrain]\n",
    "aOutputTrain = np.reshape(dfOutputTrain.values, (dfOutputTrain.shape[0], iForwardTimeWindow, iNrOutputFeatures))\n",
    "\n",
    "dfOutputValidation = dfOutput.loc[ixValidation]\n",
    "aOutputValidation = np.reshape(dfOutputValidation.values, (dfOutputValidation.shape[0], iForwardTimeWindow, iNrOutputFeatures))\n",
    "\n",
    "dfOutputTest = dfOutput.loc[ixTest]\n",
    "aOutputTest = np.reshape(dfOutputTest.values, (dfOutputTest.shape[0], iForwardTimeWindow, iNrOutputFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ce37ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "aInputTrain = np.asarray(aInputTrain, np.float32)\n",
    "aInputValidation = np.asarray(aInputValidation, np.float32)\n",
    "aInputTest = np.asarray(aInputTest, np.float32)\n",
    "aOutputTrain = np.asarray(aOutputTrain, np.float32)\n",
    "aOutputValidation = np.asarray(aOutputValidation, np.float32)\n",
    "aOutputTest = np.asarray(aOutputTest, np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febb9bfa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Pixel Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e998e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iNrOfBins = 28\n",
    "# ixZScoreIntervals = pd.interval_range(-3, 3 , iNrOfBins)\n",
    "\n",
    "# def aConvertToPixels(aNormalizedData):\n",
    "#     #(sample size, feature size, Nr of Bins, time step)\n",
    "#     aConvertedData = np.zeros((aNormalizedData.shape[0] ,   aNormalizedData.shape[2] , iNrOfBins  , aNormalizedData.shape[1]))\n",
    "\n",
    "#     for iI,  aI in enumerate(aNormalizedData): #samples\n",
    "#         for iJ, aJ in enumerate(aI): #time steps\n",
    "#             for iK, fK in enumerate(aJ): #features\n",
    "#                 if fK > 0 and fK >= ixZScoreIntervals[-1].right:\n",
    "#                     aConvertedData[iI][iJ][-1] == 1   \n",
    "#                 elif fK < 0 and fK <= ixZScoreIntervals[0].left:\n",
    "#                     aConvertedData[iI][iJ][0] == 1   \n",
    "#                 else:\n",
    "#                     iFoundIndex = ixZScoreIntervals.get_loc(fK)\n",
    "#                     aConvertedData[iI][iK][iFoundIndex][iJ] = 1\n",
    "    \n",
    "#     return aConvertedData\n",
    "\n",
    "\n",
    "# def aConvertFromPixels(aPixelData):\n",
    "#     aConvertedData = np.zeros((aPixelData.shape[0] ,  aPixelData.shape[3], aPixelData.shape[1]))\n",
    "\n",
    "#     for iI,  aI in enumerate(aPixelData): #samples\n",
    "#             for iJ, aJ in enumerate(aI): #features\n",
    "#                 aJ = np.transpose(aJ)\n",
    "#                 for iK, aK in enumerate(aJ): #time steps\n",
    "#                     iMaxIndex = np.argmax(aK)\n",
    "#                     fCenterOfBin = ixZScoreIntervals[iMaxIndex].mid\n",
    "#                     aConvertedData[iI][iK][iJ] = fCenterOfBin\n",
    "\n",
    "#     return aConvertedData\n",
    "    \n",
    "\n",
    "# aPixelOutputTrain = aConvertToPixels(aOutputTrain)\n",
    "# aPixelOutputValidation = aConvertToPixels(aOutputValidation)\n",
    "# aPixelOutputTest  = aConvertToPixels(aOutputTest)\n",
    "# aPixelInputTrain = aConvertToPixels(aInputTrain)\n",
    "# aPixelInputValidation = aConvertToPixels(aInputValidation)\n",
    "# aPixelInputTest = aConvertToPixels(aInputTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52944fb0",
   "metadata": {},
   "source": [
    "#  MODEL DEVELOPMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e253bd8c",
   "metadata": {},
   "source": [
    "## Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a484f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "iBatchSize = 64\n",
    "iEpochSize = 10000\n",
    "iNrOfHiddenNeurons = 32\n",
    "\n",
    "oEarlyStop = EarlyStopping(\n",
    "    monitor = 'val_loss', \n",
    "    mode = 'min', \n",
    "    verbose = 0 , \n",
    "    patience = 20, \n",
    "    restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27edd3cd",
   "metadata": {},
   "source": [
    "## Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032b92b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fCalculateLoss(aActual, aPrediction):\n",
    "    aDeltaActual = tf.subtract(aActual[:,1:], aActual[:,:-1])    \n",
    "    aDeltaPrediction = tf.subtract(aPrediction[:,1:], aPrediction[:,:-1])\n",
    "\n",
    "    aDeltaPerTimeSteps = tf.abs(aDeltaActual - aDeltaPrediction)\n",
    "    \n",
    "    aSignsActual = tf.sign(aDeltaActual)\n",
    "    aSignsPrediction = tf.sign(aDeltaPrediction)\n",
    "    aDeltaSigns = tf.abs(aSignsActual - aSignsPrediction)\n",
    "\n",
    "    aLossPerTimeSteps = aDeltaPerTimeSteps * aDeltaSigns\n",
    "    \n",
    "    fLoss = tf.math.reduce_mean(aLossPerTimeSteps)\n",
    "    \n",
    "    if fLoss == 0:\n",
    "        fLoss = tf.keras.metrics.mean_absolute_error(aActual, aPrediction)\n",
    "\n",
    "    return fLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75b209e",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66367dfb",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a818e0-3473-4382-aa16-2eacfc35ba40",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "aInputDeepLstm = keras.Input(\n",
    "    shape=(iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "aW = keras.layers.LSTM(64, return_sequences = True)(aInputDeepLstm)\n",
    "aW = keras.layers.Flatten()(aW)\n",
    "aW = keras.layers.Dense(iForwardTimeWindow*iNrOutputFeatures)(aW)\n",
    "aW = keras.layers.Reshape((iForwardTimeWindow, iNrOutputFeatures))(aW)\n",
    "\n",
    "aOutputDeepLstm = aW\n",
    "oModelDeepLstm = keras.Model(\n",
    "    inputs=aInputDeepLstm,\n",
    "    outputs=aOutputDeepLstm\n",
    ")\n",
    "\n",
    "oOptimizerDeepLstm = tf.keras.optimizers.Adam(learning_rate=1e-04)\n",
    "oModelDeepLstm.compile(optimizer=oOptimizerDeepLstm,\n",
    "                         loss = fCalculateLoss\n",
    "                        )\n",
    "\n",
    "oPredictiveModel = oModelDeepLstm\n",
    "\n",
    "tf.keras.utils.plot_model(oModelDeepLstm,  show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f365ab5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Deep CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6776588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aInputDeepCnn = keras.Input(\n",
    "#     shape=(iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "# aW = keras.layers.LSTM(64, return_sequences = True)(aInputDeepCnn)\n",
    "# aW = keras.layers.Flatten()(aW)\n",
    "# aW = keras.layers.Dense(iNrOfBins*iForwardTimeWindow*iNrOutputFeatures)(aW)\n",
    "# aW = keras.layers.Reshape((iNrOutputFeatures * iNrOfBins, iForwardTimeWindow, 1))(aW)\n",
    "# aW = keras.layers.Conv2D(64, (4,4), (1,1), padding = \"same\" )(aW)\n",
    "# aW = keras.layers.MaxPool2D(pool_size = (4, 4))(aW)\n",
    "# aW = keras.layers.Flatten()(aW)\n",
    "# aW = keras.layers.Dense(iNrOfBins*iForwardTimeWindow*iNrOutputFeatures)(aW)\n",
    "# aW = keras.layers.Reshape((iNrOutputFeatures, iNrOfBins, iForwardTimeWindow))(aW)\n",
    "\n",
    "# aOutputDeepCnn = aW\n",
    "# oModelDeepCnn = keras.Model(\n",
    "#     inputs=aInputDeepCnn,\n",
    "#     outputs=aOutputDeepCnn\n",
    "# )\n",
    "\n",
    "# oOptimizerDeepCnn = tf.keras.optimizers.Adam(learning_rate=1e-05)\n",
    "# oModelDeepCnn.compile(optimizer=oOptimizerDeepCnn,\n",
    "#                          loss = fCalculateLoss\n",
    "#                         )\n",
    "\n",
    "# tf.keras.utils.plot_model(oModelDeepCnn,  show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236836c5",
   "metadata": {},
   "source": [
    "#### Deep Convolutional Generative Adversarial Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429220d4",
   "metadata": {},
   "source": [
    "##### Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329bfa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aInputGenerator = keras.Input(\n",
    "#     shape=(iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "# aW = keras.layers.Flatten()(aInputGenerator)\n",
    "# aW = keras.layers.Dense(iNrOutputFeatures*iNrOfBins*iForwardTimeWindow, use_bias=False)(aW)\n",
    "# aW = keras.layers.BatchNormalization()(aW)\n",
    "# aW = keras.layers.LeakyReLU()(aW)\n",
    "\n",
    "# aW = keras.layers.Reshape((iNrOutputFeatures*iNrOfBins, iForwardTimeWindow, 1))(aW)\n",
    "\n",
    "# aW = keras.layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)(aW)\n",
    "# aW = keras.layers.BatchNormalization()(aW)\n",
    "# aW = keras.layers.LeakyReLU()(aW)\n",
    "\n",
    "# aW = keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(aW)\n",
    "# aW = keras.layers.BatchNormalization()(aW)\n",
    "# aW = keras.layers.LeakyReLU()(aW)\n",
    "\n",
    "# aW = keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')(aW)\n",
    "\n",
    "# aW = keras.layers.Flatten()(aW)\n",
    "# aW = keras.layers.Dense(iNrOutputFeatures*iNrOfBins*iForwardTimeWindow, use_bias=False)(aW)\n",
    "# aW = keras.layers.Reshape((iNrOutputFeatures, iNrOfBins, iForwardTimeWindow))(aW)\n",
    "\n",
    "# aOutputGenerator = aW\n",
    "# oModelGenerator = keras.Model(inputs = aInputGenerator, \n",
    "#                               outputs = aOutputGenerator)\n",
    "\n",
    "# def fCalculateGeneratorLoss(aFakeOutput):\n",
    "#     oCrossEntropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "#     fTotalLoss = oCrossEntropy(tf.ones_like(aFakeOutput), aFakeOutput)\n",
    "#     return fTotalLoss\n",
    "\n",
    "# oOptimizerGenerator = tf.keras.optimizers.Adam(learning_rate=1e-05)\n",
    "# oModelGenerator.compile(optimizer=oOptimizerGenerator,\n",
    "#                          loss = fCalculateGeneratorLoss\n",
    "#                         )\n",
    "\n",
    "# tf.keras.utils.plot_model(oModelGenerator,  show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da17f6a",
   "metadata": {},
   "source": [
    "##### Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a8ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aInputDiscrimantor= keras.Input(\n",
    "#     shape=(iNrOutputFeatures, iNrOfBins, iForwardTimeWindow),\n",
    "#     name = \"aInputDiscrimantor\")\n",
    "\n",
    "\n",
    "# aW = keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')(aInputDiscrimantor)\n",
    "# aW = keras.layers.LeakyReLU()(aW)\n",
    "# aW = keras.layers.Dropout(0.3)(aW)\n",
    "\n",
    "# aW = keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')(aW)\n",
    "# aW = keras.layers.LeakyReLU()(aW)\n",
    "# aW = keras.layers.Dropout(0.3)(aW)\n",
    "\n",
    "# aW = keras.layers.Flatten()(aW)\n",
    "# aW = keras.layers.Dense(1)(aW)\n",
    "\n",
    "# def fCalculateDiscrimantorLoss(aRealOutput, aFakeOutput):\n",
    "#     oCrossEntropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "#     fRealLoss = oCrossEntropy(tf.ones_like(aRealOutput), aRealOutput)\n",
    "#     fFakeLoss = oCrossEntropy(tf.zeros_like(aFakeOutput), aFakeOutput)\n",
    "#     fTotalLoss = fRealLoss + fFakeLoss\n",
    "#     return fTotalLoss\n",
    "\n",
    "# aOutputDiscriminator = aW\n",
    "# oModelDiscriminator = keras.Model(\n",
    "#     inputs=aInputDiscrimantor,\n",
    "#     outputs=aOutputDiscriminator\n",
    "# )\n",
    "\n",
    "# oOptimizerDiscriminator = tf.keras.optimizers.Adam(learning_rate=1e-05)\n",
    "# oModelDiscriminator.compile(optimizer=oOptimizerDiscriminator,\n",
    "#                          loss = fCalculateDiscrimantorLoss\n",
    "#                            )\n",
    "\n",
    "# tf.keras.utils.plot_model(oModelDiscriminator,  show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87cdcc3",
   "metadata": {},
   "source": [
    "##### GAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033e1204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "# def trainStep(aOutputActual):\n",
    "#     aNoiseInput = tf.random.normal([iBatchSize, iBackwardTimeWindow, iNrInputFeatures])\n",
    "\n",
    "#     with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "#         aOutputGenerated = oModelGenerator(aNoiseInput, training=True)\n",
    "#         aFake = oModelDiscriminator(aOutputGenerated, training=True)\n",
    "        \n",
    "#         aReal = oModelDiscriminator(aOutputActual, training=True)\n",
    "        \n",
    "#         fLossGenerator = fCalculateGeneratorLoss(aFake)\n",
    "#         fLossDiscriminator = fCalculateDiscrimantorLoss(aReal, aFake)\n",
    "\n",
    "#     aGradientsGenerator = gen_tape.gradient(fLossGenerator, oModelGenerator.trainable_variables)\n",
    "#     aGradientsDiscriminator = disc_tape.gradient(fLossDiscriminator, oModelDiscriminator.trainable_variables)\n",
    "\n",
    "#     oOptimizerGenerator.apply_gradients(zip(aGradientsGenerator, oModelGenerator.trainable_variables))\n",
    "#     oOptimizerDiscriminator.apply_gradients(zip(aGradientsDiscriminator, oModelDiscriminator.trainable_variables))\n",
    "    \n",
    "    \n",
    "\n",
    "# for iEpoch in range(iEpochSize):\n",
    "#     dtStart = time.time()\n",
    "\n",
    "#     dsOutputTrain = tf.data.Dataset.from_tensor_slices(aPixelOutputTrain).batch(iBatchSize)\n",
    "#     for aOutputTrain in dsOutputTrain:\n",
    "#         trainStep(aOutputTrain)\n",
    "\n",
    "#     print ('Time for epoch {} is {} sec'.format(iEpoch + 1, time.time()-dtStart))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11b935e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Convolutional Encoder-Decoder Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "099273b6-7f3e-4eb2-bd82-e1c3e98af43a",
   "metadata": {},
   "source": [
    "aInputs = keras.Input(\n",
    "    shape=(iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "aEncoderHiddens, aFinalH, aFinalC = keras.layers.LSTM(iNrOfHiddenNeurons,\n",
    "                                         return_state = True, \n",
    "                                         return_sequences = True\n",
    "                                        )(aInputs)\n",
    "aFinalH = keras.layers.BatchNormalization()(aFinalH)\n",
    "aFinalC = keras.layers.BatchNormalization()(aFinalC)\n",
    "\n",
    "aFeatureMap = keras.layers.Conv1D(64, 2)(aEncoderHiddens)\n",
    "aFeatureMap = keras.layers.MaxPooling1D(2)(aFeatureMap)\n",
    "aFlatted = keras.layers.Flatten()(aFeatureMap)\n",
    "\n",
    "aDecoderInputs = keras.layers.RepeatVector(iForwardTimeWindow)(aFlatted)\n",
    "\n",
    "aDecoderHiddens = keras.layers.LSTM(iNrOfHiddenNeurons, \n",
    "                       return_state = False, \n",
    "                       return_sequences = True\n",
    "                      )(aDecoderInputs, initial_state=[aFinalH, aFinalC])\n",
    "\n",
    "\n",
    "aOutputs = keras.layers.TimeDistributed(\n",
    "    Dense(iNrOutputFeatures)\n",
    ")(aDecoderHiddens)\n",
    "\n",
    "oPredictiveModel = keras.Model(\n",
    "    inputs=aInputs,\n",
    "    outputs=aOutputs\n",
    ")\n",
    "\n",
    "oOptimizer = tf.keras.optimizers.Adam(learning_rate=1e-05)\n",
    "oPredictiveModel.compile(loss = fCalculateLoss,\n",
    "                         optimizer=oOptimizer\n",
    "                        )\n",
    "\n",
    "tf.keras.utils.plot_model(oPredictiveModel,  show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1ed1a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Luong's Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b49d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aEncoderInputs = keras.Input(\n",
    "#     shape=(iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "\n",
    "# aEncoderHiddens, aFinalH, aFinalC = keras.layers.LSTM(iNrOfHiddenNeurons,\n",
    "#                                          return_state = True, \n",
    "#                                          return_sequences = True\n",
    "#                                         )(aEncoderInputs)\n",
    "# aFinalH = keras.layers.BatchNormalization()(aFinalH)\n",
    "# aFinalC = keras.layers.BatchNormalization()(aFinalC)\n",
    "\n",
    "# aDecoderInputs = keras.layers.RepeatVector(iForwardTimeWindow)(aFinalH)\n",
    "\n",
    "# aDecoderHiddens = keras.layers.LSTM(iNrOfHiddenNeurons, \n",
    "#                        return_state = False, \n",
    "#                        return_sequences = True\n",
    "#                       )(aDecoderInputs, initial_state=[aFinalH, aFinalC])\n",
    "\n",
    "# aAttentions = keras.layers.dot([aDecoderHiddens, aEncoderHiddens], axes=[2, 2])\n",
    "# aAttentions = keras.layers.Activation('softmax')(aAttentions)\n",
    "\n",
    "# aContextVector = keras.layers.dot([aAttentions, aEncoderHiddens], axes=[2,1])\n",
    "# aContextVector = keras.layers.BatchNormalization()(aContextVector)\n",
    "# aContextVector = keras.layers.concatenate([aContextVector, aDecoderHiddens])\n",
    "\n",
    "# aDecoderOutputs = keras.layers.TimeDistributed(\n",
    "#     Dense(iNrOutputFeatures)\n",
    "# )(aContextVector)\n",
    "\n",
    "# oPredictiveModel = keras.Model(\n",
    "#     inputs=aEncoderInputs,\n",
    "#     outputs=aDecoderOutputs\n",
    "# )\n",
    "\n",
    "# oOptimizer = tf.keras.optimizers.Adam(learning_rate=1e-05)\n",
    "# oPredictiveModel.compile(loss = fCalculateLoss, \n",
    "#                          optimizer=oOptimizer\n",
    "#                         )\n",
    "\n",
    "# tf.keras.utils.plot_model(oPredictiveModel,  show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedaa4fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3871f87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "oPredictiveModel.fit(\n",
    "    aInputTrain, \n",
    "    aOutputTrain, \n",
    "    epochs=iEpochSize, \n",
    "    batch_size=iBatchSize, \n",
    "    verbose=1, \n",
    "    validation_data= (aInputValidation, aOutputValidation),\n",
    "    validation_batch_size= iBatchSize\n",
    "    ,callbacks=[oEarlyStop]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680ac53a",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f88fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "oPredictiveModel.save_weights(sModelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141bb9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(oPredictiveModel.history.history).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75633cc0",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d372e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "oPredictiveModel.load_weights(sModelName)\n",
    "\n",
    "aPrediction = oPredictiveModel.predict(aInputTest)\n",
    "aPrediction = aPrediction.reshape((-1, iForwardTimeWindow * iNrOutputFeatures))\n",
    "dfPrediction = pd.DataFrame(data = aPrediction, index = ixTest, columns = aIxOutputColumns)\n",
    "\n",
    "aActual = aOutputTest.reshape((-1, iForwardTimeWindow * iNrOutputFeatures))\n",
    "dfActual =  pd.DataFrame(data = aActual, index = ixTest, columns = aIxOutputColumns).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cf6922",
   "metadata": {},
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cf53a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iComparisionTimeStep = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f2409",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = dfPrediction.iloc[:, iComparisionTimeStep]\n",
    "y_true = dfActual.iloc[:, iComparisionTimeStep]\n",
    "aMetrics = [\n",
    "        ('mean absolute error', mean_absolute_error(y_true, y_pred)),\n",
    "        ('mean squared error', mean_squared_error(y_true, y_pred)),\n",
    "        ('max error', max_error(y_true, y_pred)),\n",
    "        ('r2 score', r2_score(y_true, y_pred))\n",
    "    ]\n",
    "\n",
    "print('Metrics for regression:')\n",
    "for metric_name, metric_value in aMetrics:\n",
    "    print(f'{metric_name:>25s}: {metric_value: >20.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245d4b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTestComparision = pd.DataFrame(dfPrediction.iloc[:,iComparisionTimeStep])\n",
    "dfTestComparision = dfTestComparision.join(dfActual.iloc[:,iComparisionTimeStep], how = \"inner\", lsuffix=\"prediction\")\n",
    "dfTestComparision.columns = [\"Prediction\", \"Actual\"]\n",
    "\n",
    "sns.scatterplot(data = dfTestComparision, x = \"Actual\", y =\"Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2db4bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "iNrOfCols = 6\n",
    "iNrOfRows = int(((len(dfActual)/iNrOfCols)/iForwardTimeWindow) + 1)\n",
    "oFig, aAxises = plt.subplots(iNrOfRows, iNrOfCols, figsize=(30,80), sharex = True)\n",
    "oFig.tight_layout()\n",
    "i = 0\n",
    "for iSampleNr in range(0, len(dfActual), iForwardTimeWindow):\n",
    "    iFrom = iSampleNr\n",
    "    iTo = iFrom + iForwardTimeWindow\n",
    "\n",
    "    if iTo >= len(dfActual):\n",
    "        iTo = len(dfActual) \n",
    "    \n",
    "    dfStepComparision = dfActual.iloc[iFrom:iTo].loc[:, (slice(None), slice(aOutputFeatures[0]))].loc[:, 0]\n",
    "    dfStepComparision.columns = [\"Actual\"]\n",
    "\n",
    "    dfStepComparision[\"Prediction\"] = dfPrediction.iloc[iFrom].iloc[0:iTo-iFrom].loc[:, aOutputFeatures].values\n",
    "    \n",
    "    sTitleName = str(iFrom) + \"---\" + str(iTo) + \"---\" + str(round(r2_score(dfStepComparision[\"Actual\"], dfStepComparision[\"Prediction\"]),1))\n",
    "    \n",
    "    iSampleGraphRow =  int(i/iNrOfCols)\n",
    "    iSampleGraphCol = int(i%iNrOfCols)\n",
    "    \n",
    "    dfStepComparision.reset_index(inplace = True)\n",
    "    sns.lineplot(ax =aAxises[iSampleGraphRow,iSampleGraphCol] , data = dfStepComparision, legend = False,  marker = '^').set_title(sTitleName)\n",
    "    \n",
    "    i = i + 1\n",
    "\n",
    "oFig.legend(aAxises[0][0].lines, ['actual', 'prediction'], frameon=False, loc='lower center', ncol=2,  bbox_to_anchor=(0.5,-0.01))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ca3ab0",
   "metadata": {},
   "source": [
    "# REFERENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49501761",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/keras/train_and_evaluate#passing_data_to_multi-input_multi-output_models\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch/\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit/\n",
    "\n",
    "https://towardsdatascience.com/customize-loss-function-to-make-lstm-model-more-applicable-in-stock-price-prediction-b1c50e50b16c\n",
    "\n",
    "https://keras.io/getting_started/faq/\n",
    "\n",
    "https://machinelearningmastery.com/how-to-develop-lstm-models-for-multi-step-time-series-forecasting-of-household-power-consumption/\n",
    "\n",
    "https://www.tensorflow.org/tutorials/structured_data/time_series\n",
    "\n",
    "https://towardsdatascience.com/encoder-decoder-model-for-multistep-time-series-forecasting-using-pytorch-5d54c6af6e60\n",
    "\n",
    "https://levelup.gitconnected.com/building-seq2seq-lstm-with-luong-attention-in-keras-for-time-series-forecasting-1ee00958decb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
