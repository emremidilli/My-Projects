{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0611acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import pytz\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, max_error, median_absolute_error, r2_score, explained_variance_score\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from Long_Short_Term_Memory import Long_Short_Term_Memory\n",
    "\n",
    "from Optimize_Portfolio import PortfolioManagement\n",
    "\n",
    "import MetaTrader5 as mt5\n",
    "\n",
    "import ta\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6fc32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_o_TIME_ZONE = pytz.timezone(\"Etc/UTC\")\n",
    "gc_dt_FROM = datetime(2019, 1, 1, tzinfo=gc_o_TIME_ZONE)\n",
    "gc_dt_TO = datetime(2021, 10, 28, tzinfo=gc_o_TIME_ZONE)\n",
    "\n",
    "gc_i_BACKWARD_TIME_WINDOW = -1\n",
    "gc_i_FORWARD_TIME_WINDOW = 5\n",
    "\n",
    "gc_dec_TRAINING_RATIO = 0.6\n",
    "gc_dec_VALIDATION_RATIO = 0.2\n",
    "gc_dec_TEST_RATIO = 0.2\n",
    "\n",
    "g_aBackwardTimeSteps = range(gc_i_BACKWARD_TIME_WINDOW, 0)\n",
    "\n",
    "g_aInputFeatures = set(['open', 'high', 'low', 'close', 'spread' ,'tick_volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727b224",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def ConvertSpreadValues(dfRates, aSymbolInfo):\n",
    "    iDigits = aSymbolInfo.digits\n",
    "    dfRates['spread'] = dfRates['spread'] * pow(10, -iDigits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041e482c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def dfShiftTimeSteps(dfRates, aTimeSteps):\n",
    "    \n",
    "    lstColumnNames = list([])\n",
    "    for iTimeStep in aTimeSteps:\n",
    "        for tplCol in dfRates.columns:\n",
    "            lstColumnNames.append((iTimeStep, ) + tplCol)\n",
    "    \n",
    "    \n",
    "    lstIndexNames = (\"Time Step\",) +  tuple(dfRates.columns.names)\n",
    "    \n",
    "    dicColumnIndices = pd.MultiIndex.from_tuples(\n",
    "        lstColumnNames,\n",
    "        names = lstIndexNames\n",
    "        )\n",
    "\n",
    "\n",
    "    dfShiftedRates = pd.DataFrame(\n",
    "        columns=dicColumnIndices, \n",
    "        index=dfRates.index)\n",
    "    \n",
    "    \n",
    "\n",
    "    for i in aTimeSteps:\n",
    "        dfShiftedRates[i] = dfRates.shift(-i)\n",
    "\n",
    "    dfShiftedRates.dropna(inplace=True)\n",
    "\n",
    "    return dfShiftedRates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad524f3",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def dfGetMarketData(sSymbol):\n",
    "\n",
    "    if not mt5.initialize():\n",
    "        print(\"initialize() failed, error code =\", mt5.last_error())\n",
    "        sys.exit()\n",
    "\n",
    "    aSymbolInfo = mt5.symbol_info(sSymbol)\n",
    "    if not aSymbolInfo:\n",
    "        print(\"symbol_info() failed, error code =\", mt5.last_error())\n",
    "        sys.exit()\n",
    "\n",
    "    aRates = mt5.copy_rates_range(\n",
    "        sSymbol, mt5.TIMEFRAME_H1, gc_dt_FROM, gc_dt_TO)\n",
    "    if len(aRates) == 0:\n",
    "        print(\"copy_rates_range() failed, error code =\", mt5.last_error())\n",
    "        sys.exit()\n",
    "\n",
    "    mt5.shutdown()\n",
    "\n",
    "    dfRates = pd.DataFrame(aRates)\n",
    "\n",
    "    dfRates['time'] = pd.to_datetime(dfRates['time'], unit='s')\n",
    "    dfRates.set_index('time', inplace=True)\n",
    "    dfRates.drop('real_volume', axis=1, inplace=True)\n",
    "\n",
    "    ConvertSpreadValues(dfRates, aSymbolInfo)\n",
    "    AddSeasonalFeatures(dfRates)\n",
    "    AddReturns(dfRates)\n",
    "#     dfRates = dfAddTechnicalIndicators(dfRates)\n",
    "\n",
    "    dfRates.columns  = pd.MultiIndex.from_product(\n",
    "        [[sSymbol], dfRates.columns], \n",
    "        names=[\"Time Series\", \"Feature\"])\n",
    "    \n",
    "    \n",
    "    return dfRates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9f70b2",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def dfAddTechnicalIndicators(dfRates):\n",
    "    global g_aInputFeatures \n",
    "    \n",
    "    \n",
    "    iTimeWindow = 24\n",
    "    \n",
    "    dfHigh = dfRates[\"high\"]\n",
    "    dfLow = dfRates[\"low\"]\n",
    "    dfClose = dfRates[\"close\"]\n",
    "    \n",
    "    # Average Dricetional Movement Index\n",
    "    oAdx = ta.trend.ADXIndicator(dfHigh, dfLow, dfClose, iTimeWindow, False)\n",
    "    \n",
    "    dfAdx = oAdx.adx()\n",
    "    dfAdx.drop(dfAdx[dfAdx == 0].index, inplace = True)\n",
    "    g_aInputFeatures.add(dfAdx.name)\n",
    "    \n",
    "    dfAdxNeg = oAdx.adx_neg()\n",
    "    dfAdxNeg.drop(dfAdxNeg[dfAdxNeg == 0].index, inplace = True)\n",
    "    g_aInputFeatures.add(dfAdxNeg.name)\n",
    "    \n",
    "    \n",
    "    dfAdxPos = oAdx.adx_pos()\n",
    "    dfAdxPos.drop(dfAdxPos[dfAdxPos == 0].index, inplace = True)\n",
    "    g_aInputFeatures.add(dfAdxPos.name)\n",
    "    \n",
    "    \n",
    "    dfRates = dfRates.join(dfAdx, how = \"inner\")\n",
    "    dfRates = dfRates.join(dfAdxNeg, how = \"inner\")\n",
    "    dfRates = dfRates.join(dfAdxPos, how = \"inner\")\n",
    "\n",
    "    \n",
    "    # Aroon Indicator\n",
    "    oAroon = ta.trend.AroonIndicator(dfClose, iTimeWindow, False)\n",
    "    dfAroonDown = oAroon.aroon_down()\n",
    "    dfAroonDown.dropna(inplace = True)\n",
    "    g_aInputFeatures.add(dfAroonDown.name)\n",
    "    \n",
    "    dfAroonIndicator = oAroon.aroon_indicator() \n",
    "    dfAroonIndicator.dropna(inplace = True)\n",
    "    g_aInputFeatures.add(dfAroonIndicator.name)\n",
    "\n",
    "    \n",
    "    dfAroonUp = oAroon.aroon_up()\n",
    "    dfAroonUp.dropna(inplace = True)\n",
    "    g_aInputFeatures.add(dfAroonUp.name)\n",
    "    \n",
    "    dfRates = dfRates.join(dfAroonDown, how = \"inner\")\n",
    "    dfRates = dfRates.join(dfAroonIndicator, how = \"inner\")\n",
    "    dfRates = dfRates.join(dfAroonUp, how = \"inner\")\n",
    "    \n",
    "    \n",
    "    # Commodity Channel Index\n",
    "    oCci = ta.trend.CCIIndicator(dfHigh, dfLow,dfClose, iTimeWindow)\n",
    "    dfCci = oCci.cci()\n",
    "    dfCci.dropna(inplace = True)\n",
    "    g_aInputFeatures.add(dfCci.name)\n",
    "    \n",
    "    dfRates = dfRates.join(dfCci, how = \"inner\")\n",
    "    \n",
    "    \n",
    "    # Detrended Price Oscillator (DPO)\n",
    "    oDpo = ta.trend.DPOIndicator(dfClose, iTimeWindow)\n",
    "    dfDpo = oDpo.dpo()\n",
    "    dfDpo.dropna(inplace = True)\n",
    "    g_aInputFeatures.add(dfDpo.name)    \n",
    "    \n",
    "    dfRates = dfRates.join(dfDpo, how = \"inner\")\n",
    "    \n",
    "    \n",
    "    # EMA - Exponential Moving Average\n",
    "    oEma = ta.trend.EMAIndicator(dfClose, iTimeWindow)\n",
    "    dfEma = oEma.ema_indicator()\n",
    "    dfEma.dropna(inplace = True)\n",
    "    g_aInputFeatures.add(dfEma.name)\n",
    "    \n",
    "    dfRates = dfRates.join(dfEma, how = \"inner\")\n",
    "    \n",
    "    \n",
    "    return dfRates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89a65d2",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def AddSeasonalFeatures(dfRates):\n",
    "    global g_aInputFeatures \n",
    "    \n",
    "    c_a_SEASONAL_FEATURES = [\"year\", \"month\", \"day\", \"dayofweek\", \"hour\"]\n",
    "    for sSeasonalFeature in c_a_SEASONAL_FEATURES:\n",
    "        exec(\"dfRates[sSeasonalFeature] = dfRates.index.\" + sSeasonalFeature)\n",
    "        g_aInputFeatures.add(sSeasonalFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17475e81",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def AddReturns(dfRates):\n",
    "    dfRates[\"return\"] = (dfRates[\"open\"] - dfRates[\"close\"])/dfRates[\"open\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e680ce9d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def dfOversampleImbalancedData(dfX, dfY):\n",
    "    \n",
    "#     oOversample = SMOTE()\n",
    "#     aX, aY = oOversample.fit_resample(dfX.values, dfY.values)\n",
    "    \n",
    "#     dfX = pd.DataFrame(data = aX, columns = dfX.columns)\n",
    "#     dfY = pd.DataFrame(data = aY, columns = dfY.columns)\n",
    "    \n",
    "    dfXCopy = dfX.copy()\n",
    "    dfYCopy = dfY.copy()\n",
    "        \n",
    "    dfCombinations = dfYCopy.astype(str).agg('-'.join, axis=1)\n",
    "    dfCombinationsStats = dfCombinations.value_counts()\n",
    "    dfCombinationsStats = pd.DataFrame(dfCombinationsStats).reset_index()\n",
    "    \n",
    "    \n",
    "    iMaxAmount = dfCombinationsStats.iloc[0,1]\n",
    "    for i in range(1, len(dfCombinationsStats) ):\n",
    "        \n",
    "        sCombination = dfCombinationsStats.iloc[i, 0]\n",
    "        iSamplesNeeded = iMaxAmount - dfCombinationsStats.iloc[i, 1]\n",
    "        \n",
    "        dfSampledIndex =  dfCombinations[dfCombinations == sCombination].sample(iSamplesNeeded, replace = True).index\n",
    "        \n",
    "        dfSampledX = dfXCopy.loc[dfSampledIndex]\n",
    "        dfSampledY = dfYCopy.loc[dfSampledIndex]\n",
    "        \n",
    "    \n",
    "        dfX = dfX.append(dfSampledX , ignore_index= True)\n",
    "        dfY = dfY.append(dfSampledY , ignore_index= True)\n",
    "        \n",
    "    \n",
    "    dfX,dfY = shuffle(dfX,dfY )\n",
    "    \n",
    "\n",
    "    return dfX, dfY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682253c6",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def dfSplitData(dfInput, dfOutput):\n",
    "    dfInputTrainValidation, dfInputTest, dfOutputTrainValidation, dfOutputTest = train_test_split(\n",
    "        dfInput,\n",
    "        dfOutput,\n",
    "        test_size=gc_dec_TEST_RATIO,\n",
    "        shuffle=False)\n",
    "\n",
    "    dfInputTrain, dfInputValidation, dfOutputTrain, dfOutputValidation = train_test_split(\n",
    "        dfInputTrainValidation,\n",
    "        dfOutputTrainValidation,\n",
    "        test_size=(1/(1 -gc_dec_TEST_RATIO))-1,\n",
    "        shuffle=False)\n",
    "    \n",
    "    \n",
    "    dfInputTrain = dfInputTrain.astype(float)\n",
    "    dfInputValidation = dfInputValidation.astype(float)\n",
    "    dfInputTest = dfInputTest.astype(float)\n",
    "    dfOutputTrain = dfOutputTrain.astype(float)\n",
    "    dfOutputValidation = dfOutputValidation.astype(float)\n",
    "    dfOutputTest = dfOutputTest.astype(float)\n",
    "    \n",
    "    return dfInputTrain, dfInputValidation, dfInputTest, dfOutputTrain, dfOutputValidation, dfOutputTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3eba12",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def dfScaleData(sScalerName,dfTrain,dfValidation, dfTest, bIsStandard = True):\n",
    "    sScalersDirectory = os.path.join(sSubModelName , \"__scalers__\")\n",
    "    if bIsStandard == True:\n",
    "        oScaler = StandardScaler()\n",
    "    else:\n",
    "        oScaler = MinMaxScaler()\n",
    "\n",
    "    oScaler.fit(dfTrain)\n",
    "\n",
    "    aScaledTrain = oScaler.transform(dfTrain)\n",
    "    aScaledValidation = oScaler.transform(dfValidation)\n",
    "    aScaledTest = oScaler.transform(dfTest)\n",
    "\n",
    "    dfScaledTrain = pd.DataFrame(aScaledTrain, columns = dfTrain.columns, index = dfTrain.index)\n",
    "    dfScaledValidation = pd.DataFrame(aScaledValidation, columns = dfValidation.columns, index = dfValidation.index)\n",
    "    dfScaledTest = pd.DataFrame(aScaledTest, columns = dfTest.columns, index = dfTest.index)\n",
    "\n",
    "    sScalerFilePath =os.path.join(sScalersDirectory, sScalerName + \".sav\")\n",
    "    os.makedirs(os.path.dirname(sScalerFilePath), exist_ok=True)\n",
    "    pickle.dump(oScaler, open(sScalerFilePath, 'wb'))\n",
    "    \n",
    "    \n",
    "    return dfScaledTrain, dfScaledValidation, dfScaledTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44508f4",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "sSymbol = \"USDCAD\"\n",
    "aRelevantSymbols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7ce049",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRates = dfGetMarketData(sSymbol)\n",
    "\n",
    "for sRelevantSymbol in aRelevantSymbols:\n",
    "    dfRelevantRates = dfGetMarketData(sRelevantSymbol)\n",
    "    dfRates = dfRates.join(dfRelevantRates, how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d458f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInput  = dfRates.loc[:, dfRates.columns.get_level_values(1).isin(g_aInputFeatures)]\n",
    "dfInput = dfShiftTimeSteps(dfInput, g_aBackwardTimeSteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dabba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "j = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4e0cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "aColumns = pd.MultiIndex.from_tuples(\n",
    "    [(i,j, \"Regression\")],\n",
    "    names = [\"From\",\"To\", \"Model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdfa0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOutput = pd.DataFrame(index = dfRates.index, \n",
    "                        columns = aColumns)\n",
    "\n",
    "    \n",
    "dfSpread = dfRates[sSymbol][\"spread\"]\n",
    "dfOpen = dfRates[sSymbol][\"open\"].shift(-i)\n",
    "dfClose = dfRates[sSymbol][\"close\"].shift(-j)\n",
    "\n",
    "dfNetReturn = (abs(dfClose - dfOpen) - dfSpread)\n",
    "dfReturn = (dfClose - dfOpen)/dfOpen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4f67ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfIndexInvestable = dfNetReturn[dfNetReturn>0].index\n",
    "dfIndexNonInvestable = dfNetReturn[dfNetReturn<=0].index\n",
    "\n",
    "dfIndexUpward = dfReturn[dfReturn>0].index\n",
    "dfIndexDownward = dfReturn[dfReturn<=0].index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1127d583",
   "metadata": {},
   "source": [
    "# DEEP LEARNING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137167f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sModelName = os.path.join(sSymbol , \"__deep learning model__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c92e6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sSubModelName = os.path.join(sModelName , \"__\"+ str(i) +\"  \" + str(j) + \"__\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f452e4",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcafb344",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOutput.loc[:,(i,j,\"Regression\")] = dfClose.loc[dfOutput.index]\n",
    "\n",
    "# dfOutput.loc[dfIndexInvestable,(i,j,\"Investability\")] = 1\n",
    "# dfOutput.loc[dfIndexNonInvestable,(i,j,\"Investability\")] = 0\n",
    "\n",
    "# dfOutput.loc[dfIndexUpward,(i,j,\"Directional\")] = 1\n",
    "# dfOutput.loc[dfIndexDownward,(i,j,\"Directional\")] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7d3316",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOutput.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc694ea",
   "metadata": {},
   "source": [
    "### Remove Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264f5027",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged =pd.merge(dfInput, dfOutput, left_index=True, right_index=True)\n",
    "dfMerged.dropna(inplace = True)\n",
    "dfInput = dfMerged[dfInput.columns]\n",
    "dfOutput= dfMerged[dfOutput.columns]\n",
    "\n",
    "dfOutput = dfOutput.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68fffe3",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5275cac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInputTrain, dfInputValidation, dfInputTest, dfOutputTrain, dfOutputValidation, dfOutputTest = dfSplitData(dfInput, \n",
    "                                                                                                            dfOutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9a9ef2",
   "metadata": {},
   "source": [
    "### Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f3d4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfScaledInputTrain, dfScaledInputValidation, dfScaledInputTest = dfScaleData(\"input\", \n",
    "                                                                             dfInputTrain,\n",
    "                                                                             dfInputValidation, \n",
    "                                                                             dfInputTest)\n",
    "\n",
    "dfScaledOutputTrain, dfScaledOutputValidation, dfScaledOutputTest = dfScaleData(\"output\", \n",
    "                                                                                dfOutputTrain,\n",
    "                                                                                dfOutputValidation, \n",
    "                                                                                dfOutputTest,\n",
    "                                                                               False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52944fb0",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e253bd8c",
   "metadata": {},
   "source": [
    "### Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a484f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "iBatchSize = 32\n",
    "\n",
    "oLrSchedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    1e-05, decay_steps=100000, decay_rate=0.50, staircase=True\n",
    ")\n",
    "\n",
    "\n",
    "oOptimizer = tf.keras.optimizers.Adam(learning_rate=1e-05 , beta_1=0.9)\n",
    "\n",
    "oEarlyStop = EarlyStopping(\n",
    "    monitor = 'val_loss', \n",
    "    mode = 'min', \n",
    "    verbose = 0 , \n",
    "    patience = 20, \n",
    "    restore_best_weights = True)\n",
    "iEpochSize = 10000\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75b209e",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b360a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "oInputRates = keras.Input(\n",
    "    shape=(\n",
    "        dfScaledInputTrain.shape[1]), \n",
    "    name=\"aRates\")\n",
    "\n",
    "aW = Dense((100))(oInputRates)\n",
    "aOutputRegression = Dense((100))(aW)\n",
    "\n",
    "aOutputRegression = Dense(1, name = \"Regression\", activation = \"relu\")(aOutputRegression)\n",
    "\n",
    "oPredictiveModel = keras.Model(\n",
    "    inputs=oInputRates, \n",
    "    outputs=aOutputRegression\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaa9122",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac55b3b7",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43debeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "oPredictiveModel.compile(optimizer=oOptimizer,\n",
    "                         loss = tf.keras.losses.MeanSquaredError()\n",
    "#                          loss ={\n",
    "#                             \"Regression\": tf.keras.losses.MeanSquaredError(),\n",
    "#                         }\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedaa4fc",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1293c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "oPredictiveModel.fit(\n",
    "    dfScaledInputTrain, \n",
    "    dfScaledOutputTrain, \n",
    "    epochs=iEpochSize, \n",
    "    batch_size=iBatchSize, \n",
    "    verbose=1, \n",
    "    validation_data= (dfScaledInputValidation, dfScaledOutputValidation),\n",
    "    validation_batch_size= iBatchSize,\n",
    "    callbacks=[oEarlyStop]\n",
    ")\n",
    "\n",
    "oPredictiveModel.save_weights(sSubModelName)\n",
    "\n",
    "pd.DataFrame(oPredictiveModel.history.history).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75633cc0",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc56071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "oPredictiveModel.load_weights(sSubModelName)\n",
    "\n",
    "aPrediction = oPredictiveModel.predict(dfScaledInputTest)\n",
    "\n",
    "# dfPrediction.iloc[:,0] = aPrediction[0]\n",
    "# dfPrediction.loc[dfPrediction.iloc[:,0] <= 0.5] = 0\n",
    "# dfPrediction.loc[dfPrediction.iloc[:,0] > 0.5] = 1\n",
    "\n",
    "# dfPrediction.iloc[:,1] = aPrediction[1]\n",
    "# dfPrediction.loc[dfPrediction.iloc[:,1] <= 0.5] = 0\n",
    "# dfPrediction.loc[dfPrediction.iloc[:,1] > 0.5] = 1\n",
    "\n",
    "# dfPrediction.iloc[:,2] = aPrediction[2]\n",
    "\n",
    "sOutputScalerPath = os.path.join(sSubModelName , \"__scalers__\")\n",
    "sOutputScalerPath = os.path.join(sOutputScalerPath , \"output\" + \".sav\")\n",
    "oScalerOutput = pickle.load(open(sOutputScalerPath, 'rb'))\n",
    "aPrediction = oScalerOutput.inverse_transform(aPrediction)\n",
    "\n",
    "dfPrediction = pd.DataFrame(aPrediction, index = dfScaledOutputTest.index)\n",
    "dfPrediction.columns = aColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245d4b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTestComparision =pd.DataFrame(dfPrediction.iloc[:,0])\n",
    "dfTestComparision = dfTestComparision.join(dfOutputTest.iloc[:,0], how = \"inner\", lsuffix=\"prediction\")\n",
    "dfTestComparision.columns = [\"Prediction\", \"Actual\"]\n",
    "\n",
    "sns.scatterplot(data = dfTestComparision, x = \"Actual\", y =\"Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482be7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "iFrom = 90\n",
    "iTo = 100\n",
    "print(r2_score(dfOutputTest.iloc[iFrom:iTo, 0], dfPrediction.iloc[iFrom:iTo, 0]))\n",
    "sns.lineplot(data = dfTestComparision.iloc[iFrom:iTo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f2409",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dfPrediction.iloc[:, 0]\n",
    "y_true = dfOutputTest.iloc[:, 0]\n",
    "aMetrics = [\n",
    "        ('mean absolute error', mean_absolute_error(y_true, y_pred)),\n",
    "        ('median absolute error', median_absolute_error(y_true, y_pred)),\n",
    "        ('mean squared error', mean_squared_error(y_true, y_pred)),\n",
    "        ('max error', max_error(y_true, y_pred)),\n",
    "        ('r2 score', r2_score(y_true, y_pred)),\n",
    "        ('explained variance score', explained_variance_score(y_true, y_pred))\n",
    "    ]\n",
    "\n",
    "print('Metrics for regression:')\n",
    "for metric_name, metric_value in aMetrics:\n",
    "    print(f'{metric_name:>25s}: {metric_value: >20.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653d9142",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dfPrediction.iloc[:, 1]\n",
    "y_true = dfOutputTest.iloc[:, 1]\n",
    "print(classification_report(y_true, y_pred, zero_division = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a951e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dfPrediction.iloc[:, 0]\n",
    "y_true = dfOutputTest.iloc[:, 0]\n",
    "print(classification_report(y_true, y_pred, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ca3ab0",
   "metadata": {},
   "source": [
    "# REFERENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49501761",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/keras/train_and_evaluate#passing_data_to_multi-input_multi-output_models\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch/\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit/\n",
    "\n",
    "https://towardsdatascience.com/customize-loss-function-to-make-lstm-model-more-applicable-in-stock-price-prediction-b1c50e50b16c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c79b6b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
