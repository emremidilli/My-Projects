{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0611acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import time\n",
    "\n",
    "import pytz\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, max_error, r2_score\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import MetaTrader5 as mt5\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d915683",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44508f4",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "sSymbol = \"NAT.GAS\"\n",
    "gc_o_TIME_ZONE = pytz.timezone(\"Etc/UTC\")\n",
    "gc_dt_FROM = datetime(2021, 10, 1, tzinfo=gc_o_TIME_ZONE)\n",
    "gc_dt_TO = datetime(2021, 11, 1, tzinfo=gc_o_TIME_ZONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd3b945",
   "metadata": {},
   "outputs": [],
   "source": [
    "aDatesToFetch = list(pd.date_range(start=gc_dt_FROM, end=gc_dt_TO)) #created since MT5 library fails due to time out.\n",
    "aDatesSampled = aDatesToFetch[::200]\n",
    "aDatesSampled.append(aDatesToFetch[-1])\n",
    "aDatesSampled = list(set(aDatesSampled))\n",
    "aDatesSampled.sort()\n",
    "\n",
    "dfOhlc = pd.DataFrame()\n",
    "for i in range(0, len(aDatesSampled) - 1):\n",
    "    dtFrom = aDatesSampled[i]\n",
    "    dtTo = aDatesSampled[i+1]\n",
    "\n",
    "    if not mt5.initialize():\n",
    "        print(\"initialize() failed, error code =\", mt5.last_error())\n",
    "        sys.exit()\n",
    "\n",
    "    aSymbolInfo = mt5.symbol_info(sSymbol)\n",
    "    if not aSymbolInfo:\n",
    "        print(\"symbol_info() failed, error code =\", mt5.last_error())\n",
    "        sys.exit()\n",
    "\n",
    "    dfOhlcSample = mt5.copy_rates_range(\n",
    "        sSymbol,\n",
    "        mt5.TIMEFRAME_M30,\n",
    "        dtFrom, \n",
    "        dtTo\n",
    "    )\n",
    "    \n",
    "    if len(dfOhlcSample) == 0:\n",
    "        print(\"copy_rates_range() failed, error code =\", mt5.last_error())\n",
    "        sys.exit()\n",
    "\n",
    "    mt5.shutdown()\n",
    "\n",
    "    dfOhlcSample = pd.DataFrame(dfOhlcSample)\n",
    "\n",
    "    dfOhlcSample['timestamp'] = pd.to_datetime(dfOhlcSample['time'], unit= \"s\")\n",
    "    dfOhlcSample.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    dfOhlc = dfOhlc.append(dfOhlcSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66398f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOhlc[\"weekday\"] = dfOhlc.index.weekday\n",
    "dfOhlc[\"hour\"] = dfOhlc.index.hour\n",
    "dfOhlc[\"minute\"] = dfOhlc.index.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9b11ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOhlc[\"return\"] = (dfOhlc[\"close\"] - dfOhlc[\"open\"])/dfOhlc[\"open\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93639e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOhlc.drop([\"time\"], axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7bca11",
   "metadata": {},
   "source": [
    "# DESCRIBE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a04a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOhlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d915b40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data  = dfOhlc[\"close\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34801cd6",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137167f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sModelName = os.path.join(sSymbol , \"__deep learning model__\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa542c9e",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70088c21",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "fTrainingRatio = 0.6\n",
    "fValidationRatio = 0.2\n",
    "fTestRatio = 0.2\n",
    "\n",
    "ixTrain, ixTest = train_test_split(\n",
    "    dfOhlc.index,\n",
    "    test_size=1-fTrainingRatio,\n",
    "    shuffle=False)\n",
    "\n",
    "ixValidation, ixTest= train_test_split(\n",
    "    ixTest,\n",
    "    test_size=fTestRatio/(fTestRatio + fValidationRatio),\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e73e3",
   "metadata": {},
   "source": [
    "## Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c7b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfScaledOhlc = pd.DataFrame(index = dfOhlc.index, columns  = dfOhlc.columns)\n",
    "\n",
    "\n",
    "for sColumn in dfOhlc.columns:\n",
    "    oScaler = StandardScaler()\n",
    "    \n",
    "    dfTrain = pd.DataFrame(dfOhlc.loc[ixTrain, sColumn])\n",
    "    dfValidation = pd.DataFrame(dfOhlc.loc[ixValidation, sColumn])\n",
    "    dfTest = pd.DataFrame(dfOhlc.loc[ixTest, sColumn])\n",
    "    \n",
    "    oScaler.fit(dfTrain)\n",
    "    \n",
    "    dfScaledOhlc.loc[ixTrain, sColumn] = np.reshape(oScaler.transform(dfTrain), (-1))\n",
    "    dfScaledOhlc.loc[ixValidation, sColumn] = np.reshape(oScaler.transform(dfValidation), (-1))\n",
    "    dfScaledOhlc.loc[ixTest, sColumn] = np.reshape(oScaler.transform(dfTest), (-1))\n",
    "\n",
    "    sScalerFilePath = os.path.join(sModelName , \"__scalers__\")\n",
    "    sScalerFilePath = os.path.join(sScalerFilePath , sColumn + \".sav\")\n",
    "    os.makedirs(os.path.dirname(sScalerFilePath), exist_ok=True)\n",
    "    pickle.dump(oScaler, open(sScalerFilePath, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f452e4",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1449fbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aInputFeatures = ['open', 'high', 'low', 'close', 'tick_volume', 'spread', 'real_volume','weekday', 'hour', 'minute']\n",
    "iBackwardTimeWindow = 8\n",
    "iNrInputFeatures = len(aInputFeatures)\n",
    "aBackwardTimeSteps = range(-iBackwardTimeWindow, 0)\n",
    "\n",
    "tplInputColumns = list(itertools.product(aBackwardTimeSteps, aInputFeatures))\n",
    "miInputColums = pd.MultiIndex.from_tuples(tplInputColumns, names= [\"time_step\", \"feature\"])\n",
    "\n",
    "dfInput = pd.DataFrame( columns = miInputColums)\n",
    "\n",
    "for i in aBackwardTimeSteps:\n",
    "    for sInputFeature in aInputFeatures:\n",
    "        dfInput.loc[:, (i, sInputFeature)] = dfScaledOhlc[sInputFeature].shift(-i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce152a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "aOutputFeatures = ['return']\n",
    "iForwardTimeWindow  =  8\n",
    "iNrOutputFeatures = len(aOutputFeatures)\n",
    "aForwardTimeSteps = range(0, iForwardTimeWindow)\n",
    "\n",
    "tplOutputColumns = list(itertools.product(aForwardTimeSteps, aOutputFeatures))\n",
    "ixOutputColums = pd.MultiIndex.from_tuples(tplOutputColumns, names= [\"time_step\", \"feature\"])\n",
    "\n",
    "dfOutput = pd.DataFrame(columns = ixOutputColums)\n",
    "\n",
    "for i in aForwardTimeSteps:\n",
    "    for sOutputFeature in aOutputFeatures:\n",
    "        dfOutput.loc[:, (i, sOutputFeature)] = dfScaledOhlc[sOutputFeature].shift(-i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296eec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged = dfInput.join(dfOutput, how= \"inner\")\n",
    "dfMerged.dropna(inplace=True)\n",
    "dfInput = dfMerged[dfInput.columns]\n",
    "dfOutput = dfMerged[dfOutput.columns]\n",
    "ixTrain = ixTrain.join(dfMerged.index, how = \"inner\")\n",
    "ixValidation = ixValidation.join(dfMerged.index, how = \"inner\")\n",
    "ixTest = ixTest.join(dfMerged.index, how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e399d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInputTrain = dfInput.loc[ixTrain]\n",
    "aInputTrain = np.reshape(dfInputTrain.values, (dfInputTrain.shape[0], iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "dfInputValidation = dfInput.loc[ixValidation]\n",
    "aInputValidation = np.reshape(dfInputValidation.values, (dfInputValidation.shape[0], iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "dfInputTest = dfInput.loc[ixTest]\n",
    "aInputTest = np.reshape(dfInputTest.values, (dfInputTest.shape[0], iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "dfOutputTrain = dfOutput.loc[ixTrain]\n",
    "aOutputTrain = np.reshape(dfOutputTrain.values, (dfOutputTrain.shape[0], iForwardTimeWindow, iNrOutputFeatures))\n",
    "\n",
    "dfOutputValidation = dfOutput.loc[ixValidation]\n",
    "aOutputValidation = np.reshape(dfOutputValidation.values, (dfOutputValidation.shape[0], iForwardTimeWindow, iNrOutputFeatures))\n",
    "\n",
    "dfOutputTest = dfOutput.loc[ixTest]\n",
    "aOutputTest = np.reshape(dfOutputTest.values, (dfOutputTest.shape[0], iForwardTimeWindow, iNrOutputFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ce37ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "aInputTrain = np.asarray(aInputTrain, np.float32)\n",
    "aInputValidation = np.asarray(aInputValidation, np.float32)\n",
    "aInputTest = np.asarray(aInputTest, np.float32)\n",
    "aOutputTrain = np.asarray(aOutputTrain, np.float32)\n",
    "aOutputValidation = np.asarray(aOutputValidation, np.float32)\n",
    "aOutputTest = np.asarray(aOutputTest, np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52944fb0",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e253bd8c",
   "metadata": {},
   "source": [
    "### Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a484f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "iBatchSize = 64\n",
    "iEpochSize = 10000\n",
    "iNrOfHiddenNeurons = 32\n",
    "\n",
    "oOptimizer = tf.keras.optimizers.Adam(learning_rate=1e-05)\n",
    "\n",
    "fncLoss =  tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "oEarlyStop = EarlyStopping(\n",
    "    monitor = 'val_loss', \n",
    "    mode = 'min', \n",
    "    verbose = 0 , \n",
    "    patience = 20, \n",
    "    restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75b209e",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc5765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aEncoderInputs = keras.Input(\n",
    "    shape=(iBackwardTimeWindow, iNrInputFeatures), \n",
    "    name=\"aEncoderInputs\")\n",
    "\n",
    "aEncoderHiddens, aFinalH, aFinalC = LSTM(iNrOfHiddenNeurons,\n",
    "                                         return_state = True, \n",
    "                                         return_sequences = True,\n",
    "                                         activation = keras.activations.linear\n",
    "                                        )(aEncoderInputs)\n",
    "# aFinalH = keras.layers.BatchNormalization(momentum=0.6)(aFinalH)\n",
    "# aFinalC = keras.layers.BatchNormalization(momentum=0.6)(aFinalC)\n",
    "\n",
    "aDecoderInputs = keras.layers.RepeatVector(iForwardTimeWindow)(aFinalH)\n",
    "\n",
    "aDecoderHiddens = LSTM(iNrOfHiddenNeurons, \n",
    "                       return_state = False, \n",
    "                       return_sequences = True,\n",
    "                       activation = keras.activations.linear\n",
    "                      )(aDecoderInputs, initial_state=[aFinalH, aFinalC])\n",
    "\n",
    "# aAttentions = keras.layers.dot([aDecoderHiddens, aEncoderHiddens], axes=[2, 2])\n",
    "# aAttentions = keras.layers.Activation('softmax')(aAttentions)\n",
    "\n",
    "# aContextVector = keras.layers.dot([aAttentions, aEncoderHiddens], axes=[2,1])\n",
    "# aContextVector = keras.layers.BatchNormalization(momentum=0.6)(aContextVector)\n",
    "# aContextVector = keras.layers.concatenate([aContextVector, aDecoderHiddens])\n",
    "\n",
    "aContextVector = aDecoderHiddens\n",
    "aDecoderOutputs = keras.layers.TimeDistributed(\n",
    "    Dense(iNrOutputFeatures)\n",
    ")(aContextVector)\n",
    "\n",
    "oPredictiveModel = keras.Model(\n",
    "    inputs=aEncoderInputs,\n",
    "    outputs=aDecoderOutputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a5c23e",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8349125",
   "metadata": {},
   "outputs": [],
   "source": [
    "oFnLoss =  tf.keras.losses.MeanSquaredError()\n",
    "oPredictiveModel.compile(optimizer=oOptimizer,\n",
    "                         loss = oFnLoss\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedaa4fc",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3871f87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "oPredictiveModel.fit(\n",
    "    aInputTrain, \n",
    "    aOutputTrain, \n",
    "    epochs=iEpochSize, \n",
    "    batch_size=iBatchSize, \n",
    "    verbose=1, \n",
    "    validation_data= (aInputValidation, aOutputValidation),\n",
    "    validation_batch_size= iBatchSize,\n",
    "    callbacks=[oEarlyStop]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680ac53a",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f88fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "oPredictiveModel.save_weights(sModelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141bb9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(oPredictiveModel.history.history).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75633cc0",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d372e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "oPredictiveModel.load_weights(sModelName)\n",
    "\n",
    "aPrediction = oPredictiveModel.predict(aInputTest)\n",
    "aPrediction = aPrediction.reshape((-1, iForwardTimeWindow * iNrOutputFeatures))\n",
    "dfPrediction = pd.DataFrame(aPrediction, index = ixTest, columns = ixOutputColums)\n",
    "\n",
    "aActual = aOutputTest.reshape((-1, iForwardTimeWindow * iNrOutputFeatures))\n",
    "dfActual =  pd.DataFrame(aActual, index = ixTest, columns = ixOutputColums)\n",
    "\n",
    "for sOutputFeature in aOutputFeatures:\n",
    "    sScalerFilePath = os.path.join(sModelName , \"__scalers__\")\n",
    "    sScalerFilePath = os.path.join(sScalerFilePath , sOutputFeature + \".sav\")\n",
    "    oScaler = pickle.load(open(sScalerFilePath, 'rb'))\n",
    "    \n",
    "    tplMaskFeature = (slice(None), slice(sOutputFeature))\n",
    "    \n",
    "    dfPrediction.loc[:,tplMaskFeature] = oScaler.inverse_transform(dfPrediction.loc[:, tplMaskFeature])\n",
    "    dfActual.loc[:, tplMaskFeature] =  oScaler.inverse_transform(dfActual.loc[:, tplMaskFeature])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cf6922",
   "metadata": {},
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cf53a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iComparisionTimeStep = 5\n",
    "iFrom = 15 * iForwardTimeWindow\n",
    "iTo = iFrom + iForwardTimeWindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f2409",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = dfPrediction.iloc[:, iComparisionTimeStep]\n",
    "y_true = dfActual.iloc[:, iComparisionTimeStep]\n",
    "aMetrics = [\n",
    "        ('mean absolute error', mean_absolute_error(y_true, y_pred)),\n",
    "        ('mean squared error', mean_squared_error(y_true, y_pred)),\n",
    "        ('max error', max_error(y_true, y_pred)),\n",
    "        ('r2 score', r2_score(y_true, y_pred))\n",
    "    ]\n",
    "\n",
    "print('Metrics for regression:')\n",
    "for metric_name, metric_value in aMetrics:\n",
    "    print(f'{metric_name:>25s}: {metric_value: >20.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245d4b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTestComparision = pd.DataFrame(dfPrediction.iloc[:,iComparisionTimeStep])\n",
    "dfTestComparision = dfTestComparision.join(dfActual.iloc[:,iComparisionTimeStep], how = \"inner\", lsuffix=\"prediction\")\n",
    "dfTestComparision.columns = [\"Prediction\", \"Actual\"]\n",
    "\n",
    "sns.scatterplot(data = dfTestComparision, x = \"Actual\", y =\"Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2db4bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStepComparision = dfActual.iloc[iFrom:iTo].loc[:, (slice(None), slice(sOutputFeature))].loc[:, 0]\n",
    "dfStepComparision.columns = [\"Actual\"]\n",
    "\n",
    "dfStepComparision[\"Prediction\"] = dfPrediction.iloc[iFrom].loc[:, aOutputFeatures].values\n",
    "\n",
    "print(r2_score(dfStepComparision[\"Actual\"], dfStepComparision[\"Prediction\"]))\n",
    "sns.lineplot(data = dfStepComparision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9847276",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = dfTestComparision[\"Actual\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3a8b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = dfTestComparision[\"Prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ca3ab0",
   "metadata": {},
   "source": [
    "# REFERENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49501761",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/keras/train_and_evaluate#passing_data_to_multi-input_multi-output_models\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch/\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit/\n",
    "\n",
    "https://towardsdatascience.com/customize-loss-function-to-make-lstm-model-more-applicable-in-stock-price-prediction-b1c50e50b16c\n",
    "\n",
    "https://keras.io/getting_started/faq/\n",
    "\n",
    "https://machinelearningmastery.com/how-to-develop-lstm-models-for-multi-step-time-series-forecasting-of-household-power-consumption/\n",
    "\n",
    "https://www.tensorflow.org/tutorials/structured_data/time_series\n",
    "\n",
    "https://towardsdatascience.com/encoder-decoder-model-for-multistep-time-series-forecasting-using-pytorch-5d54c6af6e60\n",
    "\n",
    "https://levelup.gitconnected.com/building-seq2seq-lstm-with-luong-attention-in-keras-for-time-series-forecasting-1ee00958decb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
