{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d78e1f-e08c-4ea4-9448-81f915546cd2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0611acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import time\n",
    "\n",
    "import pytz\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, max_error, r2_score\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54d4875-8ad8-478e-b63a-313ed6fdb418",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c2b43fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sOutputSymbol = \"BTCUSD\"\n",
    "\n",
    "sModelType = 'MLP'\n",
    "iBatchSize = 90\n",
    "iNrOfHiddenNeurons = 197\n",
    "iBackwardTimeWindow = 3\n",
    "iForwardTimeWindow = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "137167f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sModelName = os.path.join(sOutputSymbol , sModelType + '_' +str(iBackwardTimeWindow) + '_'+ str(iForwardTimeWindow) +  '_'+ str(iBatchSize) +  '_'+  str(iNrOfHiddenNeurons) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d915683",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa23be1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Cryptocurrency List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ac336b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BTCUSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ETHUSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCHUSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LTCUSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RPLUSD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Symbol\n",
       "0  BTCUSD\n",
       "1  ETHUSD\n",
       "2  BCHUSD\n",
       "3  LTCUSD\n",
       "4  RPLUSD"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCrpytocurrencies = pd.read_csv('Static Data\\cryptocurrencies.csv')\n",
    "dfCrpytocurrencies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369ae0af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "889e4365",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOhlc = pd.read_csv('Static Data\\dfOhlc.csv')\n",
    "dfOhlc['timestamp'] = pd.DatetimeIndex(dfOhlc['timestamp'])\n",
    "dfOhlc.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34801cd6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa542c9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70088c21",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "fTrainingRatio = 0.7\n",
    "fValidationRatio = 0.15\n",
    "fTestRatio = 0.15\n",
    "\n",
    "ixTrain, ixTest = train_test_split(\n",
    "    dfOhlc.index,\n",
    "    test_size=1-fTrainingRatio,\n",
    "    shuffle=False)\n",
    "\n",
    "ixValidation, ixTest = train_test_split(\n",
    "    ixTest,\n",
    "    test_size=fTestRatio/(fTestRatio + fValidationRatio),\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e73e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32c7b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfScaledOhlc = pd.DataFrame(index = dfOhlc.index, columns  = dfOhlc.columns)\n",
    "\n",
    "for sColumn in dfOhlc.columns:\n",
    "    oScaler = StandardScaler()\n",
    "    \n",
    "    dfTrain = pd.DataFrame(dfOhlc.loc[ixTrain, sColumn])\n",
    "    dfValidation = pd.DataFrame(dfOhlc.loc[ixValidation, sColumn])\n",
    "    dfTest = pd.DataFrame(dfOhlc.loc[ixTest, sColumn])\n",
    "    \n",
    "    oScaler.fit(dfTrain.append(dfValidation))\n",
    "    \n",
    "    dfScaledOhlc.loc[ixTrain, sColumn] = np.reshape(oScaler.transform(dfTrain), (-1))\n",
    "    dfScaledOhlc.loc[ixValidation, sColumn] = np.reshape(oScaler.transform(dfValidation), (-1))\n",
    "    dfScaledOhlc.loc[ixTest, sColumn] = np.reshape(oScaler.transform(dfTest), (-1))\n",
    "\n",
    "    sScalerFilePath = os.path.join(sModelName , \"__scalers__\")\n",
    "    sScalerFilePath = os.path.join(sScalerFilePath , sColumn + \".sav\")\n",
    "    os.makedirs(os.path.dirname(sScalerFilePath), exist_ok=True)\n",
    "    \n",
    "    pickle.dump(oScaler, open(sScalerFilePath, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec96ca9f-f07a-4e1b-bc3c-aa34164c1d24",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Input Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1449fbb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>time_step</th>\n",
       "      <th colspan=\"10\" halign=\"left\">-3</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">-1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th>BTCUSD:weekday</th>\n",
       "      <th>BTCUSD:hour</th>\n",
       "      <th>BTCUSD:minute</th>\n",
       "      <th>BTCUSD:upper_shadow</th>\n",
       "      <th>BTCUSD:lower_shadow</th>\n",
       "      <th>BTCUSD:return</th>\n",
       "      <th>ETHUSD:weekday</th>\n",
       "      <th>ETHUSD:hour</th>\n",
       "      <th>ETHUSD:minute</th>\n",
       "      <th>ETHUSD:upper_shadow</th>\n",
       "      <th>...</th>\n",
       "      <th>LTCUSD:minute</th>\n",
       "      <th>LTCUSD:upper_shadow</th>\n",
       "      <th>LTCUSD:lower_shadow</th>\n",
       "      <th>LTCUSD:return</th>\n",
       "      <th>RPLUSD:weekday</th>\n",
       "      <th>RPLUSD:hour</th>\n",
       "      <th>RPLUSD:minute</th>\n",
       "      <th>RPLUSD:upper_shadow</th>\n",
       "      <th>RPLUSD:lower_shadow</th>\n",
       "      <th>RPLUSD:return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-01 01:30:00</th>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.662613</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.272382</td>\n",
       "      <td>-0.344248</td>\n",
       "      <td>0.367626</td>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.662613</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.101196</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.247703</td>\n",
       "      <td>-0.356995</td>\n",
       "      <td>-0.691235</td>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.517929</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.042302</td>\n",
       "      <td>1.24257</td>\n",
       "      <td>-2.245317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 02:00:00</th>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.662613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.482079</td>\n",
       "      <td>-0.838114</td>\n",
       "      <td>-0.274886</td>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.662613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.108089</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.676376</td>\n",
       "      <td>0.086697</td>\n",
       "      <td>0.736124</td>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.517929</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.388771</td>\n",
       "      <td>0.235062</td>\n",
       "      <td>1.631002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 02:30:00</th>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.517929</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.09279</td>\n",
       "      <td>-0.050609</td>\n",
       "      <td>-0.230078</td>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.517929</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5739</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.849824</td>\n",
       "      <td>-0.029284</td>\n",
       "      <td>0.450547</td>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.373245</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.136139</td>\n",
       "      <td>1.074724</td>\n",
       "      <td>0.541948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 03:00:00</th>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.517929</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.792066</td>\n",
       "      <td>-0.003061</td>\n",
       "      <td>0.948749</td>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.517929</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.693713</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.508944</td>\n",
       "      <td>-0.675575</td>\n",
       "      <td>0.071885</td>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.373245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.148526</td>\n",
       "      <td>-0.76391</td>\n",
       "      <td>0.835947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 03:30:00</th>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.373245</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.402557</td>\n",
       "      <td>-0.069069</td>\n",
       "      <td>0.438649</td>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.373245</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.541873</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.236206</td>\n",
       "      <td>0.260103</td>\n",
       "      <td>-0.531665</td>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.228561</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.070256</td>\n",
       "      <td>2.147994</td>\n",
       "      <td>0.002064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "time_step                       -3                            \\\n",
       "feature             BTCUSD:weekday BTCUSD:hour BTCUSD:minute   \n",
       "timestamp                                                      \n",
       "2021-09-01 01:30:00      -0.003076   -1.662613          -1.0   \n",
       "2021-09-01 02:00:00      -0.003076   -1.662613           1.0   \n",
       "2021-09-01 02:30:00      -0.003076   -1.517929          -1.0   \n",
       "2021-09-01 03:00:00      -0.003076   -1.517929           1.0   \n",
       "2021-09-01 03:30:00      -0.003076   -1.373245          -1.0   \n",
       "\n",
       "time_step                                                                  \\\n",
       "feature             BTCUSD:upper_shadow BTCUSD:lower_shadow BTCUSD:return   \n",
       "timestamp                                                                   \n",
       "2021-09-01 01:30:00            0.272382           -0.344248      0.367626   \n",
       "2021-09-01 02:00:00            1.482079           -0.838114     -0.274886   \n",
       "2021-09-01 02:30:00             0.09279           -0.050609     -0.230078   \n",
       "2021-09-01 03:00:00           -0.792066           -0.003061      0.948749   \n",
       "2021-09-01 03:30:00           -0.402557           -0.069069      0.438649   \n",
       "\n",
       "time_step                                                     \\\n",
       "feature             ETHUSD:weekday ETHUSD:hour ETHUSD:minute   \n",
       "timestamp                                                      \n",
       "2021-09-01 01:30:00      -0.003076   -1.662613          -1.0   \n",
       "2021-09-01 02:00:00      -0.003076   -1.662613           1.0   \n",
       "2021-09-01 02:30:00      -0.003076   -1.517929          -1.0   \n",
       "2021-09-01 03:00:00      -0.003076   -1.517929           1.0   \n",
       "2021-09-01 03:30:00      -0.003076   -1.373245          -1.0   \n",
       "\n",
       "time_step                                ...            -1  \\\n",
       "feature             ETHUSD:upper_shadow  ... LTCUSD:minute   \n",
       "timestamp                                ...                 \n",
       "2021-09-01 01:30:00            0.101196  ...          -1.0   \n",
       "2021-09-01 02:00:00            2.108089  ...           1.0   \n",
       "2021-09-01 02:30:00              0.5739  ...          -1.0   \n",
       "2021-09-01 03:00:00           -0.693713  ...           1.0   \n",
       "2021-09-01 03:30:00           -0.541873  ...          -1.0   \n",
       "\n",
       "time_step                                                                  \\\n",
       "feature             LTCUSD:upper_shadow LTCUSD:lower_shadow LTCUSD:return   \n",
       "timestamp                                                                   \n",
       "2021-09-01 01:30:00            0.247703           -0.356995     -0.691235   \n",
       "2021-09-01 02:00:00           -0.676376            0.086697      0.736124   \n",
       "2021-09-01 02:30:00           -0.849824           -0.029284      0.450547   \n",
       "2021-09-01 03:00:00            0.508944           -0.675575      0.071885   \n",
       "2021-09-01 03:30:00            1.236206            0.260103     -0.531665   \n",
       "\n",
       "time_step                                                     \\\n",
       "feature             RPLUSD:weekday RPLUSD:hour RPLUSD:minute   \n",
       "timestamp                                                      \n",
       "2021-09-01 01:30:00      -0.003076   -1.517929          -1.0   \n",
       "2021-09-01 02:00:00      -0.003076   -1.517929           1.0   \n",
       "2021-09-01 02:30:00      -0.003076   -1.373245          -1.0   \n",
       "2021-09-01 03:00:00      -0.003076   -1.373245           1.0   \n",
       "2021-09-01 03:30:00      -0.003076   -1.228561          -1.0   \n",
       "\n",
       "time_step                                                                  \n",
       "feature             RPLUSD:upper_shadow RPLUSD:lower_shadow RPLUSD:return  \n",
       "timestamp                                                                  \n",
       "2021-09-01 01:30:00            0.042302             1.24257     -2.245317  \n",
       "2021-09-01 02:00:00           -0.388771            0.235062      1.631002  \n",
       "2021-09-01 02:30:00            0.136139            1.074724      0.541948  \n",
       "2021-09-01 03:00:00            3.148526            -0.76391      0.835947  \n",
       "2021-09-01 03:30:00            2.070256            2.147994      0.002064  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aInputSymbols = dfCrpytocurrencies['Symbol'].values\n",
    "aInputFeatures = ['weekday', 'hour', 'minute' ,'upper_shadow', 'lower_shadow' ,'return']\n",
    "aInputFeatures = list(map(\":\".join, itertools.product(aInputSymbols, aInputFeatures)))\n",
    "\n",
    "iNrInputFeatures = len(aInputFeatures)\n",
    "\n",
    "aBackwardTimeSteps = range(-iBackwardTimeWindow, 0)\n",
    "\n",
    "aTplInputColumns = list(itertools.product(aBackwardTimeSteps, aInputFeatures))\n",
    "aIxInputColumns = pd.MultiIndex.from_tuples(aTplInputColumns, names= ['time_step', 'feature'])\n",
    "\n",
    "dfInput = pd.DataFrame(columns = aIxInputColumns)\n",
    "\n",
    "for tplColumn in list(dfInput.columns):\n",
    "    dfInput.loc[:, tplColumn] = dfScaledOhlc[(tplColumn[1])].shift(-tplColumn[0])\n",
    "\n",
    "    \n",
    "ixNas = dfInput[dfInput.isna().any(axis=1)].index\n",
    "dfInput.drop(ixNas, inplace = True, errors = 'ignore') \n",
    "ixTrain= ixTrain.drop(ixNas, errors = 'ignore') \n",
    "ixValidation= ixValidation.drop(ixNas,   errors = 'ignore') \n",
    "ixTest = ixTest.drop(ixNas,   errors = 'ignore') \n",
    "\n",
    "dfInput.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8011a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Output Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce152a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>time_step</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th>BTCUSD:return</th>\n",
       "      <th>BTCUSD:return</th>\n",
       "      <th>BTCUSD:return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-01 00:00:00</th>\n",
       "      <td>0.001941</td>\n",
       "      <td>-0.001465</td>\n",
       "      <td>-0.001227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 00:30:00</th>\n",
       "      <td>-0.001465</td>\n",
       "      <td>-0.001227</td>\n",
       "      <td>0.005021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 01:00:00</th>\n",
       "      <td>-0.001227</td>\n",
       "      <td>0.005021</td>\n",
       "      <td>0.002318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 01:30:00</th>\n",
       "      <td>0.005021</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>-0.002022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 02:00:00</th>\n",
       "      <td>0.002318</td>\n",
       "      <td>-0.002022</td>\n",
       "      <td>-0.001229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "time_step                       0             1             2\n",
       "feature             BTCUSD:return BTCUSD:return BTCUSD:return\n",
       "timestamp                                                    \n",
       "2021-09-01 00:00:00      0.001941     -0.001465     -0.001227\n",
       "2021-09-01 00:30:00     -0.001465     -0.001227      0.005021\n",
       "2021-09-01 01:00:00     -0.001227      0.005021      0.002318\n",
       "2021-09-01 01:30:00      0.005021      0.002318     -0.002022\n",
       "2021-09-01 02:00:00      0.002318     -0.002022     -0.001229"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aOutputFeatures = ['return']\n",
    "aOutputFeatures = list(map(\":\".join, itertools.product([sOutputSymbol], aOutputFeatures)))\n",
    "iNrOutputFeatures = len(aOutputFeatures)\n",
    "\n",
    "aForwardTimeSteps = range(0, iForwardTimeWindow)\n",
    "\n",
    "\n",
    "aTplOutputColumns = list(itertools.product(aForwardTimeSteps, aOutputFeatures))\n",
    "aIxOutputColumns = pd.MultiIndex.from_tuples(aTplOutputColumns, names= ['time_step', 'feature'])\n",
    "\n",
    "dfOutput = pd.DataFrame(columns = aIxOutputColumns)\n",
    "\n",
    "for tplColumn in list(dfOutput.columns):\n",
    "    dfOutput.loc[:, tplColumn] =  dfOhlc[(tplColumn[1])].shift(-tplColumn[0])\n",
    "\n",
    "ixNas = dfOutput[dfOutput.isna().any(axis=1)].index\n",
    "dfOutput.drop(ixNas, inplace = True, errors = 'ignore') \n",
    "ixTrain= ixTrain.drop(ixNas, errors = 'ignore') \n",
    "ixValidation= ixValidation.drop(ixNas,   errors = 'ignore') \n",
    "ixTest = ixTest.drop(ixNas,   errors = 'ignore') \n",
    "dfOutput.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802a6d3a-353a-45c3-a8eb-f49af789c4a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Reshape Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "296eec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "axMerged = dfInput.index.join(dfOutput.index, how = 'inner')\n",
    "\n",
    "dfInput = dfInput.loc[axMerged]\n",
    "dfOutput = dfOutput.loc[axMerged]\n",
    "\n",
    "ixTrain = ixTrain.join(axMerged, how = \"inner\")\n",
    "ixValidation = ixValidation.join(axMerged, how = \"inner\")\n",
    "ixTest = ixTest.join(axMerged, how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96e399d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInputTrain = dfInput.loc[ixTrain]\n",
    "aInputTrain = np.reshape(dfInputTrain.values, (dfInputTrain.shape[0], iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "dfInputValidation = dfInput.loc[ixValidation]\n",
    "aInputValidation = np.reshape(dfInputValidation.values, (dfInputValidation.shape[0], iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "dfInputTest = dfInput.loc[ixTest]\n",
    "aInputTest = np.reshape(dfInputTest.values, (dfInputTest.shape[0], iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "dfOutputTrain = dfOutput.loc[ixTrain]\n",
    "aOutputTrain = np.reshape(dfOutputTrain.values, (dfOutputTrain.shape[0], iForwardTimeWindow, iNrOutputFeatures))\n",
    "\n",
    "dfOutputValidation = dfOutput.loc[ixValidation]\n",
    "aOutputValidation = np.reshape(dfOutputValidation.values, (dfOutputValidation.shape[0], iForwardTimeWindow, iNrOutputFeatures))\n",
    "\n",
    "dfOutputTest = dfOutput.loc[ixTest]\n",
    "aOutputTest = np.reshape(dfOutputTest.values, (dfOutputTest.shape[0], iForwardTimeWindow, iNrOutputFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76ce37ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "aInputTrain = np.asarray(aInputTrain, np.float32)\n",
    "aInputValidation = np.asarray(aInputValidation, np.float32)\n",
    "aInputTest = np.asarray(aInputTest, np.float32)\n",
    "aOutputTrain = np.asarray(aOutputTrain, np.float32)\n",
    "aOutputValidation = np.asarray(aOutputValidation, np.float32)\n",
    "aOutputTest = np.asarray(aOutputTest, np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52944fb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  MODEL DEVELOPMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e253bd8c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a484f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "iEpochSize = 10000\n",
    "oEarlyStop = EarlyStopping(\n",
    "    monitor = 'val_loss', \n",
    "    mode = 'min', \n",
    "    verbose = 0 , \n",
    "    patience = 20, \n",
    "    restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27edd3cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "032b92b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fCalculateLoss(aActual, aPrediction):\n",
    "    aErrors = tf.abs(\n",
    "        tf.subtract(aActual, aPrediction) \n",
    "    ) #(row: iBatchSize, col: iForwardTimeWindow-1)\n",
    "\n",
    "    fBiggestError = tf.math.reduce_max(aErrors)\n",
    "    \n",
    "    aLossesDueToErrors = tf.reduce_sum(aErrors, 0) #(row: 1, col: iForwardTimeWindow)\n",
    "    \n",
    "    \n",
    "    aDeltaSignsOfReturns = tf.abs(\n",
    "        tf.sign(aActual) - tf.sign(aPrediction)\n",
    "    ) # will be between [0 : no sign diff, 2: diff signs]  (row: iBatchSize, col: iForwardTimeWindow)\n",
    "    \n",
    "    aLossesDueToSignsOfReturns = tf.math.reduce_sum(aDeltaSignsOfReturns, 0) #(row: 1, col: iForwardTimeWindow)\n",
    "    aTotalLosses = aLossesDueToErrors * aLossesDueToSignsOfReturns * fBiggestError\n",
    "    \n",
    "    fLoss = tf.math.reduce_mean(aTotalLosses)\n",
    "    \n",
    "    return fLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75b209e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a48d744-a348-4435-b0c7-88054f26e20e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fa552d5-8eb4-4008-b068-b6d5683a8fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sModelType == 'MLP':\n",
    "    aInputMlp = keras.Input(\n",
    "        shape=(iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "    aW = keras.layers.Flatten()(aInputMlp)\n",
    "    aW = keras.layers.Dense(iNrOfHiddenNeurons)(aW)\n",
    "    aW = keras.layers.Dense(iForwardTimeWindow*iNrOutputFeatures)(aW)\n",
    "    aW = keras.layers.Reshape((iForwardTimeWindow, iNrOutputFeatures))(aW)\n",
    "\n",
    "    aOutputMlp = aW\n",
    "    oModelMlp = keras.Model(\n",
    "        inputs=aInputMlp,\n",
    "        outputs=aOutputMlp\n",
    "    )\n",
    "\n",
    "    oOptimizerMlp = tf.keras.optimizers.Adam(learning_rate=1e-04)\n",
    "    oModelMlp.compile(optimizer=oOptimizerMlp,\n",
    "                             loss = fCalculateLoss\n",
    "                            )\n",
    "\n",
    "    oPredictiveModel = oModelMlp\n",
    "\n",
    "    tf.keras.utils.plot_model(oModelMlp,  show_shapes=True, to_file=sModelName +'\\Model architecture.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66367dfb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e48a9a2-527b-4226-98d8-39d7d4a79c8e",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "if sModelType == 'LSTM':\n",
    "    aInputDeepLstm = keras.Input(\n",
    "        shape=(iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "    aW = keras.layers.LSTM(64, return_sequences = True)(aInputDeepLstm)\n",
    "    aW = keras.layers.Flatten()(aW)\n",
    "    aW = keras.layers.Dense(iForwardTimeWindow*iNrOutputFeatures)(aW)\n",
    "    aW = keras.layers.Reshape((iForwardTimeWindow, iNrOutputFeatures))(aW)\n",
    "\n",
    "    aOutputDeepLstm = aW\n",
    "    oModelDeepLstm = keras.Model(\n",
    "        inputs=aInputDeepLstm,\n",
    "        outputs=aOutputDeepLstm\n",
    "    )\n",
    "\n",
    "    oOptimizerDeepLstm = tf.keras.optimizers.Adam(learning_rate=1e-04)\n",
    "    oModelDeepLstm.compile(optimizer=oOptimizerDeepLstm,\n",
    "                             loss = fCalculateLoss\n",
    "                            )\n",
    "\n",
    "    oPredictiveModel = oModelDeepLstm\n",
    "\n",
    "    tf.keras.utils.plot_model(oModelDeepLstm,  show_shapes=True, to_file=sModelName+'\\Model architecture.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f365ab5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Deep CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6776588",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sModelType == 'Deep CNN':\n",
    "    aInputDeepCnn = keras.Input(\n",
    "        shape=(iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "    aW = keras.layers.LSTM(64, return_sequences = True)(aInputDeepCnn)\n",
    "    aW = keras.layers.Flatten()(aW)\n",
    "    aW = keras.layers.Dense(iNrOfBins*iForwardTimeWindow*iNrOutputFeatures)(aW)\n",
    "    aW = keras.layers.Reshape((iNrOutputFeatures * iNrOfBins, iForwardTimeWindow, 1))(aW)\n",
    "    aW = keras.layers.Conv2D(64, (4,4), (1,1), padding = \"same\" )(aW)\n",
    "    aW = keras.layers.MaxPool2D(pool_size = (4, 4))(aW)\n",
    "    aW = keras.layers.Flatten()(aW)\n",
    "    aW = keras.layers.Dense(iNrOfBins*iForwardTimeWindow*iNrOutputFeatures)(aW)\n",
    "    aW = keras.layers.Reshape((iNrOutputFeatures, iNrOfBins, iForwardTimeWindow))(aW)\n",
    "\n",
    "    aOutputDeepCnn = aW\n",
    "    oModelDeepCnn = keras.Model(\n",
    "        inputs=aInputDeepCnn,\n",
    "        outputs=aOutputDeepCnn\n",
    "    )\n",
    "\n",
    "    oOptimizerDeepCnn = tf.keras.optimizers.Adam(learning_rate=1e-05)\n",
    "    oModelDeepCnn.compile(optimizer=oOptimizerDeepCnn,\n",
    "                             loss = fCalculateLoss\n",
    "                            )\n",
    "\n",
    "    tf.keras.utils.plot_model(oModelDeepCnn,  show_shapes=True, to_file=sModelName+'\\Model architecture.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11b935e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Convolutional Encoder-Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf77ce35-7d29-43c1-990e-a80a0fef20fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sModelType == 'Convolutional Encoder Decoder':\n",
    "    aInputs = keras.Input(\n",
    "        shape=(iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "    aEncoderHiddens, aFinalH, aFinalC = keras.layers.LSTM(iNrOfHiddenNeurons,\n",
    "                                             return_state = True, \n",
    "                                             return_sequences = True\n",
    "                                            )(aInputs)\n",
    "    aFinalH = keras.layers.BatchNormalization()(aFinalH)\n",
    "    aFinalC = keras.layers.BatchNormalization()(aFinalC)\n",
    "\n",
    "    aFeatureMap = keras.layers.Conv1D(64, 2)(aEncoderHiddens)\n",
    "    aFeatureMap = keras.layers.MaxPooling1D(2)(aFeatureMap)\n",
    "    aFlatted = keras.layers.Flatten()(aFeatureMap)\n",
    "\n",
    "    aDecoderInputs = keras.layers.RepeatVector(iForwardTimeWindow)(aFlatted)\n",
    "\n",
    "    aDecoderHiddens = keras.layers.LSTM(iNrOfHiddenNeurons, \n",
    "                           return_state = False, \n",
    "                           return_sequences = True\n",
    "                          )(aDecoderInputs, initial_state=[aFinalH, aFinalC])\n",
    "\n",
    "\n",
    "    aOutputs = keras.layers.TimeDistributed(\n",
    "        Dense(iNrOutputFeatures)\n",
    "    )(aDecoderHiddens)\n",
    "\n",
    "    oPredictiveModel = keras.Model(\n",
    "        inputs=aInputs,\n",
    "        outputs=aOutputs\n",
    "    )\n",
    "\n",
    "    oOptimizer = tf.keras.optimizers.Adam(learning_rate=1e-05)\n",
    "    oPredictiveModel.compile(loss = fCalculateLoss,\n",
    "                             optimizer=oOptimizer\n",
    "                            )\n",
    "\n",
    "    tf.keras.utils.plot_model(oPredictiveModel,  show_shapes=True, to_file=sModelName+'\\Model architecture.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1ed1a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Luong's Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6b49d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sModelType == 'Luongs Attention':\n",
    "    aEncoderInputs = keras.Input(\n",
    "        shape=(iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "    aEncoderHiddens, aFinalH, aFinalC = keras.layers.LSTM(iNrOfHiddenNeurons,\n",
    "                                             return_state = True, \n",
    "                                             return_sequences = True\n",
    "                                            )(aEncoderInputs)\n",
    "    aFinalH = keras.layers.BatchNormalization()(aFinalH)\n",
    "    aFinalC = keras.layers.BatchNormalization()(aFinalC)\n",
    "\n",
    "    aDecoderInputs = keras.layers.RepeatVector(iForwardTimeWindow)(aFinalH)\n",
    "\n",
    "    aDecoderHiddens = keras.layers.LSTM(iNrOfHiddenNeurons, \n",
    "                           return_state = False, \n",
    "                           return_sequences = True\n",
    "                          )(aDecoderInputs, initial_state=[aFinalH, aFinalC])\n",
    "\n",
    "    aAttentions = keras.layers.dot([aDecoderHiddens, aEncoderHiddens], axes=[2, 2])\n",
    "    aAttentions = keras.layers.Activation('softmax')(aAttentions)\n",
    "\n",
    "    aContextVector = keras.layers.dot([aAttentions, aEncoderHiddens], axes=[2,1])\n",
    "    aContextVector = keras.layers.BatchNormalization()(aContextVector)\n",
    "    aContextVector = keras.layers.concatenate([aContextVector, aDecoderHiddens])\n",
    "\n",
    "    aDecoderOutputs = keras.layers.TimeDistributed(\n",
    "        Dense(iNrOutputFeatures)\n",
    "    )(aContextVector)\n",
    "\n",
    "    oPredictiveModel = keras.Model(\n",
    "        inputs=aEncoderInputs,\n",
    "        outputs=aDecoderOutputs\n",
    "    )\n",
    "\n",
    "    oOptimizer = tf.keras.optimizers.Adam(learning_rate=1e-05)\n",
    "    oPredictiveModel.compile(loss = fCalculateLoss, \n",
    "                             optimizer=oOptimizer\n",
    "                            )\n",
    "\n",
    "    tf.keras.utils.plot_model(oPredictiveModel,  show_shapes=True+'\\Model architecture.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedaa4fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3871f87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "24/24 [==============================] - 1s 14ms/step - loss: 305315.0625 - val_loss: 136549.6562\n",
      "Epoch 2/10000\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 203488.4688 - val_loss: 91571.0156\n",
      "Epoch 3/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 147257.0938 - val_loss: 68055.0547\n",
      "Epoch 4/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 129165.6094 - val_loss: 58129.6484\n",
      "Epoch 5/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 109784.2734 - val_loss: 50447.8242\n",
      "Epoch 6/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 95484.9609 - val_loss: 44563.6914\n",
      "Epoch 7/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 83226.4688 - val_loss: 41329.9570\n",
      "Epoch 8/10000\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 73667.7266 - val_loss: 38591.5742\n",
      "Epoch 9/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 67474.0703 - val_loss: 35659.1641\n",
      "Epoch 10/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 60528.0078 - val_loss: 33541.3125\n",
      "Epoch 11/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 54255.2031 - val_loss: 31807.0117\n",
      "Epoch 12/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 50398.1992 - val_loss: 30030.8438\n",
      "Epoch 13/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 44241.5234 - val_loss: 27553.5684\n",
      "Epoch 14/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 41596.2070 - val_loss: 26046.6836\n",
      "Epoch 15/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 37150.9102 - val_loss: 23945.2754\n",
      "Epoch 16/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 34793.3672 - val_loss: 22819.5684\n",
      "Epoch 17/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 31347.2012 - val_loss: 21363.8848\n",
      "Epoch 18/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 28075.5586 - val_loss: 20460.7617\n",
      "Epoch 19/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 28165.5059 - val_loss: 19690.0449\n",
      "Epoch 20/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 25392.9688 - val_loss: 18731.2578\n",
      "Epoch 21/10000\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25432.4414 - val_loss: 18224.7559\n",
      "Epoch 22/10000\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23132.1777 - val_loss: 17275.0703\n",
      "Epoch 23/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 22964.9766 - val_loss: 16444.6953\n",
      "Epoch 24/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 21083.1582 - val_loss: 15534.1943\n",
      "Epoch 25/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20969.3379 - val_loss: 14943.4502\n",
      "Epoch 26/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 19015.3613 - val_loss: 14269.2490\n",
      "Epoch 27/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 17953.7402 - val_loss: 13651.4619\n",
      "Epoch 28/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 17635.4199 - val_loss: 13036.6396\n",
      "Epoch 29/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 16633.5020 - val_loss: 12702.8340\n",
      "Epoch 30/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 15316.7949 - val_loss: 11948.7510\n",
      "Epoch 31/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 15519.8037 - val_loss: 11518.6006\n",
      "Epoch 32/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 14881.5303 - val_loss: 11098.9590\n",
      "Epoch 33/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 13688.5908 - val_loss: 10865.3828\n",
      "Epoch 34/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 13252.4805 - val_loss: 10514.5879\n",
      "Epoch 35/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 12037.3877 - val_loss: 10074.1631\n",
      "Epoch 36/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 11392.6172 - val_loss: 9806.2812\n",
      "Epoch 37/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 11952.8672 - val_loss: 9435.1074\n",
      "Epoch 38/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 10936.3086 - val_loss: 9186.8818\n",
      "Epoch 39/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 10538.4287 - val_loss: 8821.7646\n",
      "Epoch 40/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 10071.4619 - val_loss: 8386.2988\n",
      "Epoch 41/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 9499.6357 - val_loss: 8034.0771\n",
      "Epoch 42/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 9614.2002 - val_loss: 7677.2769\n",
      "Epoch 43/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8584.0303 - val_loss: 7538.7041\n",
      "Epoch 44/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8474.8174 - val_loss: 7157.7856\n",
      "Epoch 45/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8206.3242 - val_loss: 6847.5825\n",
      "Epoch 46/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7524.2100 - val_loss: 6696.6831\n",
      "Epoch 47/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7260.4224 - val_loss: 6376.6909\n",
      "Epoch 48/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7410.1104 - val_loss: 6175.7798\n",
      "Epoch 49/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6854.0757 - val_loss: 5913.6685\n",
      "Epoch 50/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6183.1802 - val_loss: 5708.5200\n",
      "Epoch 51/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6153.9355 - val_loss: 5526.7466\n",
      "Epoch 52/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5935.5015 - val_loss: 5339.3545\n",
      "Epoch 53/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5755.6011 - val_loss: 5064.4263\n",
      "Epoch 54/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5615.6880 - val_loss: 4928.2173\n",
      "Epoch 55/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5278.1587 - val_loss: 4683.5508\n",
      "Epoch 56/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5016.1191 - val_loss: 4518.2021\n",
      "Epoch 57/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4662.3818 - val_loss: 4235.1929\n",
      "Epoch 58/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4593.3491 - val_loss: 4041.2300\n",
      "Epoch 59/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4327.2358 - val_loss: 3994.1853\n",
      "Epoch 60/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4185.4409 - val_loss: 3789.3157\n",
      "Epoch 61/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3964.2151 - val_loss: 3705.9910\n",
      "Epoch 62/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3809.8364 - val_loss: 3509.5327\n",
      "Epoch 63/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3746.2471 - val_loss: 3388.2300\n",
      "Epoch 64/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3480.5146 - val_loss: 3213.9224\n",
      "Epoch 65/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3283.5620 - val_loss: 3097.7134\n",
      "Epoch 66/10000\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3126.5659 - val_loss: 3012.3147\n",
      "Epoch 67/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3015.4724 - val_loss: 2906.1875\n",
      "Epoch 68/10000\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2903.9622 - val_loss: 2769.9219\n",
      "Epoch 69/10000\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2820.1392 - val_loss: 2669.4248\n",
      "Epoch 70/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 2603.2522 - val_loss: 2566.0471\n",
      "Epoch 71/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2480.3569 - val_loss: 2515.1772\n",
      "Epoch 72/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2404.8420 - val_loss: 2446.1597\n",
      "Epoch 73/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2250.6658 - val_loss: 2359.7646\n",
      "Epoch 74/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2231.2480 - val_loss: 2220.0002\n",
      "Epoch 75/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2032.1766 - val_loss: 2165.6292\n",
      "Epoch 76/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2039.9695 - val_loss: 2066.5645\n",
      "Epoch 77/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1944.5913 - val_loss: 1992.9836\n",
      "Epoch 78/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1882.9637 - val_loss: 1860.5699\n",
      "Epoch 79/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1783.3905 - val_loss: 1830.6067\n",
      "Epoch 80/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1675.9993 - val_loss: 1729.3309\n",
      "Epoch 81/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1611.6909 - val_loss: 1627.4357\n",
      "Epoch 82/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1581.4580 - val_loss: 1557.3041\n",
      "Epoch 83/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1449.6661 - val_loss: 1523.3817\n",
      "Epoch 84/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1440.2208 - val_loss: 1449.8794\n",
      "Epoch 85/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1387.9200 - val_loss: 1396.0824\n",
      "Epoch 86/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1324.6415 - val_loss: 1350.3257\n",
      "Epoch 87/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1224.8673 - val_loss: 1231.4106\n",
      "Epoch 88/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1151.2432 - val_loss: 1246.9620\n",
      "Epoch 89/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1124.8860 - val_loss: 1203.1305\n",
      "Epoch 90/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1076.3535 - val_loss: 1132.0800\n",
      "Epoch 91/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 985.5800 - val_loss: 1063.6078\n",
      "Epoch 92/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 979.4078 - val_loss: 1050.7505\n",
      "Epoch 93/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 959.6156 - val_loss: 1033.1913\n",
      "Epoch 94/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 855.0880 - val_loss: 914.2556\n",
      "Epoch 95/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 825.6818 - val_loss: 886.9172\n",
      "Epoch 96/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 803.5486 - val_loss: 841.4392\n",
      "Epoch 97/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 776.2930 - val_loss: 819.8857\n",
      "Epoch 98/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 750.4234 - val_loss: 790.9369\n",
      "Epoch 99/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 711.5371 - val_loss: 759.8198\n",
      "Epoch 100/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 682.6307 - val_loss: 754.9597\n",
      "Epoch 101/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 638.1137 - val_loss: 741.4512\n",
      "Epoch 102/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 610.5670 - val_loss: 702.6491\n",
      "Epoch 103/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 575.6356 - val_loss: 638.1362\n",
      "Epoch 104/10000\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 537.8215 - val_loss: 614.3472\n",
      "Epoch 105/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 550.1489 - val_loss: 577.7095\n",
      "Epoch 106/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 509.2849 - val_loss: 577.6515\n",
      "Epoch 107/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 473.3162 - val_loss: 541.6887\n",
      "Epoch 108/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 473.9324 - val_loss: 510.6521\n",
      "Epoch 109/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 451.8255 - val_loss: 489.9449\n",
      "Epoch 110/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 437.1285 - val_loss: 465.9212\n",
      "Epoch 111/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 405.8748 - val_loss: 451.0933\n",
      "Epoch 112/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 388.2238 - val_loss: 443.2230\n",
      "Epoch 113/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 364.3704 - val_loss: 414.7125\n",
      "Epoch 114/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 354.7745 - val_loss: 385.8452\n",
      "Epoch 115/10000\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 333.2267 - val_loss: 371.9935\n",
      "Epoch 116/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 316.9496 - val_loss: 350.8939\n",
      "Epoch 117/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 298.5740 - val_loss: 345.4669\n",
      "Epoch 118/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 293.2657 - val_loss: 330.1854\n",
      "Epoch 119/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 285.6302 - val_loss: 317.2106\n",
      "Epoch 120/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 267.1120 - val_loss: 294.2219\n",
      "Epoch 121/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 260.4552 - val_loss: 274.6758\n",
      "Epoch 122/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 229.0408 - val_loss: 269.0857\n",
      "Epoch 123/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 218.8927 - val_loss: 236.8632\n",
      "Epoch 124/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 216.4713 - val_loss: 245.8840\n",
      "Epoch 125/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 201.3223 - val_loss: 242.7192\n",
      "Epoch 126/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 193.4777 - val_loss: 218.9158\n",
      "Epoch 127/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 186.1803 - val_loss: 196.2506\n",
      "Epoch 128/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 172.6315 - val_loss: 185.7690\n",
      "Epoch 129/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 168.7823 - val_loss: 191.7042\n",
      "Epoch 130/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 156.4748 - val_loss: 175.1870\n",
      "Epoch 131/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 146.1060 - val_loss: 169.4171\n",
      "Epoch 132/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 143.8034 - val_loss: 160.6229\n",
      "Epoch 133/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 134.0780 - val_loss: 156.5511\n",
      "Epoch 134/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 125.4601 - val_loss: 142.5326\n",
      "Epoch 135/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 119.9914 - val_loss: 133.0338\n",
      "Epoch 136/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 112.8253 - val_loss: 132.8970\n",
      "Epoch 137/10000\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 110.7694 - val_loss: 126.0773\n",
      "Epoch 138/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 112.2398 - val_loss: 120.2860\n",
      "Epoch 139/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 98.4204 - val_loss: 117.9082\n",
      "Epoch 140/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 95.7972 - val_loss: 101.9121\n",
      "Epoch 141/10000\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 91.0381 - val_loss: 94.8150\n",
      "Epoch 142/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 83.8883 - val_loss: 94.3859\n",
      "Epoch 143/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 80.8561 - val_loss: 88.4945\n",
      "Epoch 144/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 75.8510 - val_loss: 85.1984\n",
      "Epoch 145/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 69.5080 - val_loss: 80.4142\n",
      "Epoch 146/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 68.0656 - val_loss: 80.4991\n",
      "Epoch 147/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 63.1222 - val_loss: 70.7383\n",
      "Epoch 148/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 61.3193 - val_loss: 69.9431\n",
      "Epoch 149/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 58.4569 - val_loss: 66.9402\n",
      "Epoch 150/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 55.1365 - val_loss: 62.7836\n",
      "Epoch 151/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 51.8136 - val_loss: 62.3124\n",
      "Epoch 152/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 50.5113 - val_loss: 54.1233\n",
      "Epoch 153/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 51.9196 - val_loss: 59.5904\n",
      "Epoch 154/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 47.4751 - val_loss: 53.2474\n",
      "Epoch 155/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 47.8816 - val_loss: 49.8307\n",
      "Epoch 156/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 43.4126 - val_loss: 46.3997\n",
      "Epoch 157/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 38.6975 - val_loss: 45.5429\n",
      "Epoch 158/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 37.0744 - val_loss: 38.6124\n",
      "Epoch 159/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 32.4267 - val_loss: 37.9516\n",
      "Epoch 160/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 32.3786 - val_loss: 37.2371\n",
      "Epoch 161/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 31.0070 - val_loss: 31.9271\n",
      "Epoch 162/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 29.4870 - val_loss: 35.9205\n",
      "Epoch 163/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 30.1599 - val_loss: 29.5710\n",
      "Epoch 164/10000\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 28.2885 - val_loss: 31.2913\n",
      "Epoch 165/10000\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 28.4247 - val_loss: 27.6967\n",
      "Epoch 166/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 25.6102 - val_loss: 28.9777\n",
      "Epoch 167/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.1472 - val_loss: 25.2668\n",
      "Epoch 168/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 22.6367 - val_loss: 22.4423\n",
      "Epoch 169/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.4223 - val_loss: 20.4801\n",
      "Epoch 170/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 22.0509 - val_loss: 23.0941\n",
      "Epoch 171/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 19.7217 - val_loss: 19.8688\n",
      "Epoch 172/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 17.9863 - val_loss: 19.4192\n",
      "Epoch 173/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 17.5650 - val_loss: 16.7751\n",
      "Epoch 174/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 17.4732 - val_loss: 17.8108\n",
      "Epoch 175/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 17.9816 - val_loss: 17.0916\n",
      "Epoch 176/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 14.8250 - val_loss: 15.6139\n",
      "Epoch 177/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 16.1532 - val_loss: 16.3239\n",
      "Epoch 178/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 16.4911 - val_loss: 13.9751\n",
      "Epoch 179/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 15.2266 - val_loss: 14.8812\n",
      "Epoch 180/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 14.9803 - val_loss: 13.6968\n",
      "Epoch 181/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 12.9102 - val_loss: 12.1975\n",
      "Epoch 182/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 11.6196 - val_loss: 11.5741\n",
      "Epoch 183/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 11.5061 - val_loss: 14.1239\n",
      "Epoch 184/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 11.1672 - val_loss: 10.6363\n",
      "Epoch 185/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 11.0786 - val_loss: 11.2769\n",
      "Epoch 186/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 11.5748 - val_loss: 10.8008\n",
      "Epoch 187/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 10.4686 - val_loss: 10.2487\n",
      "Epoch 188/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 10.2626 - val_loss: 9.8001\n",
      "Epoch 189/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 9.8654 - val_loss: 9.5868\n",
      "Epoch 190/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 9.0933 - val_loss: 9.3277\n",
      "Epoch 191/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 9.8874 - val_loss: 9.3071\n",
      "Epoch 192/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 9.0258 - val_loss: 8.4615\n",
      "Epoch 193/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.7835 - val_loss: 8.7928\n",
      "Epoch 194/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.5749 - val_loss: 7.8661\n",
      "Epoch 195/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.5732 - val_loss: 7.6168\n",
      "Epoch 196/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.1739 - val_loss: 7.7858\n",
      "Epoch 197/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.4744 - val_loss: 7.8589\n",
      "Epoch 198/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.8355 - val_loss: 7.2254\n",
      "Epoch 199/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.6921 - val_loss: 8.0978\n",
      "Epoch 200/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.2169 - val_loss: 6.7837\n",
      "Epoch 201/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.3397 - val_loss: 6.8288\n",
      "Epoch 202/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.0651 - val_loss: 6.8173\n",
      "Epoch 203/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.3322 - val_loss: 6.5888\n",
      "Epoch 204/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.9207 - val_loss: 6.7002\n",
      "Epoch 205/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.6141 - val_loss: 5.8024\n",
      "Epoch 206/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.8603 - val_loss: 6.9487\n",
      "Epoch 207/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.0738 - val_loss: 5.8998\n",
      "Epoch 208/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.5653 - val_loss: 6.8654\n",
      "Epoch 209/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.1535 - val_loss: 5.8022\n",
      "Epoch 210/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.5027 - val_loss: 5.8627\n",
      "Epoch 211/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.2277 - val_loss: 5.9950\n",
      "Epoch 212/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.1083 - val_loss: 6.1667\n",
      "Epoch 213/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.1885 - val_loss: 6.2355\n",
      "Epoch 214/10000\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.8266 - val_loss: 5.4562\n",
      "Epoch 215/10000\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.6001 - val_loss: 6.1516\n",
      "Epoch 216/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.7551 - val_loss: 5.4031\n",
      "Epoch 217/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.7561 - val_loss: 5.5548\n",
      "Epoch 218/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.1305 - val_loss: 5.8555\n",
      "Epoch 219/10000\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.6314 - val_loss: 5.2803\n",
      "Epoch 220/10000\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.9394 - val_loss: 5.5967\n",
      "Epoch 221/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.4692 - val_loss: 5.4125\n",
      "Epoch 222/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.1882 - val_loss: 5.3665\n",
      "Epoch 223/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.3242 - val_loss: 6.1128\n",
      "Epoch 224/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.8286 - val_loss: 5.3674\n",
      "Epoch 225/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.8693 - val_loss: 5.5225\n",
      "Epoch 226/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.4086 - val_loss: 6.0732\n",
      "Epoch 227/10000\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3728 - val_loss: 5.1173\n",
      "Epoch 228/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5.8005 - val_loss: 5.5140\n",
      "Epoch 229/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.8624 - val_loss: 5.4701\n",
      "Epoch 230/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.1772 - val_loss: 5.3419\n",
      "Epoch 231/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.0486 - val_loss: 5.7325\n",
      "Epoch 232/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.8772 - val_loss: 5.4415\n",
      "Epoch 233/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.1197 - val_loss: 6.3311\n",
      "Epoch 234/10000\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.7408 - val_loss: 5.0472\n",
      "Epoch 235/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.3508 - val_loss: 5.9418\n",
      "Epoch 236/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.4919 - val_loss: 6.1739\n",
      "Epoch 237/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.8652 - val_loss: 5.2434\n",
      "Epoch 238/10000\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.4537 - val_loss: 5.4930\n",
      "Epoch 239/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5.9858 - val_loss: 6.0790\n",
      "Epoch 240/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5.5995 - val_loss: 5.2300\n",
      "Epoch 241/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5.9151 - val_loss: 5.7842\n",
      "Epoch 242/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.9179 - val_loss: 6.4545\n",
      "Epoch 243/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.6667 - val_loss: 6.3895\n",
      "Epoch 244/10000\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.9733 - val_loss: 5.2161\n",
      "Epoch 245/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 5.8191 - val_loss: 5.3746\n",
      "Epoch 246/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.0076 - val_loss: 5.7675\n",
      "Epoch 247/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.5043 - val_loss: 7.6752\n",
      "Epoch 248/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.8505 - val_loss: 6.2162\n",
      "Epoch 249/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.1438 - val_loss: 5.1930\n",
      "Epoch 250/10000\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.8119 - val_loss: 5.0255\n",
      "Epoch 251/10000\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.6953 - val_loss: 5.6021\n",
      "Epoch 252/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.1390 - val_loss: 5.5065\n",
      "Epoch 253/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.7531 - val_loss: 6.3030\n",
      "Epoch 254/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 6.5783 - val_loss: 6.0291\n",
      "Epoch 255/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.8003 - val_loss: 6.6303\n",
      "Epoch 256/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.2575 - val_loss: 6.2614\n",
      "Epoch 257/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.6244 - val_loss: 5.9322\n",
      "Epoch 258/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.2052 - val_loss: 4.9873\n",
      "Epoch 259/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.0027 - val_loss: 5.6505\n",
      "Epoch 260/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.3479 - val_loss: 5.6634\n",
      "Epoch 261/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.4821 - val_loss: 6.4162\n",
      "Epoch 262/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.7541 - val_loss: 6.5653\n",
      "Epoch 263/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.9526 - val_loss: 6.9488\n",
      "Epoch 264/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.2173 - val_loss: 7.0255\n",
      "Epoch 265/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.8878 - val_loss: 5.6582\n",
      "Epoch 266/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.8445 - val_loss: 6.5503\n",
      "Epoch 267/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.8356 - val_loss: 7.6251\n",
      "Epoch 268/10000\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.6630 - val_loss: 5.7954\n",
      "Epoch 269/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.8923 - val_loss: 8.2689\n",
      "Epoch 270/10000\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.3601 - val_loss: 7.6134\n",
      "Epoch 271/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.1900 - val_loss: 8.1668\n",
      "Epoch 272/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.4814 - val_loss: 6.3654\n",
      "Epoch 273/10000\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.3007 - val_loss: 7.7468\n",
      "Epoch 274/10000\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 7.7102 - val_loss: 8.1157\n",
      "Epoch 275/10000\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.5274 - val_loss: 9.1113\n",
      "Epoch 276/10000\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.7836 - val_loss: 8.3579\n",
      "Epoch 277/10000\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.7466 - val_loss: 6.3284\n",
      "Epoch 278/10000\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.5604 - val_loss: 6.6060\n"
     ]
    }
   ],
   "source": [
    "dtStartTime = time.time()\n",
    "oPredictiveModel.fit(\n",
    "    aInputTrain, \n",
    "    aOutputTrain, \n",
    "    epochs=iEpochSize, \n",
    "    batch_size=iBatchSize, \n",
    "    verbose=1, \n",
    "    validation_data= (aInputValidation, aOutputValidation),\n",
    "    validation_batch_size= iBatchSize\n",
    "    ,callbacks=[oEarlyStop]\n",
    ")\n",
    "dtEndTime = time.time()\n",
    "dtTrainingDuration = dtEndTime -dtStartTime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857470db-83a8-4c90-ac73-bb6300ef196a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "141bb9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "oFig = sns.lineplot(data = pd.DataFrame(oPredictiveModel.history.history))\n",
    "oFig.get_figure().savefig(sModelName + '\\epochs.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680ac53a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8f88fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "oPredictiveModel.save_weights(sModelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75633cc0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d372e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "oPredictiveModel.load_weights(sModelName)\n",
    "\n",
    "aPrediction = oPredictiveModel.predict(aInputTest)\n",
    "aPrediction = aPrediction.reshape((-1, iForwardTimeWindow * iNrOutputFeatures))\n",
    "dfPrediction = pd.DataFrame(data = aPrediction, index = ixTest, columns = aIxOutputColumns)\n",
    "\n",
    "aActual = aOutputTest.reshape((-1, iForwardTimeWindow * iNrOutputFeatures))\n",
    "dfActual =  pd.DataFrame(data = aActual, index = ixTest, columns = aIxOutputColumns).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd31b058-6e14-4012-b227-97cf02dc0099",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76dfeae2-ea8d-4b16-aae1-a854d1b70708",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfActual.to_csv(sModelName + '\\dfActual.csv')\n",
    "dfPrediction.to_csv(sModelName + '\\dfPrediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d71eb51-1037-4b8e-9d10-f648c0a0a7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPerformance = pd.DataFrame(data = [dtTrainingDuration], columns = ['value'], index = ['training duration'] )\n",
    "dfPerformance.to_csv(sModelName + '\\dfPerformance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ca3ab0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# REFERENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49501761",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/keras/train_and_evaluate#passing_data_to_multi-input_multi-output_models\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch/\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit/\n",
    "\n",
    "https://towardsdatascience.com/customize-loss-function-to-make-lstm-model-more-applicable-in-stock-price-prediction-b1c50e50b16c\n",
    "\n",
    "https://keras.io/getting_started/faq/\n",
    "\n",
    "https://machinelearningmastery.com/how-to-develop-lstm-models-for-multi-step-time-series-forecasting-of-household-power-consumption/\n",
    "\n",
    "https://www.tensorflow.org/tutorials/structured_data/time_series\n",
    "\n",
    "https://towardsdatascience.com/encoder-decoder-model-for-multistep-time-series-forecasting-using-pytorch-5d54c6af6e60\n",
    "\n",
    "https://levelup.gitconnected.com/building-seq2seq-lstm-with-luong-attention-in-keras-for-time-series-forecasting-1ee00958decb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
