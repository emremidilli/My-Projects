{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d78e1f-e08c-4ea4-9448-81f915546cd2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0611acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import keras_tuner  as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54d4875-8ad8-478e-b63a-313ed6fdb418",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17fa2c83-a168-4d7f-8c30-3e0767d7a8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sOutputSymbol = 'ETHUSD'\n",
    "sModelType = 'MLP'\n",
    "sDesignType = 'Hyperband'\n",
    "iTrialId = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "833806a3-92de-48a3-ab67-70b905d98db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sFolderPath = 'Data/'+ sOutputSymbol +'//'+ sModelType + '//'+ sDesignType+'//'\n",
    "iBackwardTimeWindow = 3\n",
    "iForwardTimeWindow =3\n",
    "\n",
    "sModelName = os.path.join(sFolderPath + str(iTrialId))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d915683",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa23be1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Cryptocurrency List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ac336b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCrpytocurrencies = pd.read_csv('Data\\cryptocurrencies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369ae0af",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "889e4365",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOhlc = pd.read_csv('Data\\dfOhlc.csv')\n",
    "dfOhlc['timestamp'] = pd.DatetimeIndex(dfOhlc['timestamp'])\n",
    "dfOhlc.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34801cd6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa542c9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70088c21",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "fTrainingRatio = 0.7\n",
    "fValidationRatio = 0.15\n",
    "fTestRatio = 0.15\n",
    "\n",
    "ixTrain, ixTest = train_test_split(\n",
    "    dfOhlc.index,\n",
    "    test_size=1-fTrainingRatio,\n",
    "    shuffle=False)\n",
    "\n",
    "\n",
    "ixValidation, ixTest = train_test_split(\n",
    "    ixTest,\n",
    "    test_size=fTestRatio/(fTestRatio + fValidationRatio),\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e73e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32c7b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfScaledOhlc = pd.DataFrame(index = dfOhlc.index, columns  = dfOhlc.columns)\n",
    "\n",
    "for sColumn in dfOhlc.columns:\n",
    "    oScaler = StandardScaler()\n",
    "    \n",
    "    dfTrain = pd.DataFrame(dfOhlc.loc[ixTrain, sColumn])\n",
    "    dfValidation = pd.DataFrame(dfOhlc.loc[ixValidation, sColumn])\n",
    "    dfTest = pd.DataFrame(dfOhlc.loc[ixTest, sColumn])\n",
    "    \n",
    "    oScaler.fit(dfTrain.append(dfValidation))\n",
    "    \n",
    "    dfScaledOhlc.loc[ixTrain, sColumn] = np.reshape(oScaler.transform(dfTrain), (-1))\n",
    "    dfScaledOhlc.loc[ixValidation, sColumn] = np.reshape(oScaler.transform(dfValidation), (-1))\n",
    "    dfScaledOhlc.loc[ixTest, sColumn] = np.reshape(oScaler.transform(dfTest), (-1))\n",
    "\n",
    "    sScalerFilePath = os.path.join(sModelName , \"__scalers__\")\n",
    "    sScalerFilePath = os.path.join(sScalerFilePath , sColumn + \".sav\")\n",
    "    os.makedirs(os.path.dirname(sScalerFilePath), exist_ok=True)\n",
    "    \n",
    "    pickle.dump(oScaler, open(sScalerFilePath, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec96ca9f-f07a-4e1b-bc3c-aa34164c1d24",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Create Input Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1449fbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aInputSymbols = dfCrpytocurrencies['Symbol'].values\n",
    "aInputFeatures = ['weekday', 'hour', 'minute' ,'upper_shadow', 'lower_shadow' ,'return']\n",
    "aInputFeatures = list(map(\":\".join, itertools.product(aInputSymbols, aInputFeatures)))\n",
    "\n",
    "iNrInputFeatures = len(aInputFeatures)\n",
    "\n",
    "aBackwardTimeSteps = range(-iBackwardTimeWindow, 0)\n",
    "\n",
    "aTplInputColumns = list(itertools.product(aBackwardTimeSteps, aInputFeatures))\n",
    "aIxInputColumns = pd.MultiIndex.from_tuples(aTplInputColumns, names= ['time_step', 'feature'])\n",
    "\n",
    "dfInput = pd.DataFrame(columns = aIxInputColumns)\n",
    "\n",
    "for tplColumn in list(dfInput.columns):\n",
    "    dfInput.loc[:, tplColumn] = dfScaledOhlc[(tplColumn[1])].shift(-tplColumn[0])\n",
    "\n",
    "\n",
    "ixNas = dfInput[dfInput.isna().any(axis=1)].index\n",
    "dfInput.drop(ixNas, inplace = True, errors = 'ignore') \n",
    "ixTrain= ixTrain.drop(ixNas, errors = 'ignore') \n",
    "ixValidation= ixValidation.drop(ixNas,   errors = 'ignore') \n",
    "ixTest = ixTest.drop(ixNas,   errors = 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8011a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Output Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce152a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "aOutputFeatures = ['return']\n",
    "aOutputFeatures = list(map(\":\".join, itertools.product([sOutputSymbol], aOutputFeatures)))\n",
    "iNrOutputFeatures = len(aOutputFeatures)\n",
    "\n",
    "aForwardTimeSteps = range(0, iForwardTimeWindow)\n",
    "\n",
    "\n",
    "aTplOutputColumns = list(itertools.product(aForwardTimeSteps, aOutputFeatures))\n",
    "aIxOutputColumns = pd.MultiIndex.from_tuples(aTplOutputColumns, names= ['time_step', 'feature'])\n",
    "\n",
    "dfOutput = pd.DataFrame(columns = aIxOutputColumns)\n",
    "\n",
    "for tplColumn in list(dfOutput.columns):\n",
    "    dfOutput.loc[:, tplColumn] =  dfOhlc[(tplColumn[1])].shift(-tplColumn[0])\n",
    "\n",
    "ixNas = dfOutput[dfOutput.isna().any(axis=1)].index\n",
    "dfOutput.drop(ixNas, inplace = True, errors = 'ignore') \n",
    "ixTrain= ixTrain.drop(ixNas, errors = 'ignore') \n",
    "ixValidation= ixValidation.drop(ixNas,   errors = 'ignore') \n",
    "ixTest = ixTest.drop(ixNas,   errors = 'ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802a6d3a-353a-45c3-a8eb-f49af789c4a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reshape Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "296eec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "axMerged = dfInput.index.join(dfOutput.index, how = 'inner')\n",
    "\n",
    "dfInput = dfInput.loc[axMerged]\n",
    "dfOutput = dfOutput.loc[axMerged]\n",
    "\n",
    "ixTrain = ixTrain.join(axMerged, how = \"inner\")\n",
    "ixValidation = ixValidation.join(axMerged, how = \"inner\")\n",
    "ixTest = ixTest.join(axMerged, how = \"inner\")\n",
    "\n",
    "\n",
    "dfInputTrain = dfInput.loc[ixTrain]\n",
    "aInputTrain = np.reshape(dfInputTrain.values, (dfInputTrain.shape[0], iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "dfInputValidation = dfInput.loc[ixValidation]\n",
    "aInputValidation = np.reshape(dfInputValidation.values, (dfInputValidation.shape[0], iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "dfInputTest = dfInput.loc[ixTest]\n",
    "aInputTest = np.reshape(dfInputTest.values, (dfInputTest.shape[0], iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "dfOutputTrain = dfOutput.loc[ixTrain]\n",
    "aOutputTrain = np.reshape(dfOutputTrain.values, (dfOutputTrain.shape[0], iForwardTimeWindow, iNrOutputFeatures))\n",
    "\n",
    "dfOutputValidation = dfOutput.loc[ixValidation]\n",
    "aOutputValidation = np.reshape(dfOutputValidation.values, (dfOutputValidation.shape[0], iForwardTimeWindow, iNrOutputFeatures))\n",
    "\n",
    "dfOutputTest = dfOutput.loc[ixTest]\n",
    "aOutputTest = np.reshape(dfOutputTest.values, (dfOutputTest.shape[0], iForwardTimeWindow, iNrOutputFeatures))\n",
    "\n",
    "\n",
    "aInputTrain = np.asarray(aInputTrain, np.float32)\n",
    "aInputValidation = np.asarray(aInputValidation, np.float32)\n",
    "aInputTest = np.asarray(aInputTest, np.float32)\n",
    "aOutputTrain = np.asarray(aOutputTrain, np.float32)\n",
    "aOutputValidation = np.asarray(aOutputValidation, np.float32)\n",
    "aOutputTest = np.asarray(aOutputTest, np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52944fb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  MODEL DEVELOPMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e253bd8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a484f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "oEarlyStop = EarlyStopping(\n",
    "        monitor = 'val_loss', \n",
    "        mode = 'min', \n",
    "        verbose = 0 , \n",
    "        patience = 20, \n",
    "        restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27edd3cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define Custom Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac51d89-3f8e-4c93-aac7-463a9f016e7e",
   "metadata": {},
   "source": [
    "While loss function is defined following criteria is taken into consideration:\n",
    "1. Opposite signs should be penalized.\n",
    "1. Opposite sings will be worse when the magnitute of error increases.\n",
    "1. Any of same sign is better than any of the opposite signs.\n",
    "1. Same sign is the best when the error is 0.\n",
    "\n",
    "Following logic also should have been implemented but it was unsuccessful to implement due to forcing negative errors. It will be used as 'metric' function.\n",
    "1. Same sign is positive error is better than negative error (err = act - pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13785578-8b6a-4b3f-a5d2-ac3b6c1e7980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'05'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(5).zfill(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2a023db-aaa6-4236-b7d7-e508b17b38c0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fCalculateLoss(aActual, aPrediction):\n",
    "    aLossDueToError = tf.math.subtract(aActual ,aPrediction)\n",
    "    aLossDueToError = tf.math.abs(aLossDueToError)\n",
    "\n",
    "    fPenalty = tf.math.reduce_max(aLossDueToError)\n",
    "\n",
    "    aLossDueToSignDiff = tf.math.abs(tf.math.subtract(tf.math.sign(aActual), tf.math.sign(aPrediction)) )\n",
    "    aLossDueToSignDiff = tf.where(aLossDueToSignDiff == 0, aLossDueToSignDiff, fPenalty)\n",
    "\n",
    "    aTotalLoss = aLossDueToError + aLossDueToSignDiff\n",
    "\n",
    "    return tf.math.reduce_mean(aTotalLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75b209e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a48d744-a348-4435-b0c7-88054f26e20e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7fa552d5-8eb4-4008-b068-b6d5683a8fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        oHpHiddenNuerons = hp.Int('units', min_value=10, max_value=14, step=2)\n",
    "\n",
    "        if sModelType == 'MLP':\n",
    "            aInputMlp = keras.Input(\n",
    "                shape=(iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "            aW = keras.layers.Flatten()(aInputMlp)\n",
    "            aW = keras.layers.Dense(oHpHiddenNuerons)(aW)\n",
    "            aW = keras.layers.Dropout(0.1)(aW)\n",
    "            aW = keras.layers.Dense(iForwardTimeWindow*iNrOutputFeatures)(aW)\n",
    "            aW = keras.layers.Reshape((iForwardTimeWindow, iNrOutputFeatures))(aW)\n",
    "\n",
    "            aOutputMlp = aW\n",
    "            oModelMlp = keras.Model(\n",
    "                inputs=aInputMlp,\n",
    "                outputs=aOutputMlp\n",
    "            )\n",
    "\n",
    "            oOptimizerMlp = tf.keras.optimizers.Adam(learning_rate=1e-04)\n",
    "            oModelMlp.compile(optimizer=oOptimizerMlp,\n",
    "                                     loss = fCalculateLoss\n",
    "                                    )\n",
    "\n",
    "            oModel = oModelMlp\n",
    "\n",
    "            tf.keras.utils.plot_model(oModelMlp,  show_shapes=True, to_file=sModelName +'\\Model architecture.png')\n",
    "\n",
    "            return oModel\n",
    "        \n",
    "    def fit(self, hp, oModel, x, y, val_data, callbacks=None, **kwargs):\n",
    "        return oModel.fit(\n",
    "            x, \n",
    "            y, \n",
    "            epochs=10000, \n",
    "            batch_size=hp.Int(\"batch_size\", 60, 70, step=5, default=64), \n",
    "            verbose=0, \n",
    "            validation_data= val_data,\n",
    "            callbacks=callbacks\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e1087a5-29ed-4d09-8719-e5daf83a8ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "oTuner = kt.Hyperband(\n",
    "    hypermodel = MyHyperModel(),\n",
    "    objective = 'val_loss',\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    overwrite = True,\n",
    "    directory=sFolderPath\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedaa4fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3871f87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 05m 50s]\n",
      "val_loss: 0.015997933223843575\n",
      "\n",
      "Best val_loss So Far: 0.015997933223843575\n",
      "Total elapsed time: 00h 59m 29s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "dtStartTime = time.time()\n",
    "\n",
    "oTuner.search(x = aInputTrain, \n",
    "              y = aOutputTrain, \n",
    "              epochs=10000, \n",
    "              val_data= (aInputValidation, aOutputValidation), \n",
    "              callbacks=[oEarlyStop])\n",
    "\n",
    "dtEndTime = time.time()\n",
    "dtTrainingDuration = dtEndTime - dtStartTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "075bea86-679b-490c-a701-f2f176ded21d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-78885a3948f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moTuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_hyperparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'batch_size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "print(oTuner.get_best_hyperparameters().get('batch_size')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857470db-83a8-4c90-ac73-bb6300ef196a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save Epoch History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141bb9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHistory = pd.DataFrame(oPredictiveModel.history.history)\n",
    "dfHistory.to_csv(sModelName + '\\dfHistory.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680ac53a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f88fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "oPredictiveModel.save_weights(sModelName+'\\model weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75633cc0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d372e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "oPredictiveModel.load_weights(sModelName+'\\model weights')\n",
    "\n",
    "aPrediction = oPredictiveModel.predict(aInputTest)\n",
    "aPrediction = aPrediction.reshape((-1, iForwardTimeWindow * iNrOutputFeatures))\n",
    "dfPrediction = pd.DataFrame(data = aPrediction, index = ixTest, columns = aIxOutputColumns)\n",
    "\n",
    "aActual = aOutputTest.reshape((-1, iForwardTimeWindow * iNrOutputFeatures))\n",
    "dfActual =  pd.DataFrame(data = aActual, index = ixTest, columns = aIxOutputColumns).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd31b058-6e14-4012-b227-97cf02dc0099",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dfeae2-ea8d-4b16-aae1-a854d1b70708",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfActual.to_csv(sModelName + '\\dfActual.csv')\n",
    "dfPrediction.to_csv(sModelName + '\\dfPrediction.csv')\n",
    "\n",
    "dfPerformance = pd.DataFrame(data = [dtTrainingDuration], columns = ['value'], index = ['training duration'] )\n",
    "dfPerformance.to_csv(sModelName + '\\dfPerformance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ca3ab0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# REFERENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49501761",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/keras/train_and_evaluate#passing_data_to_multi-input_multi-output_models\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch/\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit/\n",
    "\n",
    "https://towardsdatascience.com/customize-loss-function-to-make-lstm-model-more-applicable-in-stock-price-prediction-b1c50e50b16c\n",
    "\n",
    "https://keras.io/getting_started/faq/\n",
    "\n",
    "https://machinelearningmastery.com/how-to-develop-lstm-models-for-multi-step-time-series-forecasting-of-household-power-consumption/\n",
    "\n",
    "https://www.tensorflow.org/tutorials/structured_data/time_series\n",
    "\n",
    "https://towardsdatascience.com/encoder-decoder-model-for-multistep-time-series-forecasting-using-pytorch-5d54c6af6e60\n",
    "\n",
    "https://levelup.gitconnected.com/building-seq2seq-lstm-with-luong-attention-in-keras-for-time-series-forecasting-1ee00958decb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
