{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d78e1f-e08c-4ea4-9448-81f915546cd2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0611acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import time\n",
    "\n",
    "import pytz\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, max_error, r2_score\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54d4875-8ad8-478e-b63a-313ed6fdb418",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17fa2c83-a168-4d7f-8c30-3e0767d7a8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sOutputSymbol = 'BTCUSD'\n",
    "sModelType = 'MLP'\n",
    "sSource = 'Steepest Descent'\n",
    "\n",
    "iTrialId = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "833806a3-92de-48a3-ab67-70b905d98db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDesign = pd.read_csv('Data/'+ sSource +'_'+ sOutputSymbol +'_'+ sModelType +'.csv', index_col = 0)\n",
    "iBatchSize = dfDesign.loc[iTrialId, 'Batch Size']\n",
    "iNrOfHiddenNeurons = dfDesign.loc[iTrialId, 'Number of Hidden Neurons']\n",
    "iBackwardTimeWindow = 3\n",
    "iForwardTimeWindow = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "137167f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sModelName = os.path.join(sOutputSymbol , sModelType + '_' + str(iTrialId))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d915683",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa23be1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Cryptocurrency List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ac336b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BTCUSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ETHUSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCHUSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LTCUSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RPLUSD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Symbol\n",
       "0  BTCUSD\n",
       "1  ETHUSD\n",
       "2  BCHUSD\n",
       "3  LTCUSD\n",
       "4  RPLUSD"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCrpytocurrencies = pd.read_csv('Data\\cryptocurrencies.csv')\n",
    "dfCrpytocurrencies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369ae0af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "889e4365",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOhlc = pd.read_csv('Data\\dfOhlc.csv')\n",
    "dfOhlc['timestamp'] = pd.DatetimeIndex(dfOhlc['timestamp'])\n",
    "dfOhlc.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34801cd6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa542c9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70088c21",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "fTrainingRatio = 0.7\n",
    "fValidationRatio = 0.15\n",
    "fTestRatio = 0.15\n",
    "\n",
    "ixTrain, ixTest = train_test_split(\n",
    "    dfOhlc.index,\n",
    "    test_size=1-fTrainingRatio,\n",
    "    shuffle=False)\n",
    "\n",
    "ixValidation, ixTest = train_test_split(\n",
    "    ixTest,\n",
    "    test_size=fTestRatio/(fTestRatio + fValidationRatio),\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e73e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32c7b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfScaledOhlc = pd.DataFrame(index = dfOhlc.index, columns  = dfOhlc.columns)\n",
    "\n",
    "for sColumn in dfOhlc.columns:\n",
    "    oScaler = StandardScaler()\n",
    "    \n",
    "    dfTrain = pd.DataFrame(dfOhlc.loc[ixTrain, sColumn])\n",
    "    dfValidation = pd.DataFrame(dfOhlc.loc[ixValidation, sColumn])\n",
    "    dfTest = pd.DataFrame(dfOhlc.loc[ixTest, sColumn])\n",
    "    \n",
    "    oScaler.fit(dfTrain.append(dfValidation))\n",
    "    \n",
    "    dfScaledOhlc.loc[ixTrain, sColumn] = np.reshape(oScaler.transform(dfTrain), (-1))\n",
    "    dfScaledOhlc.loc[ixValidation, sColumn] = np.reshape(oScaler.transform(dfValidation), (-1))\n",
    "    dfScaledOhlc.loc[ixTest, sColumn] = np.reshape(oScaler.transform(dfTest), (-1))\n",
    "\n",
    "    sScalerFilePath = os.path.join(sModelName , \"__scalers__\")\n",
    "    sScalerFilePath = os.path.join(sScalerFilePath , sColumn + \".sav\")\n",
    "    os.makedirs(os.path.dirname(sScalerFilePath), exist_ok=True)\n",
    "    \n",
    "    pickle.dump(oScaler, open(sScalerFilePath, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec96ca9f-f07a-4e1b-bc3c-aa34164c1d24",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Input Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1449fbb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>time_step</th>\n",
       "      <th colspan=\"10\" halign=\"left\">-3</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">-1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th>BTCUSD:weekday</th>\n",
       "      <th>BTCUSD:hour</th>\n",
       "      <th>BTCUSD:minute</th>\n",
       "      <th>BTCUSD:upper_shadow</th>\n",
       "      <th>BTCUSD:lower_shadow</th>\n",
       "      <th>BTCUSD:return</th>\n",
       "      <th>ETHUSD:weekday</th>\n",
       "      <th>ETHUSD:hour</th>\n",
       "      <th>ETHUSD:minute</th>\n",
       "      <th>ETHUSD:upper_shadow</th>\n",
       "      <th>...</th>\n",
       "      <th>LTCUSD:minute</th>\n",
       "      <th>LTCUSD:upper_shadow</th>\n",
       "      <th>LTCUSD:lower_shadow</th>\n",
       "      <th>LTCUSD:return</th>\n",
       "      <th>RPLUSD:weekday</th>\n",
       "      <th>RPLUSD:hour</th>\n",
       "      <th>RPLUSD:minute</th>\n",
       "      <th>RPLUSD:upper_shadow</th>\n",
       "      <th>RPLUSD:lower_shadow</th>\n",
       "      <th>RPLUSD:return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-01 01:30:00</th>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.662613</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.272382</td>\n",
       "      <td>-0.344248</td>\n",
       "      <td>0.367626</td>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.662613</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.101196</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.247703</td>\n",
       "      <td>-0.356995</td>\n",
       "      <td>-0.691235</td>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.517929</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.042302</td>\n",
       "      <td>1.24257</td>\n",
       "      <td>-2.245317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 02:00:00</th>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.662613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.482079</td>\n",
       "      <td>-0.838114</td>\n",
       "      <td>-0.274886</td>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.662613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.108089</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.676376</td>\n",
       "      <td>0.086697</td>\n",
       "      <td>0.736124</td>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.517929</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.388771</td>\n",
       "      <td>0.235062</td>\n",
       "      <td>1.631002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 02:30:00</th>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.517929</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.09279</td>\n",
       "      <td>-0.050609</td>\n",
       "      <td>-0.230078</td>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.517929</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5739</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.849824</td>\n",
       "      <td>-0.029284</td>\n",
       "      <td>0.450547</td>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.373245</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.136139</td>\n",
       "      <td>1.074724</td>\n",
       "      <td>0.541948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 03:00:00</th>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.517929</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.792066</td>\n",
       "      <td>-0.003061</td>\n",
       "      <td>0.948749</td>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.517929</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.693713</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.508944</td>\n",
       "      <td>-0.675575</td>\n",
       "      <td>0.071885</td>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.373245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.148526</td>\n",
       "      <td>-0.76391</td>\n",
       "      <td>0.835947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 03:30:00</th>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.373245</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.402557</td>\n",
       "      <td>-0.069069</td>\n",
       "      <td>0.438649</td>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.373245</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.541873</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.236206</td>\n",
       "      <td>0.260103</td>\n",
       "      <td>-0.531665</td>\n",
       "      <td>-0.003076</td>\n",
       "      <td>-1.228561</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.070256</td>\n",
       "      <td>2.147994</td>\n",
       "      <td>0.002064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "time_step                       -3                            \\\n",
       "feature             BTCUSD:weekday BTCUSD:hour BTCUSD:minute   \n",
       "timestamp                                                      \n",
       "2021-09-01 01:30:00      -0.003076   -1.662613          -1.0   \n",
       "2021-09-01 02:00:00      -0.003076   -1.662613           1.0   \n",
       "2021-09-01 02:30:00      -0.003076   -1.517929          -1.0   \n",
       "2021-09-01 03:00:00      -0.003076   -1.517929           1.0   \n",
       "2021-09-01 03:30:00      -0.003076   -1.373245          -1.0   \n",
       "\n",
       "time_step                                                                  \\\n",
       "feature             BTCUSD:upper_shadow BTCUSD:lower_shadow BTCUSD:return   \n",
       "timestamp                                                                   \n",
       "2021-09-01 01:30:00            0.272382           -0.344248      0.367626   \n",
       "2021-09-01 02:00:00            1.482079           -0.838114     -0.274886   \n",
       "2021-09-01 02:30:00             0.09279           -0.050609     -0.230078   \n",
       "2021-09-01 03:00:00           -0.792066           -0.003061      0.948749   \n",
       "2021-09-01 03:30:00           -0.402557           -0.069069      0.438649   \n",
       "\n",
       "time_step                                                     \\\n",
       "feature             ETHUSD:weekday ETHUSD:hour ETHUSD:minute   \n",
       "timestamp                                                      \n",
       "2021-09-01 01:30:00      -0.003076   -1.662613          -1.0   \n",
       "2021-09-01 02:00:00      -0.003076   -1.662613           1.0   \n",
       "2021-09-01 02:30:00      -0.003076   -1.517929          -1.0   \n",
       "2021-09-01 03:00:00      -0.003076   -1.517929           1.0   \n",
       "2021-09-01 03:30:00      -0.003076   -1.373245          -1.0   \n",
       "\n",
       "time_step                                ...            -1  \\\n",
       "feature             ETHUSD:upper_shadow  ... LTCUSD:minute   \n",
       "timestamp                                ...                 \n",
       "2021-09-01 01:30:00            0.101196  ...          -1.0   \n",
       "2021-09-01 02:00:00            2.108089  ...           1.0   \n",
       "2021-09-01 02:30:00              0.5739  ...          -1.0   \n",
       "2021-09-01 03:00:00           -0.693713  ...           1.0   \n",
       "2021-09-01 03:30:00           -0.541873  ...          -1.0   \n",
       "\n",
       "time_step                                                                  \\\n",
       "feature             LTCUSD:upper_shadow LTCUSD:lower_shadow LTCUSD:return   \n",
       "timestamp                                                                   \n",
       "2021-09-01 01:30:00            0.247703           -0.356995     -0.691235   \n",
       "2021-09-01 02:00:00           -0.676376            0.086697      0.736124   \n",
       "2021-09-01 02:30:00           -0.849824           -0.029284      0.450547   \n",
       "2021-09-01 03:00:00            0.508944           -0.675575      0.071885   \n",
       "2021-09-01 03:30:00            1.236206            0.260103     -0.531665   \n",
       "\n",
       "time_step                                                     \\\n",
       "feature             RPLUSD:weekday RPLUSD:hour RPLUSD:minute   \n",
       "timestamp                                                      \n",
       "2021-09-01 01:30:00      -0.003076   -1.517929          -1.0   \n",
       "2021-09-01 02:00:00      -0.003076   -1.517929           1.0   \n",
       "2021-09-01 02:30:00      -0.003076   -1.373245          -1.0   \n",
       "2021-09-01 03:00:00      -0.003076   -1.373245           1.0   \n",
       "2021-09-01 03:30:00      -0.003076   -1.228561          -1.0   \n",
       "\n",
       "time_step                                                                  \n",
       "feature             RPLUSD:upper_shadow RPLUSD:lower_shadow RPLUSD:return  \n",
       "timestamp                                                                  \n",
       "2021-09-01 01:30:00            0.042302             1.24257     -2.245317  \n",
       "2021-09-01 02:00:00           -0.388771            0.235062      1.631002  \n",
       "2021-09-01 02:30:00            0.136139            1.074724      0.541948  \n",
       "2021-09-01 03:00:00            3.148526            -0.76391      0.835947  \n",
       "2021-09-01 03:30:00            2.070256            2.147994      0.002064  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aInputSymbols = dfCrpytocurrencies['Symbol'].values\n",
    "aInputFeatures = ['weekday', 'hour', 'minute' ,'upper_shadow', 'lower_shadow' ,'return']\n",
    "aInputFeatures = list(map(\":\".join, itertools.product(aInputSymbols, aInputFeatures)))\n",
    "\n",
    "iNrInputFeatures = len(aInputFeatures)\n",
    "\n",
    "aBackwardTimeSteps = range(-iBackwardTimeWindow, 0)\n",
    "\n",
    "aTplInputColumns = list(itertools.product(aBackwardTimeSteps, aInputFeatures))\n",
    "aIxInputColumns = pd.MultiIndex.from_tuples(aTplInputColumns, names= ['time_step', 'feature'])\n",
    "\n",
    "dfInput = pd.DataFrame(columns = aIxInputColumns)\n",
    "\n",
    "for tplColumn in list(dfInput.columns):\n",
    "    dfInput.loc[:, tplColumn] = dfScaledOhlc[(tplColumn[1])].shift(-tplColumn[0])\n",
    "\n",
    "    \n",
    "ixNas = dfInput[dfInput.isna().any(axis=1)].index\n",
    "dfInput.drop(ixNas, inplace = True, errors = 'ignore') \n",
    "ixTrain= ixTrain.drop(ixNas, errors = 'ignore') \n",
    "ixValidation= ixValidation.drop(ixNas,   errors = 'ignore') \n",
    "ixTest = ixTest.drop(ixNas,   errors = 'ignore') \n",
    "\n",
    "dfInput.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8011a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Output Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce152a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>time_step</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th>BTCUSD:return</th>\n",
       "      <th>BTCUSD:return</th>\n",
       "      <th>BTCUSD:return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-01 00:00:00</th>\n",
       "      <td>0.001941</td>\n",
       "      <td>-0.001465</td>\n",
       "      <td>-0.001227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 00:30:00</th>\n",
       "      <td>-0.001465</td>\n",
       "      <td>-0.001227</td>\n",
       "      <td>0.005021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 01:00:00</th>\n",
       "      <td>-0.001227</td>\n",
       "      <td>0.005021</td>\n",
       "      <td>0.002318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 01:30:00</th>\n",
       "      <td>0.005021</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>-0.002022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 02:00:00</th>\n",
       "      <td>0.002318</td>\n",
       "      <td>-0.002022</td>\n",
       "      <td>-0.001229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "time_step                       0             1             2\n",
       "feature             BTCUSD:return BTCUSD:return BTCUSD:return\n",
       "timestamp                                                    \n",
       "2021-09-01 00:00:00      0.001941     -0.001465     -0.001227\n",
       "2021-09-01 00:30:00     -0.001465     -0.001227      0.005021\n",
       "2021-09-01 01:00:00     -0.001227      0.005021      0.002318\n",
       "2021-09-01 01:30:00      0.005021      0.002318     -0.002022\n",
       "2021-09-01 02:00:00      0.002318     -0.002022     -0.001229"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aOutputFeatures = ['return']\n",
    "aOutputFeatures = list(map(\":\".join, itertools.product([sOutputSymbol], aOutputFeatures)))\n",
    "iNrOutputFeatures = len(aOutputFeatures)\n",
    "\n",
    "aForwardTimeSteps = range(0, iForwardTimeWindow)\n",
    "\n",
    "\n",
    "aTplOutputColumns = list(itertools.product(aForwardTimeSteps, aOutputFeatures))\n",
    "aIxOutputColumns = pd.MultiIndex.from_tuples(aTplOutputColumns, names= ['time_step', 'feature'])\n",
    "\n",
    "dfOutput = pd.DataFrame(columns = aIxOutputColumns)\n",
    "\n",
    "for tplColumn in list(dfOutput.columns):\n",
    "    dfOutput.loc[:, tplColumn] =  dfOhlc[(tplColumn[1])].shift(-tplColumn[0])\n",
    "\n",
    "ixNas = dfOutput[dfOutput.isna().any(axis=1)].index\n",
    "dfOutput.drop(ixNas, inplace = True, errors = 'ignore') \n",
    "ixTrain= ixTrain.drop(ixNas, errors = 'ignore') \n",
    "ixValidation= ixValidation.drop(ixNas,   errors = 'ignore') \n",
    "ixTest = ixTest.drop(ixNas,   errors = 'ignore') \n",
    "dfOutput.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802a6d3a-353a-45c3-a8eb-f49af789c4a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Reshape Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "296eec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "axMerged = dfInput.index.join(dfOutput.index, how = 'inner')\n",
    "\n",
    "dfInput = dfInput.loc[axMerged]\n",
    "dfOutput = dfOutput.loc[axMerged]\n",
    "\n",
    "ixTrain = ixTrain.join(axMerged, how = \"inner\")\n",
    "ixValidation = ixValidation.join(axMerged, how = \"inner\")\n",
    "ixTest = ixTest.join(axMerged, how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96e399d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInputTrain = dfInput.loc[ixTrain]\n",
    "aInputTrain = np.reshape(dfInputTrain.values, (dfInputTrain.shape[0], iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "dfInputValidation = dfInput.loc[ixValidation]\n",
    "aInputValidation = np.reshape(dfInputValidation.values, (dfInputValidation.shape[0], iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "dfInputTest = dfInput.loc[ixTest]\n",
    "aInputTest = np.reshape(dfInputTest.values, (dfInputTest.shape[0], iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "dfOutputTrain = dfOutput.loc[ixTrain]\n",
    "aOutputTrain = np.reshape(dfOutputTrain.values, (dfOutputTrain.shape[0], iForwardTimeWindow, iNrOutputFeatures))\n",
    "\n",
    "dfOutputValidation = dfOutput.loc[ixValidation]\n",
    "aOutputValidation = np.reshape(dfOutputValidation.values, (dfOutputValidation.shape[0], iForwardTimeWindow, iNrOutputFeatures))\n",
    "\n",
    "dfOutputTest = dfOutput.loc[ixTest]\n",
    "aOutputTest = np.reshape(dfOutputTest.values, (dfOutputTest.shape[0], iForwardTimeWindow, iNrOutputFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76ce37ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "aInputTrain = np.asarray(aInputTrain, np.float32)\n",
    "aInputValidation = np.asarray(aInputValidation, np.float32)\n",
    "aInputTest = np.asarray(aInputTest, np.float32)\n",
    "aOutputTrain = np.asarray(aOutputTrain, np.float32)\n",
    "aOutputValidation = np.asarray(aOutputValidation, np.float32)\n",
    "aOutputTest = np.asarray(aOutputTest, np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52944fb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  MODEL DEVELOPMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e253bd8c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a484f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "iEpochSize = 10000\n",
    "oEarlyStop = EarlyStopping(\n",
    "    monitor = 'val_loss', \n",
    "    mode = 'min', \n",
    "    verbose = 0 , \n",
    "    patience = 20, \n",
    "    restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27edd3cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Define Custom Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac51d89-3f8e-4c93-aac7-463a9f016e7e",
   "metadata": {},
   "source": [
    "While loss function is defined following criteria is taken into consideration:\n",
    "1. Opposite signs should be penalized.\n",
    "1. Opposite sings will be worse when the magnitute of error increases.\n",
    "1. Any of same sign is better than any of the opposite signs.\n",
    "1. Same sign is the best when the error is 0.\n",
    "\n",
    "Following logic also should have been implemented but it was unsuccessful to implement due to forcing negative errors. It will be used as 'metric' function.\n",
    "1. Same sign is positive error is better than negative error (err = act - pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2a023db-aaa6-4236-b7d7-e508b17b38c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fCalculateLoss(aActual, aPrediction):\n",
    "    aLossDueToError = tf.math.subtract(aActual ,aPrediction)\n",
    "    aLossDueToError = tf.math.abs(aLossDueToError)\n",
    "    \n",
    "    fPenalty = tf.math.reduce_max(aLossDueToError)\n",
    "    \n",
    "    aLossDueToSignDiff = tf.math.abs(tf.math.subtract(tf.math.sign(aActual), tf.math.sign(aPrediction)) )\n",
    "    aLossDueToSignDiff = tf.where(aLossDueToSignDiff == 0, aLossDueToSignDiff, fPenalty)\n",
    "    \n",
    "    aTotalLoss = aLossDueToError + aLossDueToSignDiff\n",
    "        \n",
    "    return tf.math.reduce_mean(aTotalLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75b209e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a48d744-a348-4435-b0c7-88054f26e20e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fa552d5-8eb4-4008-b068-b6d5683a8fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sModelType == 'MLP':\n",
    "    aInputMlp = keras.Input(\n",
    "        shape=(iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "    aW = keras.layers.Flatten()(aInputMlp)\n",
    "    aW = keras.layers.Dense(iNrOfHiddenNeurons)(aW)\n",
    "    aW = keras.layers.Dense(iForwardTimeWindow*iNrOutputFeatures)(aW)\n",
    "    aW = keras.layers.Reshape((iForwardTimeWindow, iNrOutputFeatures))(aW)\n",
    "\n",
    "    aOutputMlp = aW\n",
    "    oModelMlp = keras.Model(\n",
    "        inputs=aInputMlp,\n",
    "        outputs=aOutputMlp\n",
    "    )\n",
    "\n",
    "    oOptimizerMlp = tf.keras.optimizers.Adam(learning_rate=1e-04)\n",
    "    oModelMlp.compile(optimizer=oOptimizerMlp,\n",
    "                             loss = fCalculateLoss\n",
    "                            )\n",
    "\n",
    "    oPredictiveModel = oModelMlp\n",
    "\n",
    "    tf.keras.utils.plot_model(oModelMlp,  show_shapes=True, to_file=sModelName +'\\Model architecture.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66367dfb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e48a9a2-527b-4226-98d8-39d7d4a79c8e",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "if sModelType == 'LSTM':\n",
    "    aInputDeepLstm = keras.Input(\n",
    "        shape=(iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "    aW = keras.layers.LSTM(64, return_sequences = True)(aInputDeepLstm)\n",
    "    aW = keras.layers.Flatten()(aW)\n",
    "    aW = keras.layers.Dense(iForwardTimeWindow*iNrOutputFeatures)(aW)\n",
    "    aW = keras.layers.Reshape((iForwardTimeWindow, iNrOutputFeatures))(aW)\n",
    "\n",
    "    aOutputDeepLstm = aW\n",
    "    oModelDeepLstm = keras.Model(\n",
    "        inputs=aInputDeepLstm,\n",
    "        outputs=aOutputDeepLstm\n",
    "    )\n",
    "\n",
    "    oOptimizerDeepLstm = tf.keras.optimizers.Adam(learning_rate=1e-04)\n",
    "    oModelDeepLstm.compile(optimizer=oOptimizerDeepLstm,\n",
    "                             loss = fCalculateLoss\n",
    "                            )\n",
    "\n",
    "    oPredictiveModel = oModelDeepLstm\n",
    "\n",
    "    tf.keras.utils.plot_model(oModelDeepLstm,  show_shapes=True, to_file=sModelName+'\\Model architecture.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f365ab5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Deep CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6776588",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sModelType == 'Deep CNN':\n",
    "    aInputDeepCnn = keras.Input(\n",
    "        shape=(iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "    aW = keras.layers.LSTM(64, return_sequences = True)(aInputDeepCnn)\n",
    "    aW = keras.layers.Flatten()(aW)\n",
    "    aW = keras.layers.Dense(iNrOfBins*iForwardTimeWindow*iNrOutputFeatures)(aW)\n",
    "    aW = keras.layers.Reshape((iNrOutputFeatures * iNrOfBins, iForwardTimeWindow, 1))(aW)\n",
    "    aW = keras.layers.Conv2D(64, (4,4), (1,1), padding = \"same\" )(aW)\n",
    "    aW = keras.layers.MaxPool2D(pool_size = (4, 4))(aW)\n",
    "    aW = keras.layers.Flatten()(aW)\n",
    "    aW = keras.layers.Dense(iNrOfBins*iForwardTimeWindow*iNrOutputFeatures)(aW)\n",
    "    aW = keras.layers.Reshape((iNrOutputFeatures, iNrOfBins, iForwardTimeWindow))(aW)\n",
    "\n",
    "    aOutputDeepCnn = aW\n",
    "    oModelDeepCnn = keras.Model(\n",
    "        inputs=aInputDeepCnn,\n",
    "        outputs=aOutputDeepCnn\n",
    "    )\n",
    "\n",
    "    oOptimizerDeepCnn = tf.keras.optimizers.Adam(learning_rate=1e-05)\n",
    "    oModelDeepCnn.compile(optimizer=oOptimizerDeepCnn,\n",
    "                             loss = fCalculateLoss\n",
    "                            )\n",
    "\n",
    "    tf.keras.utils.plot_model(oModelDeepCnn,  show_shapes=True, to_file=sModelName+'\\Model architecture.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11b935e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Convolutional Encoder-Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf77ce35-7d29-43c1-990e-a80a0fef20fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sModelType == 'Convolutional Encoder Decoder':\n",
    "    aInputs = keras.Input(\n",
    "        shape=(iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "    aEncoderHiddens, aFinalH, aFinalC = keras.layers.LSTM(iNrOfHiddenNeurons,\n",
    "                                             return_state = True, \n",
    "                                             return_sequences = True\n",
    "                                            )(aInputs)\n",
    "    aFinalH = keras.layers.BatchNormalization()(aFinalH)\n",
    "    aFinalC = keras.layers.BatchNormalization()(aFinalC)\n",
    "\n",
    "    aFeatureMap = keras.layers.Conv1D(64, 2)(aEncoderHiddens)\n",
    "    aFeatureMap = keras.layers.MaxPooling1D(2)(aFeatureMap)\n",
    "    aFlatted = keras.layers.Flatten()(aFeatureMap)\n",
    "\n",
    "    aDecoderInputs = keras.layers.RepeatVector(iForwardTimeWindow)(aFlatted)\n",
    "\n",
    "    aDecoderHiddens = keras.layers.LSTM(iNrOfHiddenNeurons, \n",
    "                           return_state = False, \n",
    "                           return_sequences = True\n",
    "                          )(aDecoderInputs, initial_state=[aFinalH, aFinalC])\n",
    "\n",
    "\n",
    "    aOutputs = keras.layers.TimeDistributed(\n",
    "        Dense(iNrOutputFeatures)\n",
    "    )(aDecoderHiddens)\n",
    "\n",
    "    oPredictiveModel = keras.Model(\n",
    "        inputs=aInputs,\n",
    "        outputs=aOutputs\n",
    "    )\n",
    "\n",
    "    oOptimizer = tf.keras.optimizers.Adam(learning_rate=1e-05)\n",
    "    oPredictiveModel.compile(loss = fCalculateLoss,\n",
    "                             optimizer=oOptimizer\n",
    "                            )\n",
    "\n",
    "    tf.keras.utils.plot_model(oPredictiveModel,  show_shapes=True, to_file=sModelName+'\\Model architecture.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1ed1a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Luong's Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6b49d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sModelType == 'Luongs Attention':\n",
    "    aEncoderInputs = keras.Input(\n",
    "        shape=(iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "    aEncoderHiddens, aFinalH, aFinalC = keras.layers.LSTM(iNrOfHiddenNeurons,\n",
    "                                             return_state = True, \n",
    "                                             return_sequences = True\n",
    "                                            )(aEncoderInputs)\n",
    "    aFinalH = keras.layers.BatchNormalization()(aFinalH)\n",
    "    aFinalC = keras.layers.BatchNormalization()(aFinalC)\n",
    "\n",
    "    aDecoderInputs = keras.layers.RepeatVector(iForwardTimeWindow)(aFinalH)\n",
    "\n",
    "    aDecoderHiddens = keras.layers.LSTM(iNrOfHiddenNeurons, \n",
    "                           return_state = False, \n",
    "                           return_sequences = True\n",
    "                          )(aDecoderInputs, initial_state=[aFinalH, aFinalC])\n",
    "\n",
    "    aAttentions = keras.layers.dot([aDecoderHiddens, aEncoderHiddens], axes=[2, 2])\n",
    "    aAttentions = keras.layers.Activation('softmax')(aAttentions)\n",
    "\n",
    "    aContextVector = keras.layers.dot([aAttentions, aEncoderHiddens], axes=[2,1])\n",
    "    aContextVector = keras.layers.BatchNormalization()(aContextVector)\n",
    "    aContextVector = keras.layers.concatenate([aContextVector, aDecoderHiddens])\n",
    "\n",
    "    aDecoderOutputs = keras.layers.TimeDistributed(\n",
    "        Dense(iNrOutputFeatures)\n",
    "    )(aContextVector)\n",
    "\n",
    "    oPredictiveModel = keras.Model(\n",
    "        inputs=aEncoderInputs,\n",
    "        outputs=aDecoderOutputs\n",
    "    )\n",
    "\n",
    "    oOptimizer = tf.keras.optimizers.Adam(learning_rate=1e-05)\n",
    "    oPredictiveModel.compile(loss = fCalculateLoss, \n",
    "                             optimizer=oOptimizer\n",
    "                            )\n",
    "\n",
    "    tf.keras.utils.plot_model(oPredictiveModel,  show_shapes=True+'\\Model architecture.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedaa4fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3871f87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 4.5270 - val_loss: 3.5355\n",
      "Epoch 2/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.0111 - val_loss: 3.1946\n",
      "Epoch 3/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.7384 - val_loss: 2.9415\n",
      "Epoch 4/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.3693 - val_loss: 2.7399\n",
      "Epoch 5/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3.0696 - val_loss: 2.5605\n",
      "Epoch 6/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.8953 - val_loss: 2.4064\n",
      "Epoch 7/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.7733 - val_loss: 2.2526\n",
      "Epoch 8/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5856 - val_loss: 2.1179\n",
      "Epoch 9/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5065 - val_loss: 1.9728\n",
      "Epoch 10/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.3225 - val_loss: 1.8626\n",
      "Epoch 11/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.1971 - val_loss: 1.7476\n",
      "Epoch 12/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.0716 - val_loss: 1.6615\n",
      "Epoch 13/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9570 - val_loss: 1.5651\n",
      "Epoch 14/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9435 - val_loss: 1.4904\n",
      "Epoch 15/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.8762 - val_loss: 1.4218\n",
      "Epoch 16/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.7923 - val_loss: 1.3593\n",
      "Epoch 17/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.7278 - val_loss: 1.3101\n",
      "Epoch 18/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.6541 - val_loss: 1.2493\n",
      "Epoch 19/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.6118 - val_loss: 1.2063\n",
      "Epoch 20/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.5430 - val_loss: 1.1515\n",
      "Epoch 21/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.5125 - val_loss: 1.1247\n",
      "Epoch 22/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.4717 - val_loss: 1.0803\n",
      "Epoch 23/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.4250 - val_loss: 1.0493\n",
      "Epoch 24/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.3972 - val_loss: 1.0118\n",
      "Epoch 25/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.3489 - val_loss: 0.9829\n",
      "Epoch 26/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.3129 - val_loss: 0.9574\n",
      "Epoch 27/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.2791 - val_loss: 0.9342\n",
      "Epoch 28/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.2629 - val_loss: 0.9226\n",
      "Epoch 29/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.1994 - val_loss: 0.8940\n",
      "Epoch 30/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.1837 - val_loss: 0.8787\n",
      "Epoch 31/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.1628 - val_loss: 0.8616\n",
      "Epoch 32/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.1449 - val_loss: 0.8395\n",
      "Epoch 33/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.1113 - val_loss: 0.8278\n",
      "Epoch 34/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.0866 - val_loss: 0.8171\n",
      "Epoch 35/10000\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 0.7928\n",
      "Epoch 36/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.0515 - val_loss: 0.7800\n",
      "Epoch 37/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.0375 - val_loss: 0.7615\n",
      "Epoch 38/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.0144 - val_loss: 0.7537\n",
      "Epoch 39/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.9867 - val_loss: 0.7435\n",
      "Epoch 40/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.9383 - val_loss: 0.7218\n",
      "Epoch 41/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.9460 - val_loss: 0.7177\n",
      "Epoch 42/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.8973 - val_loss: 0.7041\n",
      "Epoch 43/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.8792 - val_loss: 0.6880\n",
      "Epoch 44/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.8404 - val_loss: 0.6704\n",
      "Epoch 45/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.8435 - val_loss: 0.6660\n",
      "Epoch 46/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.8261 - val_loss: 0.6509\n",
      "Epoch 47/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.7888 - val_loss: 0.6381\n",
      "Epoch 48/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.7782 - val_loss: 0.6164\n",
      "Epoch 49/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.7607 - val_loss: 0.5978\n",
      "Epoch 50/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.7611 - val_loss: 0.5863\n",
      "Epoch 51/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.7226 - val_loss: 0.5820\n",
      "Epoch 52/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.7233 - val_loss: 0.5726\n",
      "Epoch 53/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.7084 - val_loss: 0.5639\n",
      "Epoch 54/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.6761 - val_loss: 0.5500\n",
      "Epoch 55/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.6646 - val_loss: 0.5457\n",
      "Epoch 56/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.6380 - val_loss: 0.5249\n",
      "Epoch 57/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.6453 - val_loss: 0.5114\n",
      "Epoch 58/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.6296 - val_loss: 0.4991\n",
      "Epoch 59/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.6102 - val_loss: 0.4911\n",
      "Epoch 60/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5841 - val_loss: 0.4823\n",
      "Epoch 61/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5836 - val_loss: 0.4745\n",
      "Epoch 62/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.5686 - val_loss: 0.4654\n",
      "Epoch 63/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5549 - val_loss: 0.4532\n",
      "Epoch 64/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.5498 - val_loss: 0.4409\n",
      "Epoch 65/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.5423 - val_loss: 0.4302\n",
      "Epoch 66/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5181 - val_loss: 0.4251\n",
      "Epoch 67/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4987 - val_loss: 0.4158\n",
      "Epoch 68/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4963 - val_loss: 0.4010\n",
      "Epoch 69/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4789 - val_loss: 0.3958\n",
      "Epoch 70/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4711 - val_loss: 0.3945\n",
      "Epoch 71/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4547 - val_loss: 0.3858\n",
      "Epoch 72/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4424 - val_loss: 0.3768\n",
      "Epoch 73/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4334 - val_loss: 0.3700\n",
      "Epoch 74/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4251 - val_loss: 0.3630\n",
      "Epoch 75/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4121 - val_loss: 0.3506\n",
      "Epoch 76/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4115 - val_loss: 0.3459\n",
      "Epoch 77/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3917 - val_loss: 0.3397\n",
      "Epoch 78/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3891 - val_loss: 0.3330\n",
      "Epoch 79/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3751 - val_loss: 0.3259\n",
      "Epoch 80/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3678 - val_loss: 0.3193\n",
      "Epoch 81/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3639 - val_loss: 0.3063\n",
      "Epoch 82/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3403 - val_loss: 0.2974\n",
      "Epoch 83/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3388 - val_loss: 0.2925\n",
      "Epoch 84/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3339 - val_loss: 0.2860\n",
      "Epoch 85/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3247 - val_loss: 0.2831\n",
      "Epoch 86/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3170 - val_loss: 0.2759\n",
      "Epoch 87/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3036 - val_loss: 0.2689\n",
      "Epoch 88/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2962 - val_loss: 0.2675\n",
      "Epoch 89/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2907 - val_loss: 0.2589\n",
      "Epoch 90/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2808 - val_loss: 0.2532\n",
      "Epoch 91/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2686 - val_loss: 0.2452\n",
      "Epoch 92/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2659 - val_loss: 0.2394\n",
      "Epoch 93/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2623 - val_loss: 0.2329\n",
      "Epoch 94/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2503 - val_loss: 0.2282\n",
      "Epoch 95/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2505 - val_loss: 0.2172\n",
      "Epoch 96/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2457 - val_loss: 0.2107\n",
      "Epoch 97/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2347 - val_loss: 0.2097\n",
      "Epoch 98/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2257 - val_loss: 0.2061\n",
      "Epoch 99/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2191 - val_loss: 0.2036\n",
      "Epoch 100/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2130 - val_loss: 0.1982\n",
      "Epoch 101/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2132 - val_loss: 0.1886\n",
      "Epoch 102/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2024 - val_loss: 0.1923\n",
      "Epoch 103/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2013 - val_loss: 0.1817\n",
      "Epoch 104/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1915 - val_loss: 0.1779\n",
      "Epoch 105/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1852 - val_loss: 0.1744\n",
      "Epoch 106/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1816 - val_loss: 0.1702\n",
      "Epoch 107/10000\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1726 - val_loss: 0.1651\n",
      "Epoch 108/10000\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1682 - val_loss: 0.1593\n",
      "Epoch 109/10000\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.1671 - val_loss: 0.1497\n",
      "Epoch 110/10000\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1591 - val_loss: 0.1476\n",
      "Epoch 111/10000\n",
      "80/80 [==============================] - 3s 33ms/step - loss: 0.1527 - val_loss: 0.1460\n",
      "Epoch 112/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1523 - val_loss: 0.1405\n",
      "Epoch 113/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1467 - val_loss: 0.1346\n",
      "Epoch 114/10000\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1405 - val_loss: 0.1329\n",
      "Epoch 115/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1325 - val_loss: 0.1212\n",
      "Epoch 116/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1294 - val_loss: 0.1215\n",
      "Epoch 117/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1284 - val_loss: 0.1185\n",
      "Epoch 118/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1209 - val_loss: 0.1133\n",
      "Epoch 119/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1170 - val_loss: 0.1121\n",
      "Epoch 120/10000\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1136 - val_loss: 0.1049\n",
      "Epoch 121/10000\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.1105 - val_loss: 0.0983\n",
      "Epoch 122/10000\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1081 - val_loss: 0.0954\n",
      "Epoch 123/10000\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1041 - val_loss: 0.0914\n",
      "Epoch 124/10000\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1010 - val_loss: 0.0882\n",
      "Epoch 125/10000\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0963 - val_loss: 0.0866\n",
      "Epoch 126/10000\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0926 - val_loss: 0.0834\n",
      "Epoch 127/10000\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0900 - val_loss: 0.0774\n",
      "Epoch 128/10000\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0887 - val_loss: 0.0741\n",
      "Epoch 129/10000\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.0830 - val_loss: 0.0713\n",
      "Epoch 130/10000\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0788 - val_loss: 0.0694\n",
      "Epoch 131/10000\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0798 - val_loss: 0.0689\n",
      "Epoch 132/10000\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0752 - val_loss: 0.0673\n",
      "Epoch 133/10000\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0735 - val_loss: 0.0625\n",
      "Epoch 134/10000\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0706 - val_loss: 0.0621\n",
      "Epoch 135/10000\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0680 - val_loss: 0.0605\n",
      "Epoch 136/10000\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0665 - val_loss: 0.0542\n",
      "Epoch 137/10000\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0601 - val_loss: 0.0531\n",
      "Epoch 138/10000\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0615 - val_loss: 0.0549\n",
      "Epoch 139/10000\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0586 - val_loss: 0.0487\n",
      "Epoch 140/10000\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0547 - val_loss: 0.0480\n",
      "Epoch 141/10000\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0520 - val_loss: 0.0481\n",
      "Epoch 142/10000\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0519 - val_loss: 0.0439\n",
      "Epoch 143/10000\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0500 - val_loss: 0.0407\n",
      "Epoch 144/10000\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0462 - val_loss: 0.0402\n",
      "Epoch 145/10000\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0468 - val_loss: 0.0375\n",
      "Epoch 146/10000\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0457 - val_loss: 0.0413\n",
      "Epoch 147/10000\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0449 - val_loss: 0.0364\n",
      "Epoch 148/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0408 - val_loss: 0.0367\n",
      "Epoch 149/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.0340\n",
      "Epoch 150/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0380 - val_loss: 0.0307\n",
      "Epoch 151/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0361 - val_loss: 0.0294\n",
      "Epoch 152/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0372 - val_loss: 0.0315\n",
      "Epoch 153/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0343 - val_loss: 0.0295\n",
      "Epoch 154/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.0278\n",
      "Epoch 155/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0347 - val_loss: 0.0326\n",
      "Epoch 156/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0342 - val_loss: 0.0282\n",
      "Epoch 157/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0343 - val_loss: 0.0264\n",
      "Epoch 158/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0341 - val_loss: 0.0271\n",
      "Epoch 159/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0345 - val_loss: 0.0275\n",
      "Epoch 160/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0223\n",
      "Epoch 161/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0298 - val_loss: 0.0231\n",
      "Epoch 162/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.0226\n",
      "Epoch 163/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.0258\n",
      "Epoch 164/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0302 - val_loss: 0.0232\n",
      "Epoch 165/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.0212\n",
      "Epoch 166/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.0194\n",
      "Epoch 167/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0239\n",
      "Epoch 168/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0208\n",
      "Epoch 169/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0298 - val_loss: 0.0185\n",
      "Epoch 170/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.0288\n",
      "Epoch 171/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0327 - val_loss: 0.0206\n",
      "Epoch 172/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.0200\n",
      "Epoch 173/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0252\n",
      "Epoch 174/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0233\n",
      "Epoch 175/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0214\n",
      "Epoch 176/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0202\n",
      "Epoch 177/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.0196\n",
      "Epoch 178/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0205\n",
      "Epoch 179/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0192\n",
      "Epoch 180/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0220\n",
      "Epoch 181/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0207\n",
      "Epoch 182/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0185\n",
      "Epoch 183/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0220\n",
      "Epoch 184/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0194\n",
      "Epoch 185/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0209\n",
      "Epoch 186/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0213\n",
      "Epoch 187/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0221\n",
      "Epoch 188/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0200\n",
      "Epoch 189/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0180\n",
      "Epoch 190/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0191\n",
      "Epoch 191/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0194\n",
      "Epoch 192/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0195\n",
      "Epoch 193/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0200\n",
      "Epoch 194/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0248\n",
      "Epoch 195/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0214\n",
      "Epoch 196/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0208\n",
      "Epoch 197/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0283 - val_loss: 0.0198\n",
      "Epoch 198/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0167\n",
      "Epoch 199/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0234\n",
      "Epoch 200/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0258 - val_loss: 0.0188\n",
      "Epoch 201/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0247\n",
      "Epoch 202/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0268\n",
      "Epoch 203/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0180\n",
      "Epoch 204/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.0254\n",
      "Epoch 205/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0187\n",
      "Epoch 206/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.0187\n",
      "Epoch 207/10000\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0244 - val_loss: 0.0174\n",
      "Epoch 208/10000\n",
      "80/80 [==============================] - 3s 32ms/step - loss: 0.0264 - val_loss: 0.0206\n",
      "Epoch 209/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0260 - val_loss: 0.0212\n",
      "Epoch 210/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0253 - val_loss: 0.0216\n",
      "Epoch 211/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.0204\n",
      "Epoch 212/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0234\n",
      "Epoch 213/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0174\n",
      "Epoch 214/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.0204\n",
      "Epoch 215/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0213\n",
      "Epoch 216/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0204\n",
      "Epoch 217/10000\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.0187\n",
      "Epoch 218/10000\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.0237\n"
     ]
    }
   ],
   "source": [
    "dtStartTime = time.time()\n",
    "oPredictiveModel.fit(\n",
    "    aInputTrain, \n",
    "    aOutputTrain, \n",
    "    epochs=iEpochSize, \n",
    "    batch_size=iBatchSize, \n",
    "    verbose=1, \n",
    "    validation_data= (aInputValidation, aOutputValidation),\n",
    "    validation_batch_size= iBatchSize\n",
    "    ,callbacks=[oEarlyStop]\n",
    ")\n",
    "dtEndTime = time.time()\n",
    "dtTrainingDuration = dtEndTime -dtStartTime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857470db-83a8-4c90-ac73-bb6300ef196a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "141bb9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "oFig = sns.lineplot(data = pd.DataFrame(oPredictiveModel.history.history))\n",
    "oFig.get_figure().savefig(sModelName + '\\epochs.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680ac53a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8f88fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "oPredictiveModel.save_weights(sModelName+'\\model weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75633cc0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d372e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "oPredictiveModel.load_weights(sModelName+'\\model weights')\n",
    "\n",
    "aPrediction = oPredictiveModel.predict(aInputTest)\n",
    "aPrediction = aPrediction.reshape((-1, iForwardTimeWindow * iNrOutputFeatures))\n",
    "dfPrediction = pd.DataFrame(data = aPrediction, index = ixTest, columns = aIxOutputColumns)\n",
    "\n",
    "aActual = aOutputTest.reshape((-1, iForwardTimeWindow * iNrOutputFeatures))\n",
    "dfActual =  pd.DataFrame(data = aActual, index = ixTest, columns = aIxOutputColumns).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd31b058-6e14-4012-b227-97cf02dc0099",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76dfeae2-ea8d-4b16-aae1-a854d1b70708",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfActual.to_csv(sModelName + '\\dfActual.csv')\n",
    "dfPrediction.to_csv(sModelName + '\\dfPrediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d71eb51-1037-4b8e-9d10-f648c0a0a7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPerformance = pd.DataFrame(data = [dtTrainingDuration], columns = ['value'], index = ['training duration'] )\n",
    "dfPerformance.to_csv(sModelName + '\\dfPerformance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ca3ab0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# REFERENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49501761",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/keras/train_and_evaluate#passing_data_to_multi-input_multi-output_models\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch/\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit/\n",
    "\n",
    "https://towardsdatascience.com/customize-loss-function-to-make-lstm-model-more-applicable-in-stock-price-prediction-b1c50e50b16c\n",
    "\n",
    "https://keras.io/getting_started/faq/\n",
    "\n",
    "https://machinelearningmastery.com/how-to-develop-lstm-models-for-multi-step-time-series-forecasting-of-household-power-consumption/\n",
    "\n",
    "https://www.tensorflow.org/tutorials/structured_data/time_series\n",
    "\n",
    "https://towardsdatascience.com/encoder-decoder-model-for-multistep-time-series-forecasting-using-pytorch-5d54c6af6e60\n",
    "\n",
    "https://levelup.gitconnected.com/building-seq2seq-lstm-with-luong-attention-in-keras-for-time-series-forecasting-1ee00958decb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
