{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0611acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import pytz\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, max_error, median_absolute_error, r2_score, explained_variance_score\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from Long_Short_Term_Memory import Long_Short_Term_Memory\n",
    "\n",
    "from Optimize_Portfolio import PortfolioManagement\n",
    "\n",
    "import MetaTrader5 as mt5\n",
    "\n",
    "import ta\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3c6fc32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_o_TIME_ZONE = pytz.timezone(\"Etc/UTC\")\n",
    "gc_dt_FROM = datetime(2019, 1, 1, tzinfo=gc_o_TIME_ZONE)\n",
    "gc_dt_TO = datetime(2021, 11, 10, tzinfo=gc_o_TIME_ZONE)\n",
    "\n",
    "gc_i_BACKWARD_TIME_WINDOW = -1\n",
    "gc_i_FORWARD_TIME_WINDOW = 5\n",
    "\n",
    "gc_dec_TRAINING_RATIO = 0.6\n",
    "gc_dec_VALIDATION_RATIO = 0.2\n",
    "gc_dec_TEST_RATIO = 0.2\n",
    "\n",
    "g_aBackwardTimeSteps = range(gc_i_BACKWARD_TIME_WINDOW, 0)\n",
    "g_aForwardTimeSteps = range(gc_i_FORWARD_TIME_WINDOW)\n",
    "\n",
    "g_aInputFeatures = set(['open', 'high', 'low', 'close', 'spread' ,'tick_volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4727b224",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def ConvertSpreadValues(dfRates, aSymbolInfo):\n",
    "    iDigits = aSymbolInfo.digits\n",
    "    dfRates['spread'] = dfRates['spread'] * pow(10, -iDigits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "041e482c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def dfShiftTimeSteps(dfRates, aTimeSteps):\n",
    "    \n",
    "    lstColumnNames = list([])\n",
    "    for iTimeStep in aTimeSteps:\n",
    "        for tplCol in dfRates.columns:\n",
    "            lstColumnNames.append((iTimeStep, ) + tplCol)\n",
    "    \n",
    "    \n",
    "    lstIndexNames = (\"Time Step\",) +  tuple(dfRates.columns.names)\n",
    "    \n",
    "    dicColumnIndices = pd.MultiIndex.from_tuples(\n",
    "        lstColumnNames,\n",
    "        names = lstIndexNames\n",
    "        )\n",
    "\n",
    "\n",
    "    dfShiftedRates = pd.DataFrame(\n",
    "        columns=dicColumnIndices, \n",
    "        index=dfRates.index)\n",
    "    \n",
    "    \n",
    "\n",
    "    for i in aTimeSteps:\n",
    "        dfShiftedRates[i] = dfRates.shift(-i)\n",
    "\n",
    "    dfShiftedRates.dropna(inplace=True)\n",
    "\n",
    "    return dfShiftedRates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bad524f3",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def dfGetMarketData(sSymbol):\n",
    "\n",
    "    if not mt5.initialize():\n",
    "        print(\"initialize() failed, error code =\", mt5.last_error())\n",
    "        sys.exit()\n",
    "\n",
    "    aSymbolInfo = mt5.symbol_info(sSymbol)\n",
    "    if not aSymbolInfo:\n",
    "        print(\"symbol_info() failed, error code =\", mt5.last_error())\n",
    "        sys.exit()\n",
    "\n",
    "    aRates = mt5.copy_rates_range(\n",
    "        sSymbol, mt5.TIMEFRAME_H1, gc_dt_FROM, gc_dt_TO)\n",
    "    if len(aRates) == 0:\n",
    "        print(\"copy_rates_range() failed, error code =\", mt5.last_error())\n",
    "        sys.exit()\n",
    "\n",
    "    mt5.shutdown()\n",
    "\n",
    "    dfRates = pd.DataFrame(aRates)\n",
    "\n",
    "    dfRates['time'] = pd.to_datetime(dfRates['time'], unit='s')\n",
    "    dfRates.set_index('time', inplace=True)\n",
    "    dfRates.drop('real_volume', axis=1, inplace=True)\n",
    "\n",
    "    ConvertSpreadValues(dfRates, aSymbolInfo)\n",
    "    AddSeasonalFeatures(dfRates)\n",
    "    AddReturns(dfRates)\n",
    "#     dfRates = dfAddTechnicalIndicators(dfRates)\n",
    "\n",
    "    dfRates.columns  = pd.MultiIndex.from_product(\n",
    "        [[sSymbol], dfRates.columns], \n",
    "        names=[\"Time Series\", \"Feature\"])\n",
    "    \n",
    "    \n",
    "    return dfRates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d9f70b2",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def dfAddTechnicalIndicators(dfRates):\n",
    "    global g_aInputFeatures \n",
    "    \n",
    "    \n",
    "    iTimeWindow = 24\n",
    "    \n",
    "    dfHigh = dfRates[\"high\"]\n",
    "    dfLow = dfRates[\"low\"]\n",
    "    dfClose = dfRates[\"close\"]\n",
    "    \n",
    "    # Average Dricetional Movement Index\n",
    "    oAdx = ta.trend.ADXIndicator(dfHigh, dfLow, dfClose, iTimeWindow, False)\n",
    "    \n",
    "    dfAdx = oAdx.adx()\n",
    "    dfAdx.drop(dfAdx[dfAdx == 0].index, inplace = True)\n",
    "    g_aInputFeatures.add(dfAdx.name)\n",
    "    \n",
    "    dfAdxNeg = oAdx.adx_neg()\n",
    "    dfAdxNeg.drop(dfAdxNeg[dfAdxNeg == 0].index, inplace = True)\n",
    "    g_aInputFeatures.add(dfAdxNeg.name)\n",
    "    \n",
    "    \n",
    "    dfAdxPos = oAdx.adx_pos()\n",
    "    dfAdxPos.drop(dfAdxPos[dfAdxPos == 0].index, inplace = True)\n",
    "    g_aInputFeatures.add(dfAdxPos.name)\n",
    "    \n",
    "    \n",
    "    dfRates = dfRates.join(dfAdx, how = \"inner\")\n",
    "    dfRates = dfRates.join(dfAdxNeg, how = \"inner\")\n",
    "    dfRates = dfRates.join(dfAdxPos, how = \"inner\")\n",
    "\n",
    "    \n",
    "    # Aroon Indicator\n",
    "    oAroon = ta.trend.AroonIndicator(dfClose, iTimeWindow, False)\n",
    "    dfAroonDown = oAroon.aroon_down()\n",
    "    dfAroonDown.dropna(inplace = True)\n",
    "    g_aInputFeatures.add(dfAroonDown.name)\n",
    "    \n",
    "    dfAroonIndicator = oAroon.aroon_indicator() \n",
    "    dfAroonIndicator.dropna(inplace = True)\n",
    "    g_aInputFeatures.add(dfAroonIndicator.name)\n",
    "\n",
    "    \n",
    "    dfAroonUp = oAroon.aroon_up()\n",
    "    dfAroonUp.dropna(inplace = True)\n",
    "    g_aInputFeatures.add(dfAroonUp.name)\n",
    "    \n",
    "    dfRates = dfRates.join(dfAroonDown, how = \"inner\")\n",
    "    dfRates = dfRates.join(dfAroonIndicator, how = \"inner\")\n",
    "    dfRates = dfRates.join(dfAroonUp, how = \"inner\")\n",
    "    \n",
    "    \n",
    "    # Commodity Channel Index\n",
    "    oCci = ta.trend.CCIIndicator(dfHigh, dfLow,dfClose, iTimeWindow)\n",
    "    dfCci = oCci.cci()\n",
    "    dfCci.dropna(inplace = True)\n",
    "    g_aInputFeatures.add(dfCci.name)\n",
    "    \n",
    "    dfRates = dfRates.join(dfCci, how = \"inner\")\n",
    "    \n",
    "    \n",
    "    # Detrended Price Oscillator (DPO)\n",
    "    oDpo = ta.trend.DPOIndicator(dfClose, iTimeWindow)\n",
    "    dfDpo = oDpo.dpo()\n",
    "    dfDpo.dropna(inplace = True)\n",
    "    g_aInputFeatures.add(dfDpo.name)    \n",
    "    \n",
    "    dfRates = dfRates.join(dfDpo, how = \"inner\")\n",
    "    \n",
    "    \n",
    "    # EMA - Exponential Moving Average\n",
    "    oEma = ta.trend.EMAIndicator(dfClose, iTimeWindow)\n",
    "    dfEma = oEma.ema_indicator()\n",
    "    dfEma.dropna(inplace = True)\n",
    "    g_aInputFeatures.add(dfEma.name)\n",
    "    \n",
    "    dfRates = dfRates.join(dfEma, how = \"inner\")\n",
    "    \n",
    "    \n",
    "    return dfRates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f89a65d2",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def AddSeasonalFeatures(dfRates):\n",
    "    global g_aInputFeatures \n",
    "    \n",
    "    c_a_SEASONAL_FEATURES = [\"year\", \"month\", \"day\", \"dayofweek\", \"hour\"]\n",
    "    for sSeasonalFeature in c_a_SEASONAL_FEATURES:\n",
    "        exec(\"dfRates[sSeasonalFeature] = dfRates.index.\" + sSeasonalFeature)\n",
    "        g_aInputFeatures.add(sSeasonalFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17475e81",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def AddReturns(dfRates):\n",
    "    dfRates[\"return\"] = (dfRates[\"open\"] - dfRates[\"close\"])/dfRates[\"open\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e680ce9d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def dfOversampleImbalancedData(dfX, dfY):\n",
    "    \n",
    "#     oOversample = SMOTE()\n",
    "#     aX, aY = oOversample.fit_resample(dfX.values, dfY.values)\n",
    "    \n",
    "#     dfX = pd.DataFrame(data = aX, columns = dfX.columns)\n",
    "#     dfY = pd.DataFrame(data = aY, columns = dfY.columns)\n",
    "    \n",
    "    dfXCopy = dfX.copy()\n",
    "    dfYCopy = dfY.copy()\n",
    "        \n",
    "    dfCombinations = dfYCopy.astype(str).agg('-'.join, axis=1)\n",
    "    dfCombinationsStats = dfCombinations.value_counts()\n",
    "    dfCombinationsStats = pd.DataFrame(dfCombinationsStats).reset_index()\n",
    "    \n",
    "    \n",
    "    iMaxAmount = dfCombinationsStats.iloc[0,1]\n",
    "    for i in range(1, len(dfCombinationsStats) ):\n",
    "        \n",
    "        sCombination = dfCombinationsStats.iloc[i, 0]\n",
    "        iSamplesNeeded = iMaxAmount - dfCombinationsStats.iloc[i, 1]\n",
    "        \n",
    "        dfSampledIndex =  dfCombinations[dfCombinations == sCombination].sample(iSamplesNeeded, replace = True).index\n",
    "        \n",
    "        dfSampledX = dfXCopy.loc[dfSampledIndex]\n",
    "        dfSampledY = dfYCopy.loc[dfSampledIndex]\n",
    "        \n",
    "    \n",
    "        dfX = dfX.append(dfSampledX , ignore_index= True)\n",
    "        dfY = dfY.append(dfSampledY , ignore_index= True)\n",
    "        \n",
    "    \n",
    "    dfX,dfY = shuffle(dfX,dfY )\n",
    "    \n",
    "\n",
    "    return dfX, dfY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "682253c6",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def dfSplitData(dfInput, dfOutput):\n",
    "    dfInputTrainValidation, dfInputTest, dfOutputTrainValidation, dfOutputTest = train_test_split(\n",
    "        dfInput,\n",
    "        dfOutput,\n",
    "        test_size=gc_dec_TEST_RATIO,\n",
    "        shuffle=False)\n",
    "\n",
    "    dfInputTrain, dfInputValidation, dfOutputTrain, dfOutputValidation = train_test_split(\n",
    "        dfInputTrainValidation,\n",
    "        dfOutputTrainValidation,\n",
    "        test_size=(1/(1 -gc_dec_TEST_RATIO))-1,\n",
    "        shuffle=False)\n",
    "    \n",
    "    \n",
    "    dfInputTrain = dfInputTrain.astype(float)\n",
    "    dfInputValidation = dfInputValidation.astype(float)\n",
    "    dfInputTest = dfInputTest.astype(float)\n",
    "    dfOutputTrain = dfOutputTrain.astype(float)\n",
    "    dfOutputValidation = dfOutputValidation.astype(float)\n",
    "    dfOutputTest = dfOutputTest.astype(float)\n",
    "    \n",
    "    return dfInputTrain, dfInputValidation, dfInputTest, dfOutputTrain, dfOutputValidation, dfOutputTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca3eba12",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def dfScaleData(sScalerName,dfTrain,dfValidation, dfTest, bIsStandard = True):\n",
    "    sScalersDirectory = os.path.join(sSubModelName , \"__scalers__\")\n",
    "    if bIsStandard == True:\n",
    "        oScaler = StandardScaler()\n",
    "    else:\n",
    "        oScaler = MinMaxScaler()\n",
    "\n",
    "    oScaler.fit(dfTrain)\n",
    "\n",
    "    aScaledTrain = oScaler.transform(dfTrain)\n",
    "    aScaledValidation = oScaler.transform(dfValidation)\n",
    "    aScaledTest = oScaler.transform(dfTest)\n",
    "\n",
    "    dfScaledTrain = pd.DataFrame(aScaledTrain, columns = dfTrain.columns, index = dfTrain.index)\n",
    "    dfScaledValidation = pd.DataFrame(aScaledValidation, columns = dfValidation.columns, index = dfValidation.index)\n",
    "    dfScaledTest = pd.DataFrame(aScaledTest, columns = dfTest.columns, index = dfTest.index)\n",
    "\n",
    "    sScalerFilePath =os.path.join(sScalersDirectory, sScalerName + \".sav\")\n",
    "    os.makedirs(os.path.dirname(sScalerFilePath), exist_ok=True)\n",
    "    pickle.dump(oScaler, open(sScalerFilePath, 'wb'))\n",
    "    \n",
    "    \n",
    "    return dfScaledTrain, dfScaledValidation, dfScaledTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e4f79bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "aLimits = [0.00003, 0.0005, 0.0025, 0.005]\n",
    "aNearLimits = [0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b614d9a",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def iLen(dfT):\n",
    "    return dfT.shape[0]\n",
    "\n",
    "def fOp(dfCi):\n",
    "    return dfCi[\"open\"]\n",
    "\n",
    "def fHp(dfCi):\n",
    "    return dfCi[\"high\"]\n",
    "\n",
    "def fLp(dfCi):\n",
    "    return dfCi[\"low\"]\n",
    "\n",
    "def fCp(dfCi):\n",
    "    return dfCi[\"close\"]\n",
    "\n",
    "def fHb(dfCi):\n",
    "    return abs(fCp(dfCi)-fOp(dfCi))\n",
    "\n",
    "def iId(dfS):\n",
    "    return dfS.iloc[0].name\n",
    "\n",
    "def fTpBody(dfCi):\n",
    "    return max(fOp(dfCi), fCp(dfCi))\n",
    "\n",
    "def fBmBody(dfCi):\n",
    "    return min(fOp(dfCi), fCp(dfCi))\n",
    "\n",
    "def fUs(dfCi):\n",
    "    return fHp(dfCi) - fTpBody(dfCi)\n",
    "\n",
    "def fLs(dfCi):\n",
    "    return fBmBody(dfCi) - fLp(dfCi)\n",
    "\n",
    "def fHs(dfCi):\n",
    "    return fUs(dfCi) + fLs(dfCi)\n",
    "\n",
    "def fAp(dfSTC):\n",
    "    return dfSTC[\"close\"].mean()\n",
    "\n",
    "def iPt(dfTC):\n",
    "    if fAp(dfTC.iloc[0:5]) < fAp(dfTC.iloc[1:6]):\n",
    "        if fAp(dfTC.iloc[2:7]) < fAp(dfTC.iloc[3:8]):\n",
    "            return 1\n",
    "    if fAp(dfTC.iloc[0:5]) > fAp(dfTC.iloc[1:6]):\n",
    "        if fAp(dfTC.iloc[2:7]) > fAp(dfTC.iloc[3:8]):\n",
    "            return -1\n",
    "        \n",
    "    return 0\n",
    "    \n",
    "def bSliGreater(fX, fY):\n",
    "    fRatio = abs((fX-fY)/fY)\n",
    "    if aLimits[0]<= fRatio and fRatio<aLimits[1]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def bModGreater(fX, fY):\n",
    "    fRatio = abs((fX-fY)/fY)\n",
    "    if aLimits[1]<= fRatio and fRatio<aLimits[2]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def bLarGreater(fX, fY):\n",
    "    fRatio = abs((fX-fY)/fY)\n",
    "    if aLimits[2]<= fRatio and fRatio<aLimits[3]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def bExtGreater(fX, fY):\n",
    "    fRatio = abs((fX-fY)/fY)\n",
    "    if fRatio>=aLimits[3]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    \n",
    "def bSliLess(fX, fY):\n",
    "    fRatio = abs((fY-fX)/fX)\n",
    "    if aLimits[0]<= fRatio and fRatio<aLimits[1]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "\n",
    "def bModLess(fX, fY):\n",
    "    fRatio = abs((fY-fX)/fX)\n",
    "    if aLimits[1]<= fRatio and fRatio<aLimits[2]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def bLarLess(fX, fY):\n",
    "    fRatio = abs((fY-fX)/fX)\n",
    "    if aLimits[2]<= fRatio and fRatio<aLimits[3]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def bExtLess(fX, fY):\n",
    "    fRatio = abs((fY-fX)/fX)\n",
    "    if fRatio>=aLimits[3]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def bExtNear(fX, fY):\n",
    "    fRatio = abs((abs(fX-fY))/max(fX,fY))\n",
    "    if fRatio<=aLimits[0]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "def bModNear(fX, fY):\n",
    "    fRatio = abs((abs(fX-fY))/max(fX,fY))\n",
    "    if aLimits[0]<= fRatio and fRatio<aLimits[1]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def bNear(fX, fY):\n",
    "    fRatio = abs((abs(fX-fY))/max(fX,fY))\n",
    "    if 0<= fRatio and fRatio<aLimits[1]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def bNearUp(fX, fY):\n",
    "    fRatio = abs((fY-fX)/fY)\n",
    "    if aNearLimits[0]<= fRatio and fRatio<aLimits[0]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def bNearDown(fX, fY):\n",
    "    fRatio = abs((fX-fY)/fX)\n",
    "    if aNearLimits[0]<= fRatio and fRatio<aLimits[0]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def dfGetElement(dfT, sEle):\n",
    "    return dfT.apply(sEle, axis = 1)\n",
    "\n",
    "def fAvgGetElement(dfT, sEle):\n",
    "    return dfT.apply(sEle, axis = 1).mean()\n",
    "\n",
    "def bDoji(dfCi):\n",
    "    return bExtNear(fOp(dfCi), fCp(dfCi))\n",
    "\n",
    "def bSmallBody(dfCi):\n",
    "    return bSliLess(fBmBody(dfCi), fTpBody(dfCi))\n",
    "\n",
    "def bNormalBody(dfCi):\n",
    "    return bModLess(fBmBody(dfCi), fTpBody(dfCi))\n",
    "\n",
    "def bLongBody(dfCi):\n",
    "    return bLarLess(fBmBody(dfCi), fTpBody(dfCi))\n",
    "\n",
    "def bElBody(dfCi):\n",
    "    return bExtLess(fBmBody(dfCi), fTpBody(dfCi))\n",
    "\n",
    "def bNoUs(dfCi):\n",
    "    return bExtNear(fHp(dfCi), fTpBody(dfCi))\n",
    "\n",
    "def bSmallUs(dfCi):\n",
    "    return bSliGreater(fHp(dfCi), fTpBody(dfCi))\n",
    "\n",
    "def bNormalUs(dfCi):\n",
    "    return bModGreater(fHp(dfCi), fTpBody(dfCi))\n",
    "\n",
    "def bLongUs(dfCi):\n",
    "    return bLarGreater(fHp(dfCi), fTpBody(dfCi))\n",
    "\n",
    "def bElUs(dfCi):\n",
    "    return bExtGreater(fHp(dfCi), fTpBody(dfCi))\n",
    "\n",
    "def bNoLs(dfCi):\n",
    "    return bExtNear(fLp(dfCi), fBmBody(dfCi))\n",
    "\n",
    "def bSmallLs(dfCi):\n",
    "    return bSliLess(fLp(dfCi), fBmBody(dfCi))\n",
    "\n",
    "def bNormalLs(dfCi):\n",
    "    return bModLess(fLp(dfCi), fBmBody(dfCi))\n",
    "\n",
    "def bLongLs(dfCi):\n",
    "    return bLarLess(fLp(dfCi), fBmBody(dfCi))\n",
    "\n",
    "def bElLs(dfCi):\n",
    "    return bExtLess(fLp(dfCi), fBmBody(dfCi))\n",
    "\n",
    "def bBlackBody(dfCi):\n",
    "    return fOp(dfCi)> fCp(dfCi)\n",
    "\n",
    "def bWhiteBody(dfCi):\n",
    "    return fOp(dfCi)< fCp(dfCi)\n",
    "\n",
    "def bSmallBlackBody(dfCi):\n",
    "    return bSmallBody(dfCi) and bBlackBody(dfCi)\n",
    "\n",
    "def bSmallWhiteBody(dfCi):\n",
    "    return bSmallBody(dfCi) and bWhiteBody(dfCi)\n",
    "\n",
    "def bNormalBlackBody(dfCi):\n",
    "    return bNormalBody(dfCi) and bBlackBody(dfCi)\n",
    "\n",
    "def bNormalWhiteBody(dfCi):\n",
    "    return bNormalBody(dfCi) and bWhiteBody(dfCi)\n",
    "\n",
    "def bLongBlackBody(dfCi):\n",
    "    return bLongBody(dfCi) and bBlackBody(dfCi)\n",
    "\n",
    "def bLongWhiteBody(dfCi):\n",
    "    return bLongBody(dfCi) and bWhiteBody(dfCi)\n",
    "\n",
    "def bElBlackBody(dfCi):\n",
    "    return bElBody(dfCi) and bBlackBody(dfCi)\n",
    "\n",
    "def bElWhiteBody(dfCi):\n",
    "    return bElBody(dfCi) and bWhiteBody(dfCi)\n",
    "\n",
    "def bDownShadowGap(dfCi, dfCj):\n",
    "    return fLp(dfCi)>fHp(dfCj)\n",
    "\n",
    "def bUpShadowGap(dfCi, dfCj):\n",
    "    return fHp(dfCi)<fLp(dfCj)\n",
    "\n",
    "def bDownBodyGap(dfCi, dfCj):\n",
    "    return fBmBody(dfCi)>fTpBody(dfCj)\n",
    "\n",
    "def bUpBodyGap(dfCi, dfCj):\n",
    "    return fTpBody(dfCi)<fTpBody(dfCj)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2af75b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bMarubozuBlack(dfCi):\n",
    "    return bNoUs(dfCi) and bLongBlackBody(dfCi) and bNoLs(dfCi)\n",
    "    \n",
    "def bMarubozuWhite(dfCi):\n",
    "    return bNoUs(dfCi) and bLongWhiteBody(dfCi) and bNoLs(dfCi)\n",
    "\n",
    "def bBeltHoldBullish(dfCi, dfTC):\n",
    "    return iPt(dfTC) == -1 and bLongWhiteBody(dfCi) and bNoLs(dfCi) and bModNear(fCp(dfCi), fHp(dfCi))\n",
    "\n",
    "def bMarubozuClosingBlack(dfCi):\n",
    "    return bLongBlackBody(dfCi) and bNoUs(dfCi) == False and bNoLs(dfCi)\n",
    "\n",
    "def bMarubozuOpeningWhite(dfCi):\n",
    "    return bLongWhiteBody(dfCi) and bNoUs(dfCi) == False and bNoLs(dfCi)\n",
    "\n",
    "def bShootingStarOneCandle(dfCi, dfTC):\n",
    "    return iPt(dfTC) == 1 and bLongUs(dfCi) and (fUs(dfCi)> (2*fHb(dfCi))) and bSmallBody(dfCi) and bNoLs(dfCi)\n",
    "\n",
    "def bDojiGravestone(dfCi):\n",
    "    return bDoji(dfCi) and bNoLs(dfCi) and bLongUs(dfCi)\n",
    "\n",
    "def bBeltHoldBearish(dfCi, dfTC):\n",
    "    return iPt(dfTC) == 1 and bNoUs(dfCi) and bSmallLs(dfCi) and bLongBlackBody(dfCi)\n",
    "\n",
    "def bDojiDragonfly(dfCi):\n",
    "    return bDoji(dfCi) and bSmallUs(dfCi) and bLongLs(dfCi)\n",
    "\n",
    "def bHammer(dfCi, dfTC):\n",
    "    return iPt(dfTC) == -1 and bSmallBody(dfCi) and bNoLs(dfCi) == False and (2*fHb(dfCi))< fLs(dfCi) and fLs(dfCi) < (3*fHb(dfCi)) and ((bSmallUs(dfCi)) or (bNoUs(dfCi)))\n",
    "\n",
    "def bHangingMan(dfCi, dfTC):\n",
    "    return iPt(dfTC) == 1 and bNoUs(dfCi) and bLongLs(dfCi) and bSmallBody(dfCi)\n",
    "    \n",
    "def bMarubozuOpeningBlack(dfCi):\n",
    "    return bLongBlackBody(dfCi) and bNoLs(dfCi) == False and bNoUs(dfCi)\n",
    "\n",
    "def bMarubozuClosingWhite(dfCi):\n",
    "    return bLongWhiteBody(dfCi) and bNoUs(dfCi) and bNoLs(dfCi) == False\n",
    "\n",
    "def bTakuriLine(dfCi, dfTC):\n",
    "    return iPt(dfTC) == -1 and bSmallBody(dfCi) and bNoUs(dfCi) and (fLs(dfCi) > (3*fHb(dfCi)))\n",
    "\n",
    "def bCandleBlack(dfCi):\n",
    "    return bNormalBlackBody(dfCi) and bNoUs(dfCi) == False and bNoLs(dfCi) == False and (fUs(dfCi)<fHb(dfCi)) and (fLs(dfCi)<fHb(dfCi))\n",
    "\n",
    "def bCandleShortBlack(dfCi):\n",
    "    return bSmallBlackBody(dfCi) and bNoUs(dfCi) == False and bNoLs(dfCi) == False and (fUs(dfCi)< fHb(dfCi)) and (fLs(dfCi)<fHb(dfCi))\n",
    "\n",
    "def bCandleWhite(dfCi):\n",
    "    return bNormalWhiteBody(dfCi) and bNoUs(dfCi) == False and bNoLs(dfCi) == False and (fUs(dfCi)< fHb(dfCi)) and (fLs(dfCi)<fHb(dfCi))\n",
    "\n",
    "def bCandleShortWhite(dfCi):\n",
    "    return bSmallWhiteBody(dfCi) and bNoUs(dfCi) == False and bNoLs(dfCi) == False and (fUs(dfCi)< fHb(dfCi)) and (fLs(dfCi)<fHb(dfCi))\n",
    "\n",
    "def bDojiGappingDown(dfCi, dfTC):\n",
    "    return iPt(dfTC) == -1 and bDoji(dfCi) and bDownShadowGap(dfTC.iloc[-1], dfCi)\n",
    "\n",
    "def bDojiGappingUp(dfCi, dfTC):\n",
    "    return iPt(dfTC) == 1 and bDoji(dfCi) and bUpShadowGap(dfTC.iloc[-1], dfCi)\n",
    "\n",
    "def bDojiLongLegged(dfCi):\n",
    "    return bDoji(dfCi) and bLongUs(dfCi) and bLongLs(dfCi)\n",
    "\n",
    "def bDojiNorthern(dfCi, dfTC):\n",
    "    return iPt(dfTC) == 1 and bDoji(dfCi)\n",
    "\n",
    "def bDojiSouthern(dfCi, dfTC):\n",
    "    return iPt(dfTC) == -1 and bDoji(dfCi)\n",
    "    \n",
    "def bHighWave(dfCi):\n",
    "    return bElUs(dfCi) and bElLs(dfCi) and bSmallBody(dfCi)\n",
    "\n",
    "def bLongBlackDay(dfCi, dfT):\n",
    "    return bLongBlackBody(dfCi) and ((fHb(dfCi) > (3*fAvgGetElement(dfT.iloc[-7:],fHb))) or (fHb(dfCi) > (3*fAvgGetElement(dfT.iloc[-14:],fHb)))) and fUs(dfCi) < fHb(dfCi) and fLs(dfCi) < fHb(dfCi)\n",
    "\n",
    "def bLongWhiteDay(dfCi, dfT):\n",
    "    return bLongWhiteBody(dfCi) and ((fHb(dfCi) > (3*fAvgGetElement(dfT.iloc[-7:],fHb))) or (fHb(dfCi) > (3*fAvgGetElement(dfT.iloc[-14:],fHb)))) and fUs(dfCi) < fHb(dfCi) and fLs(dfCi) < fHb(dfCi)\n",
    "    \n",
    "    \n",
    "def bRickshawMan(dfCi):\n",
    "    return bDoji(dfCi) and bNear( 0.5 * (fOp(dfCi) + fCp(dfCi)) , 0.5 * (fHp(dfCi) + fLp(dfCi))) and bElLs(dfCi) and bElUs(dfCi)\n",
    "\n",
    "def bSpinningTopBlack(dfCi):\n",
    "    return bSmallBlackBody(dfCi) and fUs(dfCi) > fHb(dfCi) and fLs(dfCi) > fHb(dfCi) and bNoLs(dfCi) == False and bNoUs(dfCi) == False\n",
    "\n",
    "\n",
    "def bSpinningTopWhite(dfCi):\n",
    "    return bSmallWhiteBody(dfCi) and fUs(dfCi) > fHb(dfCi) and fLs(dfCi) > fHb(dfCi) and bNoLs(dfCi) == False and bNoUs(dfCi) == False\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01b907d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRates = dfGetMarketData(\"EURUSD\")\n",
    "dfRates = dfRates.loc[:, \"EURUSD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8eb39022",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOutput = pd.DataFrame(index = dfRates.index)\n",
    "for i in g_aForwardTimeSteps:\n",
    "    dfOutput[i] = dfRates[\"return\"].shift(-i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f6f35e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-02 06:00:00</th>\n",
       "      <td>0.000061</td>\n",
       "      <td>-0.002884</td>\n",
       "      <td>-0.000645</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.002483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 07:00:00</th>\n",
       "      <td>-0.002884</td>\n",
       "      <td>-0.000645</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.001223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 08:00:00</th>\n",
       "      <td>-0.000645</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>-0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 09:00:00</th>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>-0.000245</td>\n",
       "      <td>0.000271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 10:00:00</th>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>-0.000245</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.002519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-09 20:00:00</th>\n",
       "      <td>0.000138</td>\n",
       "      <td>-0.000371</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>-0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-09 21:00:00</th>\n",
       "      <td>-0.000371</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-09 22:00:00</th>\n",
       "      <td>-0.000129</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-09 23:00:00</th>\n",
       "      <td>0.000267</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-10 00:00:00</th>\n",
       "      <td>-0.000026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17743 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0         1         2         3         4\n",
       "time                                                                 \n",
       "2019-01-02 06:00:00  0.000061 -0.002884 -0.000645  0.000766  0.002483\n",
       "2019-01-02 07:00:00 -0.002884 -0.000645  0.000766  0.002483  0.001223\n",
       "2019-01-02 08:00:00 -0.000645  0.000766  0.002483  0.001223 -0.000245\n",
       "2019-01-02 09:00:00  0.000766  0.002483  0.001223 -0.000245  0.000271\n",
       "2019-01-02 10:00:00  0.002483  0.001223 -0.000245  0.000271  0.002519\n",
       "...                       ...       ...       ...       ...       ...\n",
       "2021-11-09 20:00:00  0.000138 -0.000371 -0.000129  0.000267 -0.000026\n",
       "2021-11-09 21:00:00 -0.000371 -0.000129  0.000267 -0.000026       NaN\n",
       "2021-11-09 22:00:00 -0.000129  0.000267 -0.000026       NaN       NaN\n",
       "2021-11-09 23:00:00  0.000267 -0.000026       NaN       NaN       NaN\n",
       "2021-11-10 00:00:00 -0.000026       NaN       NaN       NaN       NaN\n",
       "\n",
       "[17743 rows x 5 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "973ebf75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dfOhlc = dfRates.copy()\n",
    "\n",
    "# iLoc = 0 \n",
    "# for dtIndex, dfCi in dfOhlc.iterrows():\n",
    "    \n",
    "#     dfOhlc.loc[dtIndex, \"BARUBOZU_BLACK\"] = bMarubozuBlack(dfCi)\n",
    "#     dfOhlc.loc[dtIndex, \"BARUBOZU_WHITE\"] = bMarubozuWhite(dfCi)\n",
    "    \n",
    "#     if iLoc > 7:\n",
    "#         dfTC = dfOhlc.iloc[iLoc-7:iLoc+1]\n",
    "        \n",
    "#         dfOhlc.loc[dtIndex, \"BELT_HOLD_BULLISH\"] = bBeltHoldBullish(dfCi, dfTC)\n",
    "#         dfOhlc.loc[dtIndex, \"SHOOTING_STAR_ONE_CANDLE\"] = bShootingStarOneCandle(dfCi, dfTC)\n",
    "#         dfOhlc.loc[dtIndex, \"BELT_HOLD_BEARISH\"] = bBeltHoldBearish(dfCi, dfTC)\n",
    "#         dfOhlc.loc[dtIndex, \"HAMMER\"] = bHammer(dfCi, dfTC)\n",
    "#         dfOhlc.loc[dtIndex, \"HANGING_BODY\"] = bHangingMan(dfCi, dfTC)\n",
    "#         dfOhlc.loc[dtIndex, \"TAKURI_LINE\"] = bTakuriLine(dfCi, dfTC)\n",
    "#         dfOhlc.loc[dtIndex, \"DOJI_GAPPING_DOWN\"] = bDojiGappingDown(dfCi, dfTC)\n",
    "#         dfOhlc.loc[dtIndex, \"DOJI_GAPPING_UP\"] = bDojiGappingUp(dfCi, dfTC)\n",
    "#         dfOhlc.loc[dtIndex, \"DOJI_NORTHERN\"] = bDojiNorthern(dfCi, dfTC)\n",
    "#         dfOhlc.loc[dtIndex, \"DOJI_SOUTHERN\"] = bDojiSouthern(dfCi, dfTC)\n",
    "    \n",
    "#         if iLoc > 13:\n",
    "#             dfT = dfOhlc.iloc[iLoc-13:iLoc+1]\n",
    "#             dfOhlc.loc[dtIndex, \"LONG_BLACK_DAY\"] = bLongBlackDay(dfCi, dfT)\n",
    "#             dfOhlc.loc[dtIndex, \"LONG_WHITE_DAY\"] = bLongWhiteDay(dfCi, dfT)\n",
    "            \n",
    "        \n",
    "        \n",
    "#     dfOhlc.loc[dtIndex, \"MARUBOZU_CLOSING_BLACK\"] = bMarubozuClosingBlack(dfCi)\n",
    "#     dfOhlc.loc[dtIndex, \"MARUBOZU_OPENING_WHITE\"] = bMarubozuOpeningWhite(dfCi)\n",
    "#     dfOhlc.loc[dtIndex, \"DOJI_GRAVESTONE\"] = bDojiGravestone(dfCi)\n",
    "#     dfOhlc.loc[dtIndex, \"DOJI_DRAGONFLY\"] = bDojiDragonfly(dfCi)\n",
    "#     dfOhlc.loc[dtIndex, \"MARUBOZU_OPENING_BLACK\"] = bMarubozuOpeningBlack(dfCi)\n",
    "#     dfOhlc.loc[dtIndex, \"MARUBOZU_CLOSING_WHITE\"] = bMarubozuClosingWhite(dfCi)\n",
    "#     dfOhlc.loc[dtIndex, \"CANDLE_BLACK\"] = bCandleBlack(dfCi)\n",
    "#     dfOhlc.loc[dtIndex, \"CANDLE_SHORT_BLACK\"] = bCandleShortBlack(dfCi)\n",
    "#     dfOhlc.loc[dtIndex, \"CANDLE_WHITE\"] = bCandleWhite(dfCi)\n",
    "#     dfOhlc.loc[dtIndex, \"CANDLE_SHORT_WHITE\"] = bCandleShortWhite(dfCi)\n",
    "#     dfOhlc.loc[dtIndex, \"DOJI_LONG_LEGGED\"] = bDojiLongLegged(dfCi)\n",
    "#     dfOhlc.loc[dtIndex, \"HIGH_WAVE\"] = bHighWave(dfCi)\n",
    "#     dfOhlc.loc[dtIndex, \"RICKSHAW_MAN\"] = bRickshawMan(dfCi)\n",
    "#     dfOhlc.loc[dtIndex, \"SPINNING_TOP_BLACK\"] = bSpinningTopBlack(dfCi)\n",
    "#     dfOhlc.loc[dtIndex, \"SPINNING_TOP_WHITE\"] = bSpinningTopWhite(dfCi)\n",
    "    \n",
    "    \n",
    "#     iLoc = iLoc + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1d024f33",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BARUBOZU_BLACK\n",
      "(0, 29)\n",
      "BARUBOZU_WHITE\n",
      "(0, 29)\n",
      "MARUBOZU_CLOSING_BLACK\n",
      "(3, 29)\n",
      "MARUBOZU_OPENING_WHITE\n",
      "(10, 29)\n",
      "DOJI_GRAVESTONE\n",
      "(0, 29)\n",
      "DOJI_DRAGONFLY\n",
      "(1, 29)\n",
      "MARUBOZU_OPENING_BLACK\n",
      "(20, 29)\n",
      "MARUBOZU_CLOSING_WHITE\n",
      "(4, 29)\n",
      "CANDLE_BLACK\n",
      "(1934, 29)\n",
      "CANDLE_SHORT_BLACK\n",
      "(1112, 29)\n",
      "CANDLE_WHITE\n",
      "(2024, 29)\n",
      "CANDLE_SHORT_WHITE\n",
      "(1216, 29)\n",
      "DOJI_LONG_LEGGED\n",
      "(0, 29)\n",
      "HIGH_WAVE\n",
      "(0, 29)\n",
      "RICKSHAW_MAN\n",
      "(0, 29)\n",
      "SPINNING_TOP_BLACK\n",
      "(1460, 29)\n",
      "SPINNING_TOP_WHITE\n",
      "(1448, 29)\n"
     ]
    }
   ],
   "source": [
    "for sColumn in dfOhlc.iloc[:, 12:].columns:\n",
    "    print(sColumn)\n",
    "    print(dfOhlc[dfOhlc[sColumn] == True].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44508f4",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "sSymbol = \"USDCAD\"\n",
    "aRelevantSymbols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7ce049",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRates = dfGetMarketData(sSymbol)\n",
    "\n",
    "for sRelevantSymbol in aRelevantSymbols:\n",
    "    dfRelevantRates = dfGetMarketData(sRelevantSymbol)\n",
    "    dfRates = dfRates.join(dfRelevantRates, how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d458f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInput  = dfRates.loc[:, dfRates.columns.get_level_values(1).isin(g_aInputFeatures)]\n",
    "dfInput = dfShiftTimeSteps(dfInput, g_aBackwardTimeSteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dabba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4e0cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "aColumns = pd.MultiIndex.from_tuples(\n",
    "    [(i,j, \"Regression\")],\n",
    "    names = [\"From\",\"To\", \"Model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdfa0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOutput = pd.DataFrame(index = dfRates.index, \n",
    "                        columns = aColumns)\n",
    "\n",
    "    \n",
    "dfSpread = dfRates[sSymbol][\"spread\"]\n",
    "dfOpen = dfRates[sSymbol][\"open\"].shift(-i)\n",
    "dfClose = dfRates[sSymbol][\"close\"].shift(-j)\n",
    "\n",
    "dfNetReturn = (abs(dfClose - dfOpen) - dfSpread)\n",
    "dfReturn = (dfClose - dfOpen)/dfOpen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4f67ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfIndexInvestable = dfNetReturn[dfNetReturn>0].index\n",
    "dfIndexNonInvestable = dfNetReturn[dfNetReturn<=0].index\n",
    "\n",
    "dfIndexUpward = dfReturn[dfReturn>0].index\n",
    "dfIndexDownward = dfReturn[dfReturn<=0].index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1127d583",
   "metadata": {},
   "source": [
    "# DEEP LEARNING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137167f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sModelName = os.path.join(sSymbol , \"__deep learning model__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c92e6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sSubModelName = os.path.join(sModelName , \"__\"+ str(i) +\"  \" + str(j) + \"__\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f452e4",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcafb344",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOutput.loc[:,(i,j,\"Regression\")] = dfClose.loc[dfOutput.index]\n",
    "\n",
    "# dfOutput.loc[dfIndexInvestable,(i,j,\"Investability\")] = 1\n",
    "# dfOutput.loc[dfIndexNonInvestable,(i,j,\"Investability\")] = 0\n",
    "\n",
    "# dfOutput.loc[dfIndexUpward,(i,j,\"Directional\")] = 1\n",
    "# dfOutput.loc[dfIndexDownward,(i,j,\"Directional\")] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7d3316",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOutput.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc694ea",
   "metadata": {},
   "source": [
    "### Remove Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264f5027",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged =pd.merge(dfInput, dfOutput, left_index=True, right_index=True)\n",
    "dfMerged.dropna(inplace = True)\n",
    "dfInput = dfMerged[dfInput.columns]\n",
    "dfOutput= dfMerged[dfOutput.columns]\n",
    "\n",
    "dfOutput = dfOutput.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68fffe3",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5275cac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInputTrain, dfInputValidation, dfInputTest, dfOutputTrain, dfOutputValidation, dfOutputTest = dfSplitData(dfInput, \n",
    "                                                                                                            dfOutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9a9ef2",
   "metadata": {},
   "source": [
    "### Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f3d4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfScaledInputTrain, dfScaledInputValidation, dfScaledInputTest = dfScaleData(\"input\", \n",
    "                                                                             dfInputTrain,\n",
    "                                                                             dfInputValidation, \n",
    "                                                                             dfInputTest)\n",
    "\n",
    "dfScaledOutputTrain, dfScaledOutputValidation, dfScaledOutputTest = dfScaleData(\"output\", \n",
    "                                                                                dfOutputTrain,\n",
    "                                                                                dfOutputValidation, \n",
    "                                                                                dfOutputTest,\n",
    "                                                                               False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52944fb0",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e253bd8c",
   "metadata": {},
   "source": [
    "### Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a484f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "iBatchSize = 32\n",
    "\n",
    "oLrSchedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    1e-05, decay_steps=100000, decay_rate=0.50, staircase=True\n",
    ")\n",
    "\n",
    "\n",
    "oOptimizer = tf.keras.optimizers.Adam(learning_rate=1e-05 , beta_1=0.9)\n",
    "\n",
    "oEarlyStop = EarlyStopping(\n",
    "    monitor = 'val_loss', \n",
    "    mode = 'min', \n",
    "    verbose = 0 , \n",
    "    patience = 20, \n",
    "    restore_best_weights = True)\n",
    "iEpochSize = 10000\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75b209e",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b360a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "oInputRates = keras.Input(\n",
    "    shape=(\n",
    "        dfScaledInputTrain.shape[1]), \n",
    "    name=\"aRates\")\n",
    "\n",
    "aW = Dense((100))(oInputRates)\n",
    "aOutputRegression = Dense((100))(aW)\n",
    "\n",
    "aOutputRegression = Dense(1, name = \"Regression\", activation = \"relu\")(aOutputRegression)\n",
    "\n",
    "oPredictiveModel = keras.Model(\n",
    "    inputs=oInputRates, \n",
    "    outputs=aOutputRegression\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaa9122",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac55b3b7",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43debeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "oPredictiveModel.compile(optimizer=oOptimizer,\n",
    "                         loss = tf.keras.losses.MeanSquaredError()\n",
    "#                          loss ={\n",
    "#                             \"Regression\": tf.keras.losses.MeanSquaredError(),\n",
    "#                         }\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedaa4fc",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1293c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "oPredictiveModel.fit(\n",
    "    dfScaledInputTrain, \n",
    "    dfScaledOutputTrain, \n",
    "    epochs=iEpochSize, \n",
    "    batch_size=iBatchSize, \n",
    "    verbose=1, \n",
    "    validation_data= (dfScaledInputValidation, dfScaledOutputValidation),\n",
    "    validation_batch_size= iBatchSize,\n",
    "    callbacks=[oEarlyStop]\n",
    ")\n",
    "\n",
    "oPredictiveModel.save_weights(sSubModelName)\n",
    "\n",
    "pd.DataFrame(oPredictiveModel.history.history).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75633cc0",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc56071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "oPredictiveModel.load_weights(sSubModelName)\n",
    "\n",
    "aPrediction = oPredictiveModel.predict(dfScaledInputTest)\n",
    "\n",
    "# dfPrediction.iloc[:,0] = aPrediction[0]\n",
    "# dfPrediction.loc[dfPrediction.iloc[:,0] <= 0.5] = 0\n",
    "# dfPrediction.loc[dfPrediction.iloc[:,0] > 0.5] = 1\n",
    "\n",
    "# dfPrediction.iloc[:,1] = aPrediction[1]\n",
    "# dfPrediction.loc[dfPrediction.iloc[:,1] <= 0.5] = 0\n",
    "# dfPrediction.loc[dfPrediction.iloc[:,1] > 0.5] = 1\n",
    "\n",
    "# dfPrediction.iloc[:,2] = aPrediction[2]\n",
    "\n",
    "sOutputScalerPath = os.path.join(sSubModelName , \"__scalers__\")\n",
    "sOutputScalerPath = os.path.join(sOutputScalerPath , \"output\" + \".sav\")\n",
    "oScalerOutput = pickle.load(open(sOutputScalerPath, 'rb'))\n",
    "aPrediction = oScalerOutput.inverse_transform(aPrediction)\n",
    "\n",
    "dfPrediction = pd.DataFrame(aPrediction, index = dfScaledOutputTest.index)\n",
    "dfPrediction.columns = aColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245d4b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTestComparision =pd.DataFrame(dfPrediction.iloc[:,0])\n",
    "dfTestComparision = dfTestComparision.join(dfOutputTest.iloc[:,0], how = \"inner\", lsuffix=\"prediction\")\n",
    "dfTestComparision.columns = [\"Prediction\", \"Actual\"]\n",
    "\n",
    "sns.scatterplot(data = dfTestComparision, x = \"Actual\", y =\"Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482be7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "iFrom = 90\n",
    "iTo = 100\n",
    "print(r2_score(dfOutputTest.iloc[iFrom:iTo, 0], dfPrediction.iloc[iFrom:iTo, 0]))\n",
    "sns.lineplot(data = dfTestComparision.iloc[iFrom:iTo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f2409",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dfPrediction.iloc[:, 0]\n",
    "y_true = dfOutputTest.iloc[:, 0]\n",
    "aMetrics = [\n",
    "        ('mean absolute error', mean_absolute_error(y_true, y_pred)),\n",
    "        ('median absolute error', median_absolute_error(y_true, y_pred)),\n",
    "        ('mean squared error', mean_squared_error(y_true, y_pred)),\n",
    "        ('max error', max_error(y_true, y_pred)),\n",
    "        ('r2 score', r2_score(y_true, y_pred)),\n",
    "        ('explained variance score', explained_variance_score(y_true, y_pred))\n",
    "    ]\n",
    "\n",
    "print('Metrics for regression:')\n",
    "for metric_name, metric_value in aMetrics:\n",
    "    print(f'{metric_name:>25s}: {metric_value: >20.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653d9142",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dfPrediction.iloc[:, 1]\n",
    "y_true = dfOutputTest.iloc[:, 1]\n",
    "print(classification_report(y_true, y_pred, zero_division = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a951e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dfPrediction.iloc[:, 0]\n",
    "y_true = dfOutputTest.iloc[:, 0]\n",
    "print(classification_report(y_true, y_pred, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ca3ab0",
   "metadata": {},
   "source": [
    "# REFERENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49501761",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/keras/train_and_evaluate#passing_data_to_multi-input_multi-output_models\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch/\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit/\n",
    "\n",
    "https://towardsdatascience.com/customize-loss-function-to-make-lstm-model-more-applicable-in-stock-price-prediction-b1c50e50b16c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
