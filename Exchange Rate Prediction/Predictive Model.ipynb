{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d78e1f-e08c-4ea4-9448-81f915546cd2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0611acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54d4875-8ad8-478e-b63a-313ed6fdb418",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17fa2c83-a168-4d7f-8c30-3e0767d7a8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sOutputSymbol = 'ETHUSD'\n",
    "sModelType = 'MLP'\n",
    "sDesignType = 'Full Factorial Design'\n",
    "\n",
    "iTrialId = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "833806a3-92de-48a3-ab67-70b905d98db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sFolderPath = 'Data/'+ sOutputSymbol +'//'+ sModelType + '//'+ sDesignType+ '//'\n",
    "dfDesign = pd.read_csv( sFolderPath + 'Design.csv', index_col = 'Run ID')\n",
    "iBatchSize = dfDesign.loc[iTrialId, 'Batch Size']\n",
    "iNrOfHiddenNeurons = dfDesign.loc[iTrialId, 'Number of Hidden Neurons']\n",
    "iBackwardTimeWindow = 3\n",
    "iForwardTimeWindow = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "137167f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sModelName = os.path.join(sFolderPath + str(iTrialId))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d915683",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa23be1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cryptocurrency List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ac336b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BTCUSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ETHUSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCHUSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LTCUSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RPLUSD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Symbol\n",
       "0  BTCUSD\n",
       "1  ETHUSD\n",
       "2  BCHUSD\n",
       "3  LTCUSD\n",
       "4  RPLUSD"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCrpytocurrencies = pd.read_csv('Data\\cryptocurrencies.csv')\n",
    "dfCrpytocurrencies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369ae0af",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "889e4365",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOhlc = pd.read_csv('Data\\dfOhlc.csv')\n",
    "dfOhlc['timestamp'] = pd.DatetimeIndex(dfOhlc['timestamp'])\n",
    "dfOhlc.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34801cd6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa542c9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70088c21",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "fTrainingRatio = 0.7\n",
    "fValidationRatio = 0.15\n",
    "fTestRatio = 0.15\n",
    "\n",
    "ixTrain, ixTest = train_test_split(\n",
    "    dfOhlc.index,\n",
    "    test_size=1-fTrainingRatio,\n",
    "    shuffle=False)\n",
    "\n",
    "ixValidation, ixTest = train_test_split(\n",
    "    ixTest,\n",
    "    test_size=fTestRatio/(fTestRatio + fValidationRatio),\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e73e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32c7b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfScaledOhlc = pd.DataFrame(index = dfOhlc.index, columns  = dfOhlc.columns)\n",
    "\n",
    "for sColumn in dfOhlc.columns:\n",
    "    oScaler = StandardScaler()\n",
    "    \n",
    "    dfTrain = pd.DataFrame(dfOhlc.loc[ixTrain, sColumn])\n",
    "    dfValidation = pd.DataFrame(dfOhlc.loc[ixValidation, sColumn])\n",
    "    dfTest = pd.DataFrame(dfOhlc.loc[ixTest, sColumn])\n",
    "    \n",
    "    oScaler.fit(dfTrain.append(dfValidation))\n",
    "    \n",
    "    dfScaledOhlc.loc[ixTrain, sColumn] = np.reshape(oScaler.transform(dfTrain), (-1))\n",
    "    dfScaledOhlc.loc[ixValidation, sColumn] = np.reshape(oScaler.transform(dfValidation), (-1))\n",
    "    dfScaledOhlc.loc[ixTest, sColumn] = np.reshape(oScaler.transform(dfTest), (-1))\n",
    "\n",
    "    sScalerFilePath = os.path.join(sModelName , \"__scalers__\")\n",
    "    sScalerFilePath = os.path.join(sScalerFilePath , sColumn + \".sav\")\n",
    "    os.makedirs(os.path.dirname(sScalerFilePath), exist_ok=True)\n",
    "    \n",
    "    pickle.dump(oScaler, open(sScalerFilePath, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec96ca9f-f07a-4e1b-bc3c-aa34164c1d24",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Input Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1449fbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aInputSymbols = dfCrpytocurrencies['Symbol'].values\n",
    "aInputFeatures = ['weekday', 'hour', 'minute' ,'upper_shadow', 'lower_shadow' ,'return']\n",
    "aInputFeatures = list(map(\":\".join, itertools.product(aInputSymbols, aInputFeatures)))\n",
    "\n",
    "iNrInputFeatures = len(aInputFeatures)\n",
    "\n",
    "aBackwardTimeSteps = range(-iBackwardTimeWindow, 0)\n",
    "\n",
    "aTplInputColumns = list(itertools.product(aBackwardTimeSteps, aInputFeatures))\n",
    "aIxInputColumns = pd.MultiIndex.from_tuples(aTplInputColumns, names= ['time_step', 'feature'])\n",
    "\n",
    "dfInput = pd.DataFrame(columns = aIxInputColumns)\n",
    "\n",
    "for tplColumn in list(dfInput.columns):\n",
    "    dfInput.loc[:, tplColumn] = dfScaledOhlc[(tplColumn[1])].shift(-tplColumn[0])\n",
    "\n",
    "    \n",
    "ixNas = dfInput[dfInput.isna().any(axis=1)].index\n",
    "dfInput.drop(ixNas, inplace = True, errors = 'ignore') \n",
    "ixTrain= ixTrain.drop(ixNas, errors = 'ignore') \n",
    "ixValidation= ixValidation.drop(ixNas,   errors = 'ignore') \n",
    "ixTest = ixTest.drop(ixNas,   errors = 'ignore') \n",
    "\n",
    "dfInput.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8011a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Create Output Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce152a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "aOutputFeatures = ['return']\n",
    "aOutputFeatures = list(map(\":\".join, itertools.product([sOutputSymbol], aOutputFeatures)))\n",
    "iNrOutputFeatures = len(aOutputFeatures)\n",
    "\n",
    "aForwardTimeSteps = range(0, iForwardTimeWindow)\n",
    "\n",
    "\n",
    "aTplOutputColumns = list(itertools.product(aForwardTimeSteps, aOutputFeatures))\n",
    "aIxOutputColumns = pd.MultiIndex.from_tuples(aTplOutputColumns, names= ['time_step', 'feature'])\n",
    "\n",
    "dfOutput = pd.DataFrame(columns = aIxOutputColumns)\n",
    "\n",
    "for tplColumn in list(dfOutput.columns):\n",
    "    dfOutput.loc[:, tplColumn] =  dfOhlc[(tplColumn[1])].shift(-tplColumn[0])\n",
    "\n",
    "ixNas = dfOutput[dfOutput.isna().any(axis=1)].index\n",
    "dfOutput.drop(ixNas, inplace = True, errors = 'ignore') \n",
    "ixTrain= ixTrain.drop(ixNas, errors = 'ignore') \n",
    "ixValidation= ixValidation.drop(ixNas,   errors = 'ignore') \n",
    "ixTest = ixTest.drop(ixNas,   errors = 'ignore') \n",
    "dfOutput.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802a6d3a-353a-45c3-a8eb-f49af789c4a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Reshape Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296eec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "axMerged = dfInput.index.join(dfOutput.index, how = 'inner')\n",
    "\n",
    "dfInput = dfInput.loc[axMerged]\n",
    "dfOutput = dfOutput.loc[axMerged]\n",
    "\n",
    "ixTrain = ixTrain.join(axMerged, how = \"inner\")\n",
    "ixValidation = ixValidation.join(axMerged, how = \"inner\")\n",
    "ixTest = ixTest.join(axMerged, how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e399d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInputTrain = dfInput.loc[ixTrain]\n",
    "aInputTrain = np.reshape(dfInputTrain.values, (dfInputTrain.shape[0], iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "dfInputValidation = dfInput.loc[ixValidation]\n",
    "aInputValidation = np.reshape(dfInputValidation.values, (dfInputValidation.shape[0], iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "dfInputTest = dfInput.loc[ixTest]\n",
    "aInputTest = np.reshape(dfInputTest.values, (dfInputTest.shape[0], iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "dfOutputTrain = dfOutput.loc[ixTrain]\n",
    "aOutputTrain = np.reshape(dfOutputTrain.values, (dfOutputTrain.shape[0], iForwardTimeWindow, iNrOutputFeatures))\n",
    "\n",
    "dfOutputValidation = dfOutput.loc[ixValidation]\n",
    "aOutputValidation = np.reshape(dfOutputValidation.values, (dfOutputValidation.shape[0], iForwardTimeWindow, iNrOutputFeatures))\n",
    "\n",
    "dfOutputTest = dfOutput.loc[ixTest]\n",
    "aOutputTest = np.reshape(dfOutputTest.values, (dfOutputTest.shape[0], iForwardTimeWindow, iNrOutputFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ce37ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "aInputTrain = np.asarray(aInputTrain, np.float32)\n",
    "aInputValidation = np.asarray(aInputValidation, np.float32)\n",
    "aInputTest = np.asarray(aInputTest, np.float32)\n",
    "aOutputTrain = np.asarray(aOutputTrain, np.float32)\n",
    "aOutputValidation = np.asarray(aOutputValidation, np.float32)\n",
    "aOutputTest = np.asarray(aOutputTest, np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52944fb0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#  MODEL DEVELOPMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e253bd8c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Set Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a484f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_c_Seed = 1\n",
    "oInitilizer = tf.keras.initializers.GlorotUniform(seed = i_c_Seed)\n",
    "\n",
    "\n",
    "\n",
    "oEarlyStop = EarlyStopping(\n",
    "    monitor = 'val_loss', \n",
    "    mode = 'min', \n",
    "    verbose = 0 , \n",
    "    patience = 20, \n",
    "    restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27edd3cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Define Custom Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac51d89-3f8e-4c93-aac7-463a9f016e7e",
   "metadata": {},
   "source": [
    "While loss function is defined following criteria is taken into consideration:\n",
    "1. Opposite signs should be penalized.\n",
    "1. Opposite sings will be worse when the magnitute of error increases.\n",
    "1. Any of same sign is better than any of the opposite signs.\n",
    "1. Same sign is the best when the error is 0.\n",
    "\n",
    "Following logic also should have been implemented but it was unsuccessful to implement due to forcing negative errors. It will be used as 'metric' function.\n",
    "1. Same sign is positive error is better than negative error (err = act - pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a023db-aaa6-4236-b7d7-e508b17b38c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fCalculateLoss(aActual, aPrediction):\n",
    "    aLossDueToError = tf.math.subtract(aActual ,aPrediction)\n",
    "    aLossDueToError = tf.math.abs(aLossDueToError)\n",
    "    \n",
    "    fPenalty = tf.math.reduce_max(aLossDueToError)\n",
    "    \n",
    "    aLossDueToSignDiff = tf.math.abs(tf.math.subtract(tf.math.sign(aActual), tf.math.sign(aPrediction)) )\n",
    "    aLossDueToSignDiff = tf.where(aLossDueToSignDiff == 0, aLossDueToSignDiff, fPenalty)\n",
    "    \n",
    "    aTotalLoss = aLossDueToError + aLossDueToSignDiff\n",
    "        \n",
    "    return tf.math.reduce_mean(aTotalLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75b209e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a48d744-a348-4435-b0c7-88054f26e20e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa552d5-8eb4-4008-b068-b6d5683a8fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sModelType == 'MLP':\n",
    "    aInputMlp = keras.Input(\n",
    "        shape=(iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "    aW = keras.layers.Flatten()(aInputMlp)\n",
    "    aW = keras.layers.Dense(iNrOfHiddenNeurons, kernel_initializer = oInitilizer)(aW)\n",
    "    aW = keras.layers.Dense(iForwardTimeWindow*iNrOutputFeatures, kernel_initializer = oInitilizer)(aW)\n",
    "    aW = keras.layers.Reshape((iForwardTimeWindow, iNrOutputFeatures))(aW)\n",
    "\n",
    "    aOutputMlp = aW\n",
    "    oModelMlp = keras.Model(\n",
    "        inputs=aInputMlp,\n",
    "        outputs=aOutputMlp\n",
    "    )\n",
    "\n",
    "    oOptimizerMlp = tf.keras.optimizers.Adam(learning_rate=1e-04)\n",
    "    oModelMlp.compile(optimizer=oOptimizerMlp,\n",
    "                             loss = fCalculateLoss\n",
    "                            )\n",
    "\n",
    "    oPredictiveModel = oModelMlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66367dfb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e48a9a2-527b-4226-98d8-39d7d4a79c8e",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "if sModelType == 'LSTM':\n",
    "    aInputDeepLstm = keras.Input(\n",
    "        shape=(iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "    aW = keras.layers.LSTM(64, return_sequences = True)(aInputDeepLstm)\n",
    "    aW = keras.layers.Flatten()(aW)\n",
    "    aW = keras.layers.Dense(iForwardTimeWindow*iNrOutputFeatures)(aW)\n",
    "    aW = keras.layers.Reshape((iForwardTimeWindow, iNrOutputFeatures))(aW)\n",
    "\n",
    "    aOutputDeepLstm = aW\n",
    "    oModelDeepLstm = keras.Model(\n",
    "        inputs=aInputDeepLstm,\n",
    "        outputs=aOutputDeepLstm\n",
    "    )\n",
    "\n",
    "    oOptimizerDeepLstm = tf.keras.optimizers.Adam(learning_rate=1e-04)\n",
    "    oModelDeepLstm.compile(optimizer=oOptimizerDeepLstm,\n",
    "                             loss = fCalculateLoss\n",
    "                            )\n",
    "\n",
    "    oPredictiveModel = oModelDeepLstm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11b935e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Convolutional Encoder-Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf77ce35-7d29-43c1-990e-a80a0fef20fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sModelType == 'Convolutional Encoder Decoder':\n",
    "    aInputs = keras.Input(\n",
    "        shape=(iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "    aEncoderHiddens, aFinalH, aFinalC = keras.layers.LSTM(iNrOfHiddenNeurons,\n",
    "                                             return_state = True, \n",
    "                                             return_sequences = True\n",
    "                                            )(aInputs)\n",
    "    aFinalH = keras.layers.BatchNormalization()(aFinalH)\n",
    "    aFinalC = keras.layers.BatchNormalization()(aFinalC)\n",
    "\n",
    "    aFeatureMap = keras.layers.Conv1D(64, 2)(aEncoderHiddens)\n",
    "    aFeatureMap = keras.layers.MaxPooling1D(2)(aFeatureMap)\n",
    "    aFlatted = keras.layers.Flatten()(aFeatureMap)\n",
    "\n",
    "    aDecoderInputs = keras.layers.RepeatVector(iForwardTimeWindow)(aFlatted)\n",
    "\n",
    "    aDecoderHiddens = keras.layers.LSTM(iNrOfHiddenNeurons, \n",
    "                           return_state = False, \n",
    "                           return_sequences = True\n",
    "                          )(aDecoderInputs, initial_state=[aFinalH, aFinalC])\n",
    "\n",
    "\n",
    "    aOutputs = keras.layers.TimeDistributed(\n",
    "        Dense(iNrOutputFeatures)\n",
    "    )(aDecoderHiddens)\n",
    "\n",
    "    oPredictiveModel = keras.Model(\n",
    "        inputs=aInputs,\n",
    "        outputs=aOutputs\n",
    "    )\n",
    "\n",
    "    oOptimizer = tf.keras.optimizers.Adam(learning_rate=1e-05)\n",
    "    oPredictiveModel.compile(loss = fCalculateLoss,\n",
    "                             optimizer=oOptimizer\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1ed1a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Luong's Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b49d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sModelType == 'Luongs Attention':\n",
    "    aEncoderInputs = keras.Input(\n",
    "        shape=(iBackwardTimeWindow, iNrInputFeatures))\n",
    "\n",
    "    aEncoderHiddens, aFinalH, aFinalC = keras.layers.LSTM(iNrOfHiddenNeurons,\n",
    "                                             return_state = True, \n",
    "                                             return_sequences = True\n",
    "                                            )(aEncoderInputs)\n",
    "    aFinalH = keras.layers.BatchNormalization()(aFinalH)\n",
    "    aFinalC = keras.layers.BatchNormalization()(aFinalC)\n",
    "\n",
    "    aDecoderInputs = keras.layers.RepeatVector(iForwardTimeWindow)(aFinalH)\n",
    "\n",
    "    aDecoderHiddens = keras.layers.LSTM(iNrOfHiddenNeurons, \n",
    "                           return_state = False, \n",
    "                           return_sequences = True\n",
    "                          )(aDecoderInputs, initial_state=[aFinalH, aFinalC])\n",
    "\n",
    "    aAttentions = keras.layers.dot([aDecoderHiddens, aEncoderHiddens], axes=[2, 2])\n",
    "    aAttentions = keras.layers.Activation('softmax')(aAttentions)\n",
    "\n",
    "    aContextVector = keras.layers.dot([aAttentions, aEncoderHiddens], axes=[2,1])\n",
    "    aContextVector = keras.layers.BatchNormalization()(aContextVector)\n",
    "    aContextVector = keras.layers.concatenate([aContextVector, aDecoderHiddens])\n",
    "\n",
    "    aDecoderOutputs = keras.layers.TimeDistributed(\n",
    "        keras.layers.Dense(iNrOutputFeatures)\n",
    "    )(aContextVector)\n",
    "\n",
    "    oPredictiveModel = keras.Model(\n",
    "        inputs=aEncoderInputs,\n",
    "        outputs=aDecoderOutputs\n",
    "    )\n",
    "\n",
    "    oOptimizer = tf.keras.optimizers.Adam(learning_rate=1e-05)\n",
    "    oPredictiveModel.compile(loss = fCalculateLoss, \n",
    "                             optimizer=oOptimizer\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec09d00-d453-413e-82b0-d9e2f777f7ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Plot Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97529958-2133-4445-bd8b-9455843cc0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(oPredictiveModel,  show_shapes=True+'\\Model architecture.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedaa4fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3871f87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "iEpochSize = 10000\n",
    "dtStartTime = time.time()\n",
    "oPredictiveModel.fit(\n",
    "    aInputTrain, \n",
    "    aOutputTrain, \n",
    "    epochs=iEpochSize, \n",
    "    batch_size=iBatchSize, \n",
    "    verbose=0, \n",
    "    validation_data= (aInputValidation, aOutputValidation),\n",
    "    validation_batch_size= iBatchSize\n",
    "    ,callbacks=[oEarlyStop]\n",
    ")\n",
    "dtEndTime = time.time()\n",
    "dtTrainingDuration = dtEndTime -dtStartTime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857470db-83a8-4c90-ac73-bb6300ef196a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Save Epoch History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141bb9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "dfHistory = pd.DataFrame(oPredictiveModel.history.history)\n",
    "oFig = sns.lineplot(data = dfHistory)\n",
    "oFig.get_figure().savefig(sModelName + '\\epochs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef8cfb6-6cf1-4545-84b6-f7a881da74d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHistory.to_csv(sModelName + '\\dfHistory.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680ac53a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f88fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "oPredictiveModel.save_weights(sModelName+'\\model weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75633cc0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d372e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "oPredictiveModel.load_weights(sModelName+'\\model weights')\n",
    "\n",
    "aPrediction = oPredictiveModel.predict(aInputTest)\n",
    "aPrediction = aPrediction.reshape((-1, iForwardTimeWindow * iNrOutputFeatures))\n",
    "dfPrediction = pd.DataFrame(data = aPrediction, index = ixTest, columns = aIxOutputColumns)\n",
    "\n",
    "aActual = aOutputTest.reshape((-1, iForwardTimeWindow * iNrOutputFeatures))\n",
    "dfActual =  pd.DataFrame(data = aActual, index = ixTest, columns = aIxOutputColumns).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd31b058-6e14-4012-b227-97cf02dc0099",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dfeae2-ea8d-4b16-aae1-a854d1b70708",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfActual.to_csv(sModelName + '\\dfActual.csv')\n",
    "dfPrediction.to_csv(sModelName + '\\dfPrediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d71eb51-1037-4b8e-9d10-f648c0a0a7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPerformance = pd.DataFrame(data = [dtTrainingDuration], columns = ['value'], index = ['training duration'] )\n",
    "dfPerformance.to_csv(sModelName + '\\dfPerformance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ca3ab0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# REFERENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49501761",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/keras/train_and_evaluate#passing_data_to_multi-input_multi-output_models\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch/\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit/\n",
    "\n",
    "https://towardsdatascience.com/customize-loss-function-to-make-lstm-model-more-applicable-in-stock-price-prediction-b1c50e50b16c\n",
    "\n",
    "https://keras.io/getting_started/faq/\n",
    "\n",
    "https://machinelearningmastery.com/how-to-develop-lstm-models-for-multi-step-time-series-forecasting-of-household-power-consumption/\n",
    "\n",
    "https://www.tensorflow.org/tutorials/structured_data/time_series\n",
    "\n",
    "https://towardsdatascience.com/encoder-decoder-model-for-multistep-time-series-forecasting-using-pytorch-5d54c6af6e60\n",
    "\n",
    "https://levelup.gitconnected.com/building-seq2seq-lstm-with-luong-attention-in-keras-for-time-series-forecasting-1ee00958decb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
