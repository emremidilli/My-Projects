{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5ab04b1-7487-40a9-a791-e1459379234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow as tf\n",
    "\n",
    "import CONSTANTS as c\n",
    "FEATURE_ENGINEERED_DATA_PATH = c.FEATURE_ENGINEERED_DATA_PATH\n",
    "RANDOM_STATE = c.RANDOM_STATE\n",
    "\n",
    "\n",
    "########################################### DATA COLLECTION ###########################################\n",
    "i = 0\n",
    "for oFile in os.walk(FEATURE_ENGINEERED_DATA_PATH):\n",
    "    sFolderPath = oFile[0]\n",
    "    if sFolderPath != FEATURE_ENGINEERED_DATA_PATH:\n",
    "        aX = np.load(r'{}\\X.npy'.format(sFolderPath))\n",
    "        aX_time = np.load(r'{}\\X_TIME.npy'.format(sFolderPath))\n",
    "        aY = np.load(r'{}\\Y.npy'.format(sFolderPath))\n",
    "        if i == 0:\n",
    "            X = aX\n",
    "            Y= aY\n",
    "            X_TIME = aX_time\n",
    "        else:\n",
    "            X = np.concatenate([X, aX])\n",
    "            X_TIME = np.concatenate([X_TIME, aX_time])\n",
    "            Y = np.concatenate([Y, aY])\n",
    "            \n",
    "        i = i + 1\n",
    "        \n",
    "\n",
    "Y = Y[:,0,:,0]\n",
    "\n",
    "Y = Y[:, int(Y.shape[1]/2):]\n",
    "\n",
    "\n",
    "########################################### ANALYSIS ###########################################\n",
    "class Time2Vec(Layer):\n",
    "    def __init__(self, kernel_size):\n",
    "        '''\n",
    "        :param kernel_size:         The length of time vector representation.\n",
    "        :param periodic_activation: The periodic activation, sine or cosine, or any future function.\n",
    "        '''\n",
    "        super(Time2Vec, self).__init__(\n",
    "            trainable=True,\n",
    "            name='Time2VecLayer_SIN'\n",
    "        )\n",
    "        \n",
    "        self.k = kernel_size\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # While i = 0\n",
    "        self.wb = self.add_weight(\n",
    "            shape=(1, 1),\n",
    "            initializer='uniform',\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "        self.bb = self.add_weight(\n",
    "            shape=(1, 1),\n",
    "            initializer='uniform',\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "        # Else needs to pass the periodic activation\n",
    "        self.wa = self.add_weight(\n",
    "            shape=(1, self.k),\n",
    "            initializer='uniform',\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "        self.ba = self.add_weight(\n",
    "            shape=(1, self.k),\n",
    "            initializer='uniform',\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "        super(Time2Vec, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs, **kwargs):\n",
    "        '''\n",
    "        :param inputs: A Tensor with shape (batch_size, feature_size, 1)\n",
    "        :param kwargs:\n",
    "        :return: A Tensor with shape (batch_size, feature_size, length of time vector representation + 1)\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        bias = self.wb * inputs + self.bb\n",
    "        wgts = K.sin(K.dot(inputs, self.wa) + self.ba)\n",
    "        \n",
    "        return K.concatenate([bias, wgts], -1)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1], self.k + 1)\n",
    "\n",
    "    \n",
    "\n",
    "def transformer_encoder(inputs):\n",
    "    # Normalization and Attention\n",
    "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = tf.keras.layers.MultiHeadAttention(key_dim=128, num_heads=4, dropout=0.1)(x, x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = tf.keras.layers.Conv1D(filters=1, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    x = tf.keras.layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return res\n",
    "\n",
    "\n",
    "# Build model\n",
    "TermInput = tf.keras.Input(\n",
    "    shape=(X.shape[1], X.shape[2])\n",
    ")\n",
    "\n",
    "TimeInput = tf.keras.Input(\n",
    "    shape=(X_TIME.shape[1]))\n",
    "\n",
    "W = TermInput\n",
    "W = tf.keras.layers.Flatten()(W)\n",
    "\n",
    "\n",
    "W2= tf.expand_dims(TimeInput, -1)\n",
    "\n",
    "W2 = Time2Vec(2)(W2)\n",
    "W2 = tf.keras.layers.Flatten()(W2)\n",
    "\n",
    "\n",
    "W = tf.keras.layers.concatenate([W, W2], -1)\n",
    "\n",
    "# for _ in range(2):\n",
    "#     W = transformer_encoder(W)\n",
    "    \n",
    "# W = tf.keras.layers.GlobalAveragePooling1D(data_format=\"channels_first\")(W)\n",
    "\n",
    "for _ in range(2):\n",
    "    W = tf.keras.layers.Dense(528)(W)\n",
    "    W = tf.keras.layers.ReLU()(W)\n",
    "    W = tf.keras.layers.Dropout(0.1)(W)\n",
    "\n",
    "\n",
    "W = tf.keras.layers.Dense(Y.shape[1], activation = 'sigmoid')(W)\n",
    "\n",
    "ModelOutput = W\n",
    "oModel = tf.keras.Model([TermInput, TimeInput], ModelOutput, name = 'TRANSFORMER_MODEL')\n",
    "\n",
    "\n",
    "oLrSchedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=10**2,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "\n",
    "oOptimizer = tf.keras.optimizers.Adam(learning_rate=oLrSchedule)\n",
    "oModel.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "    metrics = tf.keras.metrics.AUC(),\n",
    "    optimizer=oOptimizer\n",
    ")\n",
    "\n",
    "tf.keras.utils.plot_model(oModel, show_shapes=True)    \n",
    "\n",
    "# Fit model\n",
    "oModel.fit(\n",
    "    (X, X_TIME), \n",
    "    Y, \n",
    "    epochs= 10**3, \n",
    "    batch_size=2**15, \n",
    "    verbose=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
