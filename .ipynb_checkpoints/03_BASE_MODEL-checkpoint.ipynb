{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae6ae86a-8a61-40b1-9bfe-847f7a256879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Models\\Data_Augmentaiton\\Base_Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Models\\Data_Augmentaiton\\Base_Model\\assets\n"
     ]
    }
   ],
   "source": [
    "import CONSTANTS as c\n",
    "import tensorflow as tf\n",
    "\n",
    "FFT_AC_COEFFICIENT = c.FFT_AC_COEFFICIENT\n",
    "BACKWARD_WINDOW_LENGTH = c.BACKWARD_WINDOW_LENGTH\n",
    "NR_OF_BINS = c.NR_OF_BINS\n",
    "DATA_AUGMENTATION_BASE_MODEL_PATH = c.DATA_AUGMENTATION_BASE_MODEL_PATH\n",
    "\n",
    "TermInput = tf.keras.Input(\n",
    "    shape=(BACKWARD_WINDOW_LENGTH,FFT_AC_COEFFICIENT)\n",
    ")\n",
    "\n",
    "W = TermInput\n",
    "\n",
    "W = tf.keras.layers.Flatten()(W)\n",
    "for _ in range(2):\n",
    "    W = tf.keras.layers.Dense(256)(W)\n",
    "    W = tf.keras.layers.ReLU()(W)\n",
    "    W = tf.keras.layers.Dropout(0.1)(W)\n",
    "\n",
    "W = tf.keras.layers.Dense(NR_OF_BINS/2, activation = 'sigmoid')(W)\n",
    "\n",
    "ModelOutput = W\n",
    "oModel = tf.keras.Model(TermInput, ModelOutput, name = 'BASE_MODEL')\n",
    "\n",
    "\n",
    "oOptimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "oModel.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "    metrics = tf.keras.metrics.AUC(),\n",
    "    optimizer=oOptimizer\n",
    ")\n",
    "\n",
    "\n",
    "tf.keras.utils.plot_model(oModel, show_shapes=True, to_file = r'{}\\model.png'.format(DATA_AUGMENTATION_BASE_MODEL_PATH))\n",
    "\n",
    "oModel.save(DATA_AUGMENTATION_BASE_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0980df7-f6e3-49c7-a079-6af8d6c6b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.MultiHeadAttention(num_heads=2, key_dim=2)\n",
    "target = tf.keras.Input(shape=[8, 16])\n",
    "source = tf.keras.Input(shape=[4, 16])\n",
    "output_tensor, weights = layer(target, source,return_attention_scores=True)\n",
    "print(output_tensor.shape)\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f96be37-10a0-48b2-91a3-03b58372c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class Time2Vec(Layer):\n",
    "    def __init__(self, kernel_size, periodic_activation='sin'):\n",
    "        '''\n",
    "        :param kernel_size:         The length of time vector representation.\n",
    "        :param periodic_activation: The periodic activation, sine or cosine, or any future function.\n",
    "        '''\n",
    "        super(Time2Vec, self).__init__(\n",
    "            trainable=True,\n",
    "            name='Time2VecLayer_'+periodic_activation.upper()\n",
    "        )\n",
    "        \n",
    "        self.k = kernel_size\n",
    "        self.p_activation = periodic_activation\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # While i = 0\n",
    "        self.wb = self.add_weight(\n",
    "            shape=(1, 1),\n",
    "            initializer='uniform',\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "        self.bb = self.add_weight(\n",
    "            shape=(1, 1),\n",
    "            initializer='uniform',\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "        # Else needs to pass the periodic activation\n",
    "        self.wa = self.add_weight(\n",
    "            shape=(1, self.k),\n",
    "            initializer='uniform',\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "        self.ba = self.add_weight(\n",
    "            shape=(1, self.k),\n",
    "            initializer='uniform',\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "        super(Time2Vec, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs, **kwargs):\n",
    "        '''\n",
    "        :param inputs: A Tensor with shape (batch_size, feature_size, 1)\n",
    "        :param kwargs:\n",
    "        :return: A Tensor with shape (batch_size, feature_size, length of time vector representation + 1)\n",
    "        '''\n",
    "        bias = self.wb * inputs + self.bb\n",
    "        if self.p_activation.startswith('sin') :\n",
    "            wgts = K.sin(K.dot(inputs, self.wa) + self.ba)\n",
    "        elif self.p_activation.startswith('cos') :\n",
    "            wgts = K.cos(K.dot(inputs, self.wa) + self.ba)\n",
    "        else:\n",
    "            raise NotImplementedError('Neither sine or cosine periodic activation be selected.')\n",
    "        return K.concatenate([bias, wgts], -1)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1], self.k + 1)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
