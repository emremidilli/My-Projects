{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "148aa612",
   "metadata": {},
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4de5840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362b10a9",
   "metadata": {},
   "source": [
    "# READING DATA FROM SOURCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf01f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCustomers = pd.read_csv(\"customers.csv\", delimiter = \",\")\n",
    "dfCustomers.set_index(\"CLIENT_ID\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f9c5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCustomers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9237de2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfTransactions = pd.read_csv(\"transactions.csv\", delimiter = \",\")\n",
    "dfTransactions.set_index(\"TRANS_ID\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8558e61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af5ad44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDistricts =  pd.read_csv(\"districts.csv\", delimiter = \",\")\n",
    "dfDistricts.set_index(\"DISTRICT_ID\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0972b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDistricts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e096ce",
   "metadata": {},
   "source": [
    "# DATA EXPLORATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239c7463",
   "metadata": {},
   "source": [
    "## Exploring Uniqueness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f4c57c",
   "metadata": {},
   "source": [
    "### dfCustomers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd6ffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfCustomers.index.unique()) == len(dfCustomers.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d597db",
   "metadata": {},
   "source": [
    "### dfDistricts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb00a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfDistricts.index.unique()) == len(dfDistricts.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cb82ae",
   "metadata": {},
   "source": [
    "### dfTransactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d839ea",
   "metadata": {},
   "source": [
    "dfTransactions contain some duplicated TRANS_IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e7ed40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(dfTransactions.index.unique()) == len(dfTransactions.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acf6100",
   "metadata": {},
   "source": [
    "There are 20000 rows which are duplicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49b103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransactions[dfTransactions.index.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b875e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransactions.loc[3457056]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebd17dd",
   "metadata": {},
   "source": [
    "## Exploring Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9c8332",
   "metadata": {},
   "source": [
    "### dfCustomers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaee04ac",
   "metadata": {},
   "source": [
    "\"LOAN\" field should be either 1 or 0 by description. Usually such fields have integer data types. However, it looks as float64, it s a sign that this field can include some unexpected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33c7d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCustomers.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e66616",
   "metadata": {},
   "source": [
    "Confirming that each client has only 1 account id in dfCustomers dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214edc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfCustomers.index.unique()) == len(dfCustomers[\"ACCOUNT_ID\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bd49ce",
   "metadata": {},
   "source": [
    "### dfDistricts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d92fa19",
   "metadata": {},
   "source": [
    "\"UNEMP_95\" and \"CRIME_95\" fields look as object data type. By description of field, \"UNEMP_95\" should represent unemployment ratio which is float, however it looks as object. Similarly, \"CRIME_95\" field represents number of committed crimes which should be in integer type. However, it also looks as object. These are signs that, the fields of \"UNEMP_95\" and \"CRIME_95\" contain some unexpected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca9e684",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfDistricts.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da9187c",
   "metadata": {},
   "source": [
    "### dfTransactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007ec621",
   "metadata": {},
   "source": [
    "\"ACCOUNT_ID\" field's data type should be integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08e312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransactions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e166513",
   "metadata": {},
   "source": [
    "## Exploring Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa14ef67",
   "metadata": {},
   "source": [
    "### dfCustomers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197a8c1d",
   "metadata": {},
   "source": [
    "Only field 'LOAN' includes NaN values in dfCustomers dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35401b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCustomers.columns[dfCustomers.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa2a67f",
   "metadata": {},
   "source": [
    "Checking unique fields to be sure if any other missing values except NaN. Unique values are sorted to detect missing values on the boundaries of the sorted array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5b547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dfCustomers.index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9c281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dfCustomers[\"ACCOUNT_ID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a46700",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dfCustomers[\"GENDER\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0167a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dfCustomers[\"BIRTH_DT\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6828e9",
   "metadata": {},
   "source": [
    "Confirming that each date value includes 8 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5bfdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCustomers[\"BIRTH_DT\"].astype(str).str.len().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb88eadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dfCustomers[\"ACTIVE\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca93dfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dfCustomers[\"LOAN\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d371c273",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dfCustomers[\"DISTRICT_ID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79e03ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dfCustomers[\"SET_SPLIT\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefd76a3",
   "metadata": {},
   "source": [
    "### dfDistricts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62da4eef",
   "metadata": {},
   "source": [
    "Looks like there is no field that contains NaN value in dfDistricts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7385c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDistricts.columns[dfDistricts.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbde6c6e",
   "metadata": {},
   "source": [
    "Checking unique fields to be sure if any other missing values except NaN. Unique values are sorted to detect missing values on the boundaries of the sorted array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f637ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dfDistricts.index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1859868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dfDistricts[\"N_INHAB\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa50c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dfDistricts[\"N_CITIES\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a148e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dfDistricts[\"URBAN_RATIO\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26607dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dfDistricts[\"AVG_SALARY\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848155b3",
   "metadata": {},
   "source": [
    "\"UNEMP_95\" field contains value of question mark character '?'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e7146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dfDistricts[\"UNEMP_95\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b950ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dfDistricts[\"UNEMP_96\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8316c266",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dfDistricts[\"N_ENTR\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d497c52",
   "metadata": {},
   "source": [
    "\"CRIME_95\" field contains value of question mark character '?'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849d323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dfDistricts[\"CRIME_95\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f3fcf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.sort(dfDistricts[\"CRIME_96\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02702d82",
   "metadata": {},
   "source": [
    "### dfTransactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333d140d",
   "metadata": {},
   "source": [
    "\"ACCOUNT_ID\" and \"OPERATION\" operation fields contain NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e755cae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransactions.columns[dfTransactions.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3d36bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dfTransactions.index.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a3221f",
   "metadata": {},
   "source": [
    "\"ACCOUNT_ID\" field contains NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfc190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dfTransactions[\"ACCOUNT_ID\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f685a3",
   "metadata": {},
   "source": [
    "\"DATE\" field doesn't contain NaN value but date format is not in DDMMYYY format for some values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541707a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dfTransactions[\"DATE\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df6bdf2",
   "metadata": {},
   "source": [
    "Ther are incompatible formats of DD such as 40, 50, 41 etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1ac9c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " dfTransactions[\"DATE\"].astype(str).str[:2].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba936a6a",
   "metadata": {},
   "source": [
    "Ther are incompatible formats of MM such as 71, 81, 91 etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b4a6b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfTransactions[\"DATE\"].astype(str).str[2:4].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5279083d",
   "metadata": {},
   "source": [
    "When some accounts are checked, it is observed that they are not inserted as DDMMYYY but DDMMYYYY format. And when day of month is less than 10, they are inserted only 1 digit not 2 digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0108d9",
   "metadata": {},
   "outputs": [],
   "source": [
    " dfTransactions[dfTransactions[\"DATE\"].astype(str).str[:2] == \"50\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a5005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransactions[dfTransactions[\"ACCOUNT_ID\"] == 652]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e27cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransactions[\"DATE\"].astype(str).str[4:].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7030129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dfTransactions[\"AMOUNT\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dced84fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dfTransactions[\"BALANCE\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e20dce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dfTransactions[\"TYPE\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b669fef",
   "metadata": {},
   "source": [
    "\"ACCOUNT_ID\" field contains NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133afeb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfTransactions[\"OPERATION\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4963f7",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa69e0e4",
   "metadata": {},
   "source": [
    "Data preprocessing is applied to the copied datasets since some fields may be good enough for exploratory analysis but not complied for predictive model. That's why, preprocessing is applied only to the datasets that will be used in predictive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c826c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCustomersModel = dfCustomers.copy()\n",
    "dfTransactionsModel = dfTransactions.copy()\n",
    "dfDistrictsModel = dfDistricts.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412532cb",
   "metadata": {},
   "source": [
    "## Remove Duplicated Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d46dcbc",
   "metadata": {},
   "source": [
    "### TRANS_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49f0f76",
   "metadata": {},
   "source": [
    "One of the duplicated rows are kept. Rest of them are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4180592",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransactionsModel.drop_duplicates(inplace = True, keep = \"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e8e482",
   "metadata": {},
   "source": [
    "Still there are duplicated rows in terms of index but not for other values. The reason of this situation is that at least one of the duplicated rows contains NaN value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc611a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfTransactionsModel.index.unique()) == len(dfTransactionsModel.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3206e7ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfDuplicatedTransactions = dfTransactionsModel[dfTransactionsModel.index.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c5b360",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDuplicatedTransactions.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db46ab10",
   "metadata": {},
   "source": [
    "We can fill missing values by copying from its duplicated index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c752479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aDuplicatedTransIds = dfDuplicatedTransactions.index.unique()\n",
    "\n",
    "\n",
    "for iTransId in aDuplicatedTransIds:\n",
    "    \n",
    "    for j in range(dfTransactionsModel.shape[1]):\n",
    "        sColumnName = dfTransactionsModel.columns[j]\n",
    "        \n",
    "        aColumnValues = dfTransactionsModel.loc[iTransId, sColumnName]\n",
    "        \n",
    "        iNrOfMissingValues = aColumnValues.isna().sum()\n",
    "        iNrOfDuplicates = len(aColumnValues)\n",
    "        \n",
    "        if iNrOfMissingValues > 0 and iNrOfMissingValues < iNrOfDuplicates:\n",
    "            \n",
    "            aNonMissingValues = aColumnValues[aColumnValues.notna()]\n",
    "            iNrOfNonMissingValues = len(aNonMissingValues)\n",
    "            \n",
    "            if iNrOfNonMissingValues == 1:\n",
    "                dfTransactionsModel.loc[iTransId, sColumnName] = aNonMissingValues\n",
    "            \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f040f1da",
   "metadata": {},
   "source": [
    "After filling missing values from it's duplicated row, dropping duplicates is applied once again. It is observed that, there is no more duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00816633",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransactionsModel.drop_duplicates(inplace = True, keep = \"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed9cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfTransactionsModel.index.unique()) == len(dfTransactionsModel.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd71ec5",
   "metadata": {},
   "source": [
    "## Converting Date Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9d9274",
   "metadata": {},
   "source": [
    "### BIRTH_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644bef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCustomersModel[\"BIRTH_DT\"] = pd.to_datetime(dfCustomersModel[\"BIRTH_DT\"], format=\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224dc987",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dfCustomersModel[\"BIRTH_DT\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98a73e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCustomersModel.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72c2b89",
   "metadata": {},
   "source": [
    "### DATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa4422",
   "metadata": {},
   "source": [
    "\"DATE\" field should be in DDMMYYY based on description however, it is in DMMYYYY format. For the days that are less than 10, day of month is represented just 1 digit. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645ddc0c",
   "metadata": {},
   "source": [
    " \"0\" character is added at the beginning of the values where day of month is represented with single value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480ea64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransactionsModel[\"DATE\"] = dfTransactionsModel[\"DATE\"].astype(str)\n",
    "adfTransactionsWith7DigitsDates = dfTransactionsModel[dfTransactionsModel[\"DATE\"].str.len() == 7]\n",
    "dfTransactionsModel.loc[adfTransactionsWith7DigitsDates.index, \"DATE\"] = \"0\" + dfTransactionsModel.loc[adfTransactionsWith7DigitsDates.index, \"DATE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7a11c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransactionsModel[\"DATE\"] = pd.to_datetime(dfTransactionsModel[\"DATE\"], format=\"%d%m%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da7c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dfTransactionsModel[\"DATE\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88916a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransactionsModel.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007bfd63",
   "metadata": {},
   "source": [
    "## Missing Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb1e945",
   "metadata": {},
   "source": [
    "### LOAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0565daa",
   "metadata": {},
   "source": [
    "There are 50 customers which have NaN value on their \"LOAN\" field. Empty \"LOAN\" data can't be used for training or testing purposes. That's why, the customers which don't have \"LOAN\" information are dropped from dfCustomersModel and dfTransactionsModel datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8c6e7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfCustomersMissingLoan = dfCustomers[dfCustomers[\"LOAN\"].isna()]\n",
    "\n",
    "dfTransactionsMissingLoan = dfTransactions.reset_index().merge(\n",
    "    dfCustomersMissingLoan, \n",
    "    how = \"inner\", \n",
    "    on = \"ACCOUNT_ID\").set_index(\"TRANS_ID\")\n",
    "\n",
    "\n",
    "dfTransactionsModel.drop(dfTransactionsMissingLoan.index, inplace = True)\n",
    "dfCustomersModel.drop(dfCustomersMissingLoan.index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a42ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCustomersModel[\"LOAN\"] = dfCustomersModel[\"LOAN\"].astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0405c88",
   "metadata": {},
   "source": [
    "### UNEMP_95 & CRIME_95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9949ecc",
   "metadata": {},
   "source": [
    "There is 1 district (DISTRICT_ID=69) whose \"UNEMP_95\" and \"CRIME_95\" fields are empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d64525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDistricts[dfDistricts[\"UNEMP_95\"] == \"?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc964c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDistricts[dfDistricts[\"CRIME_95\"] == \"?\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb08ea2e",
   "metadata": {},
   "source": [
    "A predictive model is used to produce a value instead of question mark. As it is mentioned above, \"UNEMP_95\" and \"CRIME_95\" are in object format not in float format. The reason of this situation was because of question mark character on DISTRIC_ID=96. \n",
    "This row is dropped for temporary purpose from dataset to convert \"UNEMP_95\" and \"CRIME_95\" to float data type so that we can perform some numerical analysis. After missing values are predicted, DISTRICT_ID = 69 will be appended back to dfDistrictsModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9403f4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMissingRows = dfDistrictsModel[(dfDistrictsModel[\"UNEMP_95\"] == \"?\") | (dfDistrictsModel[\"CRIME_95\"] == \"?\")]\n",
    "\n",
    "dfDistrictsModel.drop(dfMissingRows.index, inplace = True)\n",
    "\n",
    "dfDistrictsModel[\"UNEMP_95\"] = pd.to_numeric(dfDistrictsModel[\"UNEMP_95\"])\n",
    "dfDistrictsModel[\"CRIME_95\"] = pd.to_numeric(dfDistrictsModel[\"CRIME_95\"])\n",
    "\n",
    "dfDistrictsModel.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fdf00e",
   "metadata": {},
   "source": [
    "A heatmap is created to understand if there are any strong relationships between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0a3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(abs(dfDistrictsModel.corr()), vmin = 0, vmax = 1, cmap = \"Greens\", linewidths=0.5, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489aede0",
   "metadata": {},
   "source": [
    "It is observed that linear relationship between \"UNEMP_95\" and \"UNEMP_96\" are strong. That's why, a simple linear regression model can be used to predict missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e51ec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aX = np.array(dfDistrictsModel[\"UNEMP_96\"]).reshape(-1,1)\n",
    "aY = np.array(dfDistrictsModel[\"UNEMP_95\"]).reshape(-1,1)\n",
    "\n",
    "oLinRegModel = LinearRegression()\n",
    "\n",
    "oLinRegModel.fit(aX, aY)\n",
    "\n",
    "aUnemp95ToPredict = dfDistricts[dfDistricts[\"UNEMP_95\"] == \"?\"].loc[:, \"UNEMP_96\"]\n",
    "aUnemp95ToPredict = np.array(aUnemp95ToPredict).reshape(-1,1)\n",
    "\n",
    "aUnemp95Predicted = oLinRegModel.predict(aUnemp95ToPredict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91575ccf",
   "metadata": {},
   "source": [
    "There is a linear relationship between \"CRIME_95\", \"CRIME_96\" and \"N_INHAB\" fields. That's why, a simple linear regression model can be used to predict missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8552c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aX = np.array(np.array(dfDistrictsModel[[\"CRIME_96\", \"N_INHAB\"]]))\n",
    "aY = np.array(dfDistrictsModel[\"CRIME_95\"]).reshape(-1,1)\n",
    "\n",
    "oLinRegModel = LinearRegression()\n",
    "\n",
    "oLinRegModel.fit(aX, aY)\n",
    "\n",
    "aCrime95ToPredict = dfDistricts[dfDistricts[\"CRIME_95\"] == \"?\"].loc[:,[\"CRIME_96\", \"N_INHAB\"]]\n",
    "aCrime95ToPredict = np.array(aCrime95ToPredict)\n",
    "\n",
    "aCrime95Predicted = oLinRegModel.predict(aCrime95ToPredict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6289ea45",
   "metadata": {},
   "source": [
    "In order to replace question marks with predicted valeus,  missing rows are added back to dfDistrictsModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda2d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDistrictsModel= dfDistrictsModel.append(dfMissingRows)\n",
    "dfDistrictsModel.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1ef009",
   "metadata": {},
   "source": [
    "Predicted valeus are added to missing rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5385106",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMaskMissingUnemp95s = dfDistrictsModel[\"UNEMP_95\"] == \"?\"\n",
    "dfDistrictsModel.loc[dfMaskMissingUnemp95s,\"UNEMP_95\"] = aUnemp95Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df0bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMaskMissingCrime95s = dfDistrictsModel[\"CRIME_95\"] == \"?\"\n",
    "dfDistrictsModel.loc[dfMaskMissingCrime95s,\"CRIME_95\"] = aCrime95Predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef51910",
   "metadata": {},
   "source": [
    "Now those columns can be converted to numerical type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4fb2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDistrictsModel[\"UNEMP_95\"] = dfDistrictsModel[\"UNEMP_95\"].astype(np.float64)\n",
    "dfDistrictsModel[\"CRIME_95\"] = dfDistrictsModel[\"CRIME_95\"].astype(np.int64)\n",
    "\n",
    "dfDistrictsModel.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3a1bcb",
   "metadata": {},
   "source": [
    "### ACCOUNT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeab78b1",
   "metadata": {},
   "source": [
    "There are 4915 rows that don't have value in \"ACCOUNT_ID\" field. This is not a big amount for this database. That's why, those rows are dropped from dfTransactionsModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299c5019",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMissingAccountIds = dfTransactionsModel[dfTransactionsModel[\"ACCOUNT_ID\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46716e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMissingAccountIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d89484",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransactionsModel.drop(dfMissingAccountIds.index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efca14b",
   "metadata": {},
   "source": [
    "\"ACCOUNT_ID\" field is converted to integer format to be allign with dfCustomers's \"ACCOINT_ID\" field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc842da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransactionsModel[\"ACCOUNT_ID\"] = dfTransactionsModel[\"ACCOUNT_ID\"].astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65034125",
   "metadata": {},
   "source": [
    "### OPERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7119d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransactionsMissingOperation = dfTransactionsModel[dfTransactionsModel[\"OPERATION\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50126bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransactionsMissingOperation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6937592b",
   "metadata": {},
   "source": [
    "\"TYPE\" field of all of the missing values are \"CREDIT\". When all data is checked, \"CREDIT\" type can have 2 possible \"OPERATION\":\n",
    "\n",
    "1. COLLECTION_FROM_OTHER_BANK\n",
    "or\n",
    "2. CREDIT_IN_CASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602f94bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransactionsMissingOperation[\"TYPE\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f4e5ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfTransactionsModel[[\"TYPE\", \"OPERATION\", \"AMOUNT\"]].groupby([\"TYPE\", \"OPERATION\"]).agg([\"count\", \"min\", \"max\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33700ecc",
   "metadata": {},
   "source": [
    "A decision classifier can be used to predict missing \"OPERATION\" values. In order to train the classifier, it would be enough to use only the transactions that have \"CREDIT\" type. And \"TYPE\" field doesn't need to be an input feature since it is always same for all missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a760f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransactionsNonMissingOperation = dfTransactionsModel.drop(dfTransactionsMissingOperation.index)\n",
    "dfTransactionsNonMissingOperation = dfTransactionsNonMissingOperation[dfTransactionsNonMissingOperation[\"TYPE\"] == \"CREDIT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af133513",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX = dfTransactionsModel[dfTransactionsModel[\"TYPE\"] == \"CREDIT\"].copy()\n",
    "\n",
    "dfX.drop([\"TYPE\", \"OPERATION\", \"DATE\"], axis = 1, inplace=True)\n",
    "\n",
    "dfX[\"TRANSACTION_YEAR\"] = dfTransactionsModel[\"DATE\"].dt.year\n",
    "dfX[\"TRANSACTION_MONTH\"] = dfTransactionsModel[\"DATE\"].dt.month\n",
    "dfX[\"TRANSACTION_DAY\"] = dfTransactionsModel[\"DATE\"].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e955f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e898034",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfY = pd.get_dummies(dfTransactionsModel[dfTransactionsModel[\"TYPE\"] == \"CREDIT\"][\"OPERATION\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ff977",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fdec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dfX.loc[dfTransactionsNonMissingOperation.index], \n",
    "    dfY.loc[dfTransactionsNonMissingOperation.index], \n",
    "    test_size=0.3, \n",
    "    random_state=1, \n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077d0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "oDecTreeModel =  DecisionTreeClassifier()\n",
    "oDecTreeModel.fit(X_train, y_train)\n",
    "\n",
    "y_pred = oDecTreeModel.predict(X_test)\n",
    "\n",
    "y_pred = pd.DataFrame(y_pred, index = y_test.index, columns = y_test.columns )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa44cc58",
   "metadata": {},
   "source": [
    "Both classes have good accuracy and f1 score meaning that decision tree model may able to predict both True Positives and True Negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82400ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=dfY.columns))\n",
    "\n",
    "for sClass in dfY.columns:\n",
    "    print(f\"Accuracy of : \" + sClass + \": \"+ str(round(metrics.accuracy_score(y_test[sClass], y_pred[sClass]), 2))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7562b454",
   "metadata": {},
   "source": [
    "All of the missing values are predicted as \"CREDIT_IN_CASH\" value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13d88d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "aPredictionsForMissingOperations = oDecTreeModel.predict(dfX.loc[dfTransactionsMissingOperation.index])\n",
    "dfPredictionsForMissingOperations = pd.DataFrame(data = aPredictionsForMissingOperations, columns = dfY.columns, index = dfTransactionsMissingOperation.index)\n",
    "\n",
    "aPredictedOperations = dfPredictionsForMissingOperations.idxmax(axis=1)\n",
    "\n",
    "dfTransactionsModel.loc[dfTransactionsMissingOperation.index,\"OPERATION\"] = aPredictedOperations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd59b85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aPredictedOperations.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83f8e4d",
   "metadata": {},
   "source": [
    "# DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddde1e9",
   "metadata": {},
   "source": [
    "## Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb5956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAnalysis = dfTransactionsModel[[\"DATE\", \"AMOUNT\"]].groupby([\"DATE\"], as_index = False).agg([\"count\", \"mean\"])[\"AMOUNT\"].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e7dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738135a3",
   "metadata": {},
   "source": [
    "1. There is a seasonality in average amount of payment. \n",
    "2. Behavior of average payment doesn't change much after 1994. But there is a high deviation on average payment in 1993's 1st half. \n",
    "3. On every January, average payment goes down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c124f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.lineplot(data = dfAnalysis, \n",
    "             x = \"DATE\", \n",
    "             y = \"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a67079",
   "metadata": {},
   "source": [
    "In some dates, average \"AMOUNT\" is less than 1k. When year, 1998 is checked, it is observed that those are the end dates of each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afa15e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAnalysis[(dfAnalysis[\"mean\"] < 1000) & (dfAnalysis[\"DATE\"].dt.year == 1998)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8cf8a2",
   "metadata": {},
   "source": [
    "1. There is an upwards-trend for the number of the payments. \n",
    "2. At the last day of each month, number of payment increases.\n",
    "3. During 5th-15th of each month, number of payments are higher than other days (except latest day of month)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7124a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.lineplot(data = dfAnalysis, \n",
    "             x = \"DATE\", \n",
    "             y = \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe042c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.lineplot(data = dfAnalysis[(dfAnalysis[\"DATE\"] > \"1996-03-30\") & (dfAnalysis[\"DATE\"] < \"1996-07-01\")], \n",
    "             x = \"DATE\", \n",
    "             y = \"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743aa543",
   "metadata": {},
   "source": [
    "## Customer Profile Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997c7b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMaskTransaction1996 = dfTransactionsModel[\"DATE\"].dt.year == 1996\n",
    "dfMaskTransctionsCredit = dfTransactionsModel[\"TYPE\"] ==\"CREDIT\"\n",
    "dfMaskTransctionsWithdrawal = dfTransactionsModel[\"TYPE\"] ==\"WITHDRAWAL\"\n",
    "\n",
    "dfTransactions1996 = dfTransactionsModel[dfMaskTransaction1996]\n",
    "dfTransactionsCredit1996 = dfTransactionsModel[dfMaskTransaction1996 & dfMaskTransctionsCredit]\n",
    "dfTransactionsWithdrawal1996 = dfTransactionsModel[dfMaskTransaction1996 & dfMaskTransctionsWithdrawal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1743e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBalances1996 = dfTransactions1996[[\"ACCOUNT_ID\", \"BALANCE\"]].groupby([\"ACCOUNT_ID\"]).agg([\"mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f2a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCredits1996 = dfTransactionsCredit1996[[\"ACCOUNT_ID\", \"AMOUNT\"]].groupby([\"ACCOUNT_ID\"]).agg([\"count\", \"sum\", \"mean\"])\n",
    "\n",
    "dfCredits1996.columns = dfCredits1996.columns.set_levels([\"CREDIT AMAOUNT\"], level = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd1a265",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWithdrawals1996 = dfTransactionsWithdrawal1996[[\"ACCOUNT_ID\", \"AMOUNT\"]].groupby([\"ACCOUNT_ID\"]).agg([\"count\",\"sum\",\"mean\"])\n",
    "\n",
    "dfWithdrawals1996.columns = dfWithdrawals1996.columns.set_levels([\"WITHDRAWAL AMAOUNT\"], level = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446824d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransactionSummary1996 = dfBalances1996.join(dfCredits1996, how = \"left\")\n",
    "dfTransactionSummary1996 = dfTransactionSummary1996.join(dfWithdrawals1996, how = \"left\")\n",
    "dfTransactionSummary1996.columns = ['_'.join(col) for col in dfTransactionSummary1996.columns.values]\n",
    "dfTransactionSummary1996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb29488",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAnalysis = dfCustomersModel.reset_index().merge(dfTransactionSummary1996, how = \"inner\", on = \"ACCOUNT_ID\")\n",
    "dfAnalysis = dfAnalysis.merge(dfDistrictsModel, on = \"DISTRICT_ID\", how = \"inner\")\n",
    "\n",
    "dfAnalysis[\"CUSTOMER_AGE\"] = 1996 - dfAnalysis[\"BIRTH_DT\"].dt.year\n",
    "\n",
    "dfAnalysis.drop([\"CLIENT_ID\", \"DISTRICT_ID\", \"ACCOUNT_ID\", \"BIRTH_DT\", \"SET_SPLIT\", \"CRIME_95\", \"UNEMP_95\", \"ACTIVE\"], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beb477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAnalysis.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c045fc30",
   "metadata": {},
   "source": [
    "There is no linear relationship between district features v.s. average&sum transaction quantities. That's why, district related features are excluded from dfAnalysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e59709",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(round(abs(dfAnalysis.corr()),1), vmin=0, vmax=1,  cmap = \"Greens\", linewidths=0.5, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1da45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAnalysis.drop(['N_INHAB','N_CITIES', 'URBAN_RATIO', 'AVG_SALARY', 'UNEMP_96', 'N_ENTR','CRIME_96'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7424fb6",
   "metadata": {},
   "source": [
    "BALANCE_mean distribution plot: \n",
    "1. Average balances of the customers who have loan is similar to the ones who didn't have loan. \n",
    "2. Number of customers who have loan are less than the the ones who don't have loan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e62f530",
   "metadata": {},
   "source": [
    "BALANCE_mean vs. CREDIT_AMOUNT_sum: \n",
    "1. The customers who took loan has similar CREDIT_AMOUNT_sum to their BALANCE_mean.\n",
    "2. The customers that didn't take loan has relatively smaller CREDIT_AMOUNT_sum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8cdf44",
   "metadata": {},
   "source": [
    "BALANCE_mean vs. CUSTOMER_AGE: \n",
    "1. The customers that are under 20: \n",
    "    1. They don't have any loan almost. \n",
    "2. The customers that are between 20-40:\n",
    "    1. mainly the customers that have over 60k balance have loan. \n",
    "3. The customers between 40-60 ages:\n",
    "    1. loan is distributed more homogeneously than customers that are in age 20-40.\n",
    "4. The customers over 60:\n",
    "    1. They don't have loan. \n",
    "    2. They have almost half balance than other customer profiles. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf4049c",
   "metadata": {},
   "source": [
    "CREDIT_AMOUNT_count distribution plot: \n",
    "1. Plot has 3 hills. It s a sign that there are clusters based on CREDIT_AMOUNT_count. \n",
    "2. CREDIT_AMOUNT_count can be categorized: \n",
    "    1. less than 20 transactions\n",
    "    2. 20-40 transactions\n",
    "    3. 40+ transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f063ae",
   "metadata": {},
   "source": [
    "CREDIT_AMOUNT_count vs. CUSTOMER_AGE: \n",
    "1. Customers over 60, have half number of credits compared to other customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ec70a6",
   "metadata": {},
   "source": [
    "CREDIT_AMOUNT_sum distribution plot: \n",
    "1. Customers that have less than 500k,\n",
    "    1. number of the customers that don't have loan is more than the other ones. \n",
    "2. Customers that have more than 500k, \n",
    "    1. CREDIT_AMOUNT_sum have almost same amount of customers that are loaned and not loaned. \n",
    "3. Plot has 3 hills. We can categorize them as:\n",
    "    1. less than 200k\n",
    "    2. 200k-500k\n",
    "    3. 500k+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf5e8cd",
   "metadata": {},
   "source": [
    "CREDIT_AMOUNT_sum vs. WITHDRAWAL_AMOUNT_sum:\n",
    "1. There is a strong linear relationship between them regardless loan status."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe472fff",
   "metadata": {},
   "source": [
    "CREDIT_AMOUNT_sum vs. CUSTOMER_AGE: \n",
    "1. The customers over 60\n",
    "    1. have 4 times less CREDIT_AMOUNT_sum than the other customers. \n",
    "    2. This ratio was 2 about CREDIT_AMOUNT_count and BALANCE_mean. \n",
    "2. Customers that are less than 60 years old\n",
    "    1. customers that have CREDIT_AMOUNT_sum  more than 200k, \n",
    "        1. mostly have loan \n",
    "    2. customers that have CREDIT_AMOUNT_sum less than 200k,\n",
    "        1. mostly don't have loan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affe558b",
   "metadata": {},
   "source": [
    "WITHDRAWAL_AMOUNT_count distribution plot: \n",
    "1. Customers that don't have loan withdraw more times than the ones that have loan. \n",
    "2. There are 2 hills on distribution plot. WITHDRAWAL_AMOUNT_count can be categorized as:\n",
    "    1. less than 25 transactions\n",
    "    2. 25+ transactions\n",
    "3. Customers that have less than 500k transactions,\n",
    "    1. Number of non-loaned customers are less than loaned customers.\n",
    "4. Customers that have more than 500k transactions,\n",
    "    1. Number of loaned and non-loaned customers are close to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e37654e",
   "metadata": {},
   "source": [
    "CUSTOMER_AGE distribution plot:\n",
    "1. Based on the hills of plot, CUSTOMER_AGE can be categorized as follows:\n",
    "    1. Less than 20 age\n",
    "    2. 20-40 age\n",
    "    3. 40-60 age\n",
    "    4. 60+ age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c23314",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "sns.pairplot(\n",
    "    data=dfAnalysis,\n",
    "    hue = \"LOAN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e8a611",
   "metadata": {},
   "source": [
    "Gender doesn't matter on customer behavior. For example, CREDIT_AMOUNT_sum has similar pattern for both male and female customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b65fce5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "sns.relplot(\n",
    "    data=dfAnalysis, \n",
    "    x = \"CUSTOMER_AGE\", \n",
    "    y = \"CREDIT AMAOUNT_sum\", \n",
    "    hue = \"LOAN\",\n",
    "    col=\"GENDER\", \n",
    "    kind=\"scatter\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353d78a0",
   "metadata": {},
   "source": [
    "## Geographical District Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc13feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAnalysis = dfTransactionsModel[dfTransactionsModel[\"DATE\"].dt.year == 1996]\n",
    "dfAnalysis = dfTransactionsModel.reset_index().merge(dfCustomersModel.reset_index(), on = \"ACCOUNT_ID\", how = \"inner\").set_index(\"TRANS_ID\")\n",
    "dfAnalysis = dfAnalysis.reset_index().merge(dfDistrictsModel.reset_index(), on = \"DISTRICT_ID\", how = \"inner\").set_index(\"TRANS_ID\")\n",
    "dfAnalysis[\"CUSTOMER_AGE\"] = 1996 - dfAnalysis[\"BIRTH_DT\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b58a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAnalysis.drop([\"DATE\", \"GENDER\", \"BIRTH_DT\", \"ACTIVE\", \"SET_SPLIT\", \"UNEMP_95\", \"CRIME_95\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e8468f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.scatterplot(data = dfAnalysis[dfAnalysis[\"TYPE\"] == \"CREDIT\"], x = \"DISTRICT_ID\", y = \"AMOUNT\", hue = \"OPERATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c25190",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.scatterplot(data = dfAnalysis[dfAnalysis[\"TYPE\"] == \"WITHDRAWAL\"], x = \"DISTRICT_ID\", y = \"AMOUNT\", hue = \"OPERATION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7378e16",
   "metadata": {},
   "source": [
    "# PREDICTIVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe84f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAnalysis =dfTransactionsModel.pivot_table(index = \"ACCOUNT_ID\", columns=\"OPERATION\", values=\"AMOUNT\")\n",
    "dfAnalysis.fillna(0, inplace=True)\n",
    "\n",
    "dfTransacitonSummary = dfTransactionsModel[[\"BALANCE\", \"ACCOUNT_ID\"]].groupby([\"ACCOUNT_ID\"]).agg([\"count\", \"mean\"])[\"BALANCE\"]\n",
    "dfTransacitonSummary.columns =[\"NUMBER_OF_TRANSACTIONS\", \"BALANCE_AVERAGE\"]\n",
    "\n",
    "\n",
    "dfAnalysis = dfAnalysis.merge(dfTransacitonSummary,  how = \"inner\", on = \"ACCOUNT_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46674ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAnalysis = dfAnalysis.merge(dfCustomersModel, how = \"inner\", on = \"ACCOUNT_ID\")\n",
    "dfAnalysis[\"CUSTOMER_AGE\"] = 1996- dfAnalysis[\"BIRTH_DT\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e2280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAnalysis= dfAnalysis.merge(dfDistrictsModel, how = \"inner\", on = \"DISTRICT_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc9cbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAnalysis.drop([\"ACCOUNT_ID\", \"GENDER\", \"BIRTH_DT\", \"DISTRICT_ID\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cd6c6b",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0226ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrainX = dfAnalysis[dfAnalysis[\"SET_SPLIT\"] == \"TRAIN\"].drop([\"SET_SPLIT\", \"LOAN\"], axis = 1)\n",
    "dfTrainY = dfAnalysis[dfAnalysis[\"SET_SPLIT\"] == \"TRAIN\"][\"LOAN\"]\n",
    "dfTestX = dfAnalysis[dfAnalysis[\"SET_SPLIT\"] == \"TEST\"].drop([\"SET_SPLIT\", \"LOAN\"], axis = 1)\n",
    "dfTestY = dfAnalysis[dfAnalysis[\"SET_SPLIT\"] == \"TEST\"][\"LOAN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fc1117",
   "metadata": {},
   "source": [
    "## Oversample Imbalance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d1c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombinations = dfTrainY\n",
    "dfCombinationsStats = dfCombinations.value_counts()\n",
    "dfCombinationsStats = pd.DataFrame(dfCombinationsStats).reset_index()\n",
    "\n",
    "iMaxAmount = dfCombinationsStats.iloc[0,1]\n",
    "for i in range(1, len(dfCombinationsStats) ):\n",
    "\n",
    "    sCombination = dfCombinationsStats.iloc[i, 0]\n",
    "    iSamplesNeeded = iMaxAmount - dfCombinationsStats.iloc[i, 1]\n",
    "\n",
    "    dfSampledIndex =  dfCombinations[dfCombinations == sCombination].sample(iSamplesNeeded, replace = True).index\n",
    "\n",
    "    dfSampledX = dfTrainX.loc[dfSampledIndex]\n",
    "    dfSampledY = dfTrainY.loc[dfSampledIndex]\n",
    "\n",
    "\n",
    "    dfTrainX = dfTrainX.append(dfSampledX , ignore_index= True)\n",
    "    dfTrainY = dfTrainY.append(dfSampledY , ignore_index= True)\n",
    "\n",
    "\n",
    "dfTrainX,dfTrainY = shuffle(dfTrainX,dfTrainY,random_state=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b8b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrainY.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d50b4e5",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2640d98d",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9006d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "oLogRegModel =  LogisticRegression(max_iter=10000)\n",
    "oLogRegModel.fit(dfTrainX, dfTrainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3ccee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "aPredictedLogReg = oLogRegModel.predict(dfTrainX)\n",
    "dfPredictedLogReg = pd.DataFrame(aPredictedLogReg, index = dfTrainX.index, columns = [\"LOAN\"])\n",
    "print(classification_report(dfTrainY, aPredictedLogReg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f40bde2",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6dd33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aPredictedLogRegProbability = oLogRegModel.predict_proba(dfTestX)\n",
    "aPredictedLogReg = oLogRegModel.predict(dfTestX)\n",
    "dfPredictedLogReg = pd.DataFrame(aPredictedLogReg, index = dfTestX.index, columns = [\"LOAN\"])\n",
    "print(classification_report(dfTestY, aPredictedLogReg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247aa24f",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fadd99",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7267147",
   "metadata": {},
   "outputs": [],
   "source": [
    "oDecTreeModel =  DecisionTreeClassifier()\n",
    "oDecTreeModel.fit(dfTrainX, dfTrainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e5852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aPredictedDecTree = oDecTreeModel.predict(dfTrainX)\n",
    "dfPredictedDecTree = pd.DataFrame(aPredictedDecTree, index = dfTrainX.index, columns = [\"LOAN\"])\n",
    "print(classification_report(dfTrainY, dfPredictedDecTree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f6c981",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256c4a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "aPredictedDecTreeProbability = oDecTreeModel.predict_proba(dfTestX)\n",
    "aPredictedDecTree = oDecTreeModel.predict(dfTestX)\n",
    "dfPredictedDecTree = pd.DataFrame(aPredictedDecTree, index = dfTestX.index, columns = [\"LOAN\"])\n",
    "print(classification_report(dfTestY, dfPredictedDecTree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573a4cdf",
   "metadata": {},
   "source": [
    "## Random Forest Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9c4bb9",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ead96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "oRandForestModel = RandomForestClassifier()\n",
    "oRandForestModel.fit(dfTrainX, dfTrainY.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17f7177",
   "metadata": {},
   "outputs": [],
   "source": [
    "aPredictedRandForest = oRandForestModel.predict(dfTrainX)\n",
    "dfPredictedRandForest = pd.DataFrame(aPredictedRandForest, index = dfTrainX.index, columns = [\"LOAN\"])\n",
    "print(classification_report(dfTrainY, dfPredictedRandForest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702915b9",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26627d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "aPredictedRandForestProbability = oRandForestModel.predict_proba(dfTestX)\n",
    "aPredictedRandForest = oRandForestModel.predict(dfTestX)\n",
    "dfPredictedRandForest = pd.DataFrame(aPredictedRandForest, index = dfTestX.index, columns = [\"LOAN\"])\n",
    "print(classification_report(dfTestY, dfPredictedRandForest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39505985",
   "metadata": {},
   "source": [
    "## Preprocessing for Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7627051",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrainX, dfValidationX, dfTrainY, dfValidationY = train_test_split(\n",
    "    dfTrainX,\n",
    "    dfTrainY,\n",
    "    test_size=0.30,\n",
    "    shuffle=True,\n",
    "    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9c2960",
   "metadata": {},
   "outputs": [],
   "source": [
    "oScaler = StandardScaler()\n",
    "dfTrainX = oScaler.fit_transform(dfTrainX)\n",
    "dfValidationX = oScaler.transform(dfValidationX)\n",
    "dfTestX = oScaler.transform(dfTestX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9902c814",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_f_LEARNING_RATE = 0.001\n",
    "c_f_MOMENTUM_RATE = 0.9\n",
    "c_i_PATIENCE = 10\n",
    "c_i_BATCH_SIZE = 16\n",
    "c_i_EPOCH_SIZE = 1000\n",
    "c_f_L2_FACTOR = 0.01\n",
    "\n",
    "oEarlyStop = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 0 , patience = c_i_PATIENCE, restore_best_weights=True)\n",
    "oOptimizer = tf.keras.optimizers.Adam(learning_rate= c_f_LEARNING_RATE, beta_1=c_f_MOMENTUM_RATE)\n",
    "\n",
    "oKernelRegulizer = regularizers.l2(c_f_L2_FACTOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95539049",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3f9244",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6306c0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "oMlpModel = tf.keras.Sequential()\n",
    "\n",
    "oMlpModel.add(Dense(100, activation='relu', kernel_regularizer=oKernelRegulizer, input_shape=(dfTrainX.shape[1],)))\n",
    "oMlpModel.add(Dropout(0.5))\n",
    "oMlpModel.add(Dense(100, activation='relu', kernel_regularizer=oKernelRegulizer))\n",
    "oMlpModel.add(Dropout(0.5))\n",
    "oMlpModel.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "oMlpModel.compile(optimizer=oOptimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "oMlpModel.fit(dfTrainX, \n",
    "              dfTrainY, \n",
    "              epochs=c_i_EPOCH_SIZE, \n",
    "              batch_size=c_i_BATCH_SIZE, \n",
    "              verbose=1, \n",
    "              validation_data= (dfValidationX, dfValidationY),\n",
    "              callbacks=[oEarlyStop]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f6d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "dfMlpHistory = pd.DataFrame(oMlpModel.history.history)\n",
    "\n",
    "dfMlpHistory[[\"loss\", \"val_loss\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568add44",
   "metadata": {},
   "outputs": [],
   "source": [
    "aPredictedMlpProbability = oMlpModel.predict(dfTrainX)\n",
    "\n",
    "aPredictedMlp = np.zeros(aPredictedMlpProbability.shape)\n",
    "aPredictedMlp[aPredictedMlpProbability >= 0.5] = 1\n",
    "print(classification_report(dfTrainY, aPredictedMlp, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3898c4b8",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe078f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "aPredictedMlpProbability = oMlpModel.predict(dfTestX)\n",
    "\n",
    "aPredictedMlp = np.zeros(aPredictedMlpProbability.shape)\n",
    "aPredictedMlp[aPredictedMlpProbability >= 0.5] = 1\n",
    "print(classification_report(dfTestY, aPredictedMlp, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099eb63e",
   "metadata": {},
   "source": [
    "## Long-Short Term Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264763f0",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a13669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "oLstmModel = tf.keras.Sequential()\n",
    "\n",
    "oLstmModel.add(LSTM(100, activation = \"relu\", kernel_regularizer=oKernelRegulizer))\n",
    "oLstmModel.add(Dropout(0.5))\n",
    "oLstmModel.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "oLstmModel.compile(optimizer=oOptimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "oLstmModel.fit(tf.expand_dims(dfTrainX, 1), \n",
    "                dfTrainY, \n",
    "                epochs=c_i_EPOCH_SIZE, \n",
    "                batch_size=c_i_BATCH_SIZE, \n",
    "                verbose=1, \n",
    "                validation_data= (tf.expand_dims(dfValidationX, 1), dfValidationY),\n",
    "                callbacks=[oEarlyStop]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4259983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "dfLstmHistory = pd.DataFrame(oLstmModel.history.history)\n",
    "dfLstmHistory[[\"loss\", \"val_loss\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cb4769",
   "metadata": {},
   "outputs": [],
   "source": [
    "aPredictedLstmProbability = oLstmModel.predict(tf.expand_dims(dfTrainX, 1))\n",
    "\n",
    "aPredictedLstm = np.zeros(aPredictedLstmProbability.shape)\n",
    "aPredictedLstm[aPredictedLstmProbability >= 0.5] = 1\n",
    "print(classification_report(dfTrainY, aPredictedLstm, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc59815",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2caa617",
   "metadata": {},
   "outputs": [],
   "source": [
    "aPredictedLstmProbability = oLstmModel.predict(tf.expand_dims(dfTestX, 1))\n",
    "\n",
    "aPredictedLstm = np.zeros(aPredictedLstmProbability.shape)\n",
    "aPredictedLstm[aPredictedLstmProbability >= 0.5] = 1\n",
    "print(classification_report(dfTestY, aPredictedLstm, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a03337",
   "metadata": {},
   "source": [
    "## ROC Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166eaf88",
   "metadata": {},
   "source": [
    "ROC curves typically feature true positive rate on the Y axis, and false positive rate on the X axis. This means that the top left corner of the plot is the ideal point - a false positive rate of zero, and a true positive rate of one. This is not very realistic, but it does mean that a larger area under the curve (AUC) is usually better.\n",
    "\n",
    "The steepness of ROC curves is also important, since it is ideal to maximize the true positive rate while minimizing the false positive rate.\n",
    "\n",
    "Source:\n",
    "\n",
    "1. https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5\n",
    "\n",
    "1. https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c432d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aNoSkillProbability = [0 for _ in range(len(dfTestY))]\n",
    "\n",
    "fAucNoSkill = metrics.roc_auc_score(dfTestY, aNoSkillProbability)\n",
    "fAucLogReg = metrics.roc_auc_score(dfTestY, aPredictedLogRegProbability[:,0])\n",
    "fAucRandForest = metrics.roc_auc_score(dfTestY, aPredictedRandForestProbability[:,0])\n",
    "fAucDecTree = metrics.roc_auc_score(dfTestY, aPredictedDecTreeProbability[:,0])\n",
    "fAucMlp = metrics.roc_auc_score(dfTestY, aPredictedMlpProbability[:,0])\n",
    "fAucLstm = metrics.roc_auc_score(dfTestY, aPredictedLstmProbability[:,0])\n",
    "\n",
    "\n",
    "\n",
    "aFprNoSkill, aTprNoSkill, _ = metrics.roc_curve(dfTestY, aNoSkillProbability)\n",
    "aFprLogReg, aTprLogReg, _ = metrics.roc_curve(dfTestY,  aPredictedLogRegProbability[:,0])\n",
    "aFprRandForest, aTprRandForest, _ = metrics.roc_curve(dfTestY,  aPredictedRandForestProbability[:,0])\n",
    "aFprDecTree, aTprDecTree, _ = metrics.roc_curve(dfTestY,  aPredictedDecTreeProbability[:,0])\n",
    "aFprMlp, aTprMlp, _ = metrics.roc_curve(dfTestY,  aPredictedMlpProbability[:,0])\n",
    "aFprLstm, aTprLstm, _ = metrics.roc_curve(dfTestY,  aPredictedLstmProbability[:,0])\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(aFprNoSkill, aTprNoSkill, linestyle='--', label='No Skill ROC AUC=%.3f' % (fAucNoSkill))\n",
    "plt.plot(aFprLogReg, aTprLogReg, marker='.', label='Logistic Regression ROC AUC=%.3f' % (fAucLogReg))\n",
    "plt.plot(aFprRandForest, aTprRandForest, marker='.', label='Random Forest Classifier ROC AUC=%.3f' % (fAucRandForest))\n",
    "plt.plot(aFprDecTree, aTprDecTree, marker='.', label='Decision Tree Classifier ROC AUC=%.3f' % (fAucDecTree))\n",
    "plt.plot(aFprMlp, aTprMlp, marker='.', label='Multi Layer Perceptron ROC AUC=%.3f' % (fAucMlp))\n",
    "plt.plot(aFprLstm, aTprLstm, marker='.', label='Long Short Term Memory ROC AUC=%.3f' % (fAucLstm))\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(bbox_to_anchor=(1.0, 1.0))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
